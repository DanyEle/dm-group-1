{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Gemma's function for removing outliers\n",
    "sys.path.insert(0, './../Gemma/Part 1')\n",
    "from outliers import removeOutliers\n",
    "\n",
    "#import Riccardo's function for removing missing values\n",
    "sys.path.insert(0, './../Riccardo')\n",
    "from MissingValues_3 import remove_missing_values\n",
    "\n",
    "#import Daniele's function for converting education into a numerical attribute\n",
    "#import also Daniele's function for adding mean columns' value to the data frame\n",
    "from dependencies import create_data_frame_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_credit_default_to_numerical_attribute(credit_cards_input):    \n",
    "    credit_default_column = credit_cards_input[\"credit_default\"]\n",
    "    credit_default_column_new = []\n",
    "   \n",
    "    for default_row  in credit_default_column:\n",
    "        credit_default_column_new.append(default_to_number(default_row))\n",
    "       \n",
    "    credit_cards_input[\"credit_default\"] = credit_default_column_new\n",
    "    return credit_cards_input\n",
    "\n",
    "def default_to_number(category):\n",
    "    if category == \"no\":\n",
    "        return 0\n",
    "    elif category == \"yes\":\n",
    "        return 1 \n",
    "    \n",
    "    \n",
    "def convert_education_to_numerical_attribute(credit_cards_input):    \n",
    "    education_column = credit_cards_input[\"education\"]\n",
    "    education_column_new = []\n",
    "   \n",
    "    for education_row  in education_column:\n",
    "        education_column_new.append(educ_category_to_number(education_row))\n",
    "       \n",
    "    credit_cards_input[\"education\"] = education_column_new\n",
    "    return credit_cards_input\n",
    "\n",
    "def educ_category_to_number(category):\n",
    "    if category == \"others\":\n",
    "        return 0\n",
    "    elif category == \"high school\":\n",
    "        return 1\n",
    "    elif category == \"university\":\n",
    "        return 2\n",
    "    elif category == \"graduate school\":\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if train_dataset == True --> also remove missing values and outliers\n",
    "#if train_dataset == False --> Do not remove missing values and outliers\n",
    "def load_pre_process_dataset(url, train_dataset, attributes_deep_learning):\n",
    "    #Load the training data\n",
    "    credit_cards_df = pd.read_csv(url)\n",
    "\n",
    "    #firstly, remove missing values\n",
    "    credit_cards_no_missing_outliers = remove_missing_values(credit_cards_df)\n",
    "    #and remove outliers (this function operates in place)\n",
    "    if(train_dataset == True):\n",
    "        removeOutliers(credit_cards_no_missing_outliers)\n",
    "    #create mean value columns\n",
    "    credit_cards_avg = create_data_frame_avg(credit_cards_no_missing_outliers, [\"ba-apr\", \"ba-may\", \"ba-jun\", \"ba-jul\", \"ba-aug\", \"ba-sep\"], [\"pa-apr\", \"pa-may\", \"pa-jun\", \"pa-jul\", \"pa-aug\", \"pa-sep\"],  [\"ps-apr\", \"ps-may\", \"ps-jun\", \"ps-jul\", \"ps-aug\", \"ps-sep\"])\n",
    "    credit_cards_edu_numerical = convert_education_to_numerical_attribute(credit_cards_avg)\n",
    "    #and convert the credit_default into a numerical attribute as well\n",
    "    if(train_dataset == True):\n",
    "        credit_cards_default_num = convert_credit_default_to_numerical_attribute(credit_cards_edu_numerical)\n",
    "    else:\n",
    "        credit_cards_default_num = credit_cards_edu_numerical\n",
    "    #pick the attributes you wanna use for deep learning\n",
    "    credit_cards_deep_learning = credit_cards_default_num[attributes_deep_learning]\n",
    "    \n",
    "    if(train_dataset == True):    \n",
    "        return(credit_cards_deep_learning, credit_cards_edu_numerical[\"credit_default\"])\n",
    "    else:\n",
    "        return(credit_cards_deep_learning)\n",
    "#lovely python lets me return multiple values <3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size of data frame:  (10000, 24)\n",
      "Visual analysis, number of rows to be dropped:  30\n",
      "Final size of data frame:  (9970, 24)\n",
      "(9970, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>pa-apr</th>\n",
       "      <th>pa-may</th>\n",
       "      <th>pa-jun</th>\n",
       "      <th>pa-jul</th>\n",
       "      <th>pa-aug</th>\n",
       "      <th>pa-sep</th>\n",
       "      <th>ps-apr</th>\n",
       "      <th>...</th>\n",
       "      <th>ba-jun</th>\n",
       "      <th>ba-jul</th>\n",
       "      <th>ba-aug</th>\n",
       "      <th>ba-sep</th>\n",
       "      <th>pa-apr</th>\n",
       "      <th>pa-may</th>\n",
       "      <th>pa-jun</th>\n",
       "      <th>pa-jul</th>\n",
       "      <th>pa-aug</th>\n",
       "      <th>pa-sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8269</th>\n",
       "      <td>110000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1054</td>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5043</td>\n",
       "      <td>4296</td>\n",
       "      <td>4095</td>\n",
       "      <td>3242</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1054</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>160000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3600</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500</td>\n",
       "      <td>3800</td>\n",
       "      <td>3400</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80710</td>\n",
       "      <td>79129</td>\n",
       "      <td>77220</td>\n",
       "      <td>75636</td>\n",
       "      <td>3600</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500</td>\n",
       "      <td>3800</td>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>90000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1274</td>\n",
       "      <td>556</td>\n",
       "      <td>545</td>\n",
       "      <td>26400</td>\n",
       "      <td>5322</td>\n",
       "      <td>63201</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27878</td>\n",
       "      <td>5322</td>\n",
       "      <td>63201</td>\n",
       "      <td>1933</td>\n",
       "      <td>1274</td>\n",
       "      <td>556</td>\n",
       "      <td>545</td>\n",
       "      <td>26400</td>\n",
       "      <td>5322</td>\n",
       "      <td>63201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>150000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>20000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>536</td>\n",
       "      <td>740</td>\n",
       "      <td>663</td>\n",
       "      <td>670</td>\n",
       "      <td>1290</td>\n",
       "      <td>1318</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19406</td>\n",
       "      <td>19026</td>\n",
       "      <td>18054</td>\n",
       "      <td>19102</td>\n",
       "      <td>536</td>\n",
       "      <td>740</td>\n",
       "      <td>663</td>\n",
       "      <td>670</td>\n",
       "      <td>1290</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       limit   age  education  pa-apr  pa-may  pa-jun  pa-jul  pa-aug  pa-sep  \\\n",
       "8269  110000  28.0          2    1500    1000    1000    1000    1054    1300   \n",
       "5276  160000  31.0          2    3600    3500    3500    3500    3800    3400   \n",
       "267    90000  60.0          1    1274     556     545   26400    5322   63201   \n",
       "3087  150000  23.0          3       0       0       0       0       0       0   \n",
       "5311   20000  30.0          2     536     740     663     670    1290    1318   \n",
       "\n",
       "      ps-apr   ...    ba-jun  ba-jul  ba-aug  ba-sep  pa-apr  pa-may  pa-jun  \\\n",
       "8269       0   ...      5043    4296    4095    3242    1500    1000    1000   \n",
       "5276       0   ...     80710   79129   77220   75636    3600    3500    3500   \n",
       "267        0   ...     27878    5322   63201    1933    1274     556     545   \n",
       "3087      -2   ...         0       0       0       0       0       0       0   \n",
       "5311       0   ...     19406   19026   18054   19102     536     740     663   \n",
       "\n",
       "      pa-jul  pa-aug  pa-sep  \n",
       "8269    1000    1054    1300  \n",
       "5276    3500    3800    3400  \n",
       "267    26400    5322   63201  \n",
       "3087       0       0       0  \n",
       "5311     670    1290    1318  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_deep_learning = [\"limit\", \"age\", \"education\", \"pa-apr\", \"pa-may\", \"pa-jun\", \"pa-jul\", \"pa-aug\", \"pa-sep\", 'ps-apr', 'ps-may', 'ps-jun', 'ps-jul', 'ps-aug', 'ps-sep', \"ba-apr\", \"ba-may\", \"ba-jun\", \"ba-jul\", \"ba-aug\", \"ba-sep\", \"pa-apr\", \"pa-may\", \"pa-jun\", \"pa-jul\", \"pa-aug\", \"pa-sep\"]\n",
    "url_train = \"../../Dataset/credit_default_train.csv\"\n",
    "\n",
    "credit_cards_deep_learning_train, labels_train = load_pre_process_dataset(url_train, True, attributes_deep_learning)\n",
    "\n",
    "# Take a peek at the data \n",
    "print(credit_cards_deep_learning_train.shape)\n",
    "credit_cards_deep_learning_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limit</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>pa-apr</th>\n",
       "      <th>pa-may</th>\n",
       "      <th>pa-jun</th>\n",
       "      <th>pa-jul</th>\n",
       "      <th>pa-aug</th>\n",
       "      <th>pa-sep</th>\n",
       "      <th>ps-apr</th>\n",
       "      <th>...</th>\n",
       "      <th>ba-jun</th>\n",
       "      <th>ba-jul</th>\n",
       "      <th>ba-aug</th>\n",
       "      <th>ba-sep</th>\n",
       "      <th>pa-apr</th>\n",
       "      <th>pa-may</th>\n",
       "      <th>pa-jun</th>\n",
       "      <th>pa-jul</th>\n",
       "      <th>pa-aug</th>\n",
       "      <th>pa-sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>80000</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4811</td>\n",
       "      <td>0</td>\n",
       "      <td>1613</td>\n",
       "      <td>1125</td>\n",
       "      <td>171</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1613</td>\n",
       "      <td>1125</td>\n",
       "      <td>171</td>\n",
       "      <td>6887</td>\n",
       "      <td>0</td>\n",
       "      <td>4811</td>\n",
       "      <td>0</td>\n",
       "      <td>1613</td>\n",
       "      <td>1125</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>210000</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>129</td>\n",
       "      <td>148</td>\n",
       "      <td>873</td>\n",
       "      <td>732</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>873</td>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>129</td>\n",
       "      <td>148</td>\n",
       "      <td>873</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>80000</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6541</td>\n",
       "      <td>1456</td>\n",
       "      <td>3045</td>\n",
       "      <td>2500</td>\n",
       "      <td>9295</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3045</td>\n",
       "      <td>2500</td>\n",
       "      <td>9295</td>\n",
       "      <td>3500</td>\n",
       "      <td>0</td>\n",
       "      <td>6541</td>\n",
       "      <td>1456</td>\n",
       "      <td>3045</td>\n",
       "      <td>2500</td>\n",
       "      <td>9295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>230000</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>6622</td>\n",
       "      <td>0</td>\n",
       "      <td>7500</td>\n",
       "      <td>8000</td>\n",
       "      <td>8500</td>\n",
       "      <td>8000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>200300</td>\n",
       "      <td>197039</td>\n",
       "      <td>193112</td>\n",
       "      <td>189724</td>\n",
       "      <td>6622</td>\n",
       "      <td>0</td>\n",
       "      <td>7500</td>\n",
       "      <td>8000</td>\n",
       "      <td>8500</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13030</th>\n",
       "      <td>120000</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1800</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1640</td>\n",
       "      <td>3700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40107</td>\n",
       "      <td>38746</td>\n",
       "      <td>38036</td>\n",
       "      <td>35220</td>\n",
       "      <td>1800</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1640</td>\n",
       "      <td>3700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        limit  age  education  pa-apr  pa-may  pa-jun  pa-jul  pa-aug  pa-sep  \\\n",
       "5795    80000   31          3       0    4811       0    1613    1125     171   \n",
       "6175   210000   37          3       0     292     129     148     873     732   \n",
       "3816    80000   34          1       0    6541    1456    3045    2500    9295   \n",
       "6064   230000   46          3    6622       0    7500    8000    8500    8000   \n",
       "13030  120000   28          3    1800    2000    2000    2000    1640    3700   \n",
       "\n",
       "       ps-apr   ...    ba-jun  ba-jul  ba-aug  ba-sep  pa-apr  pa-may  pa-jun  \\\n",
       "5795       -1   ...      1613    1125     171    6887       0    4811       0   \n",
       "6175       -1   ...       148     873     732       0       0     292     129   \n",
       "3816       -1   ...      3045    2500    9295    3500       0    6541    1456   \n",
       "6064        2   ...    200300  197039  193112  189724    6622       0    7500   \n",
       "13030       0   ...     40107   38746   38036   35220    1800    2000    2000   \n",
       "\n",
       "       pa-jul  pa-aug  pa-sep  \n",
       "5795     1613    1125     171  \n",
       "6175      148     873     732  \n",
       "3816     3045    2500    9295  \n",
       "6064     8000    8500    8000  \n",
       "13030    2000    1640    3700  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_test = \"../../Dataset/credit_default_test.csv\"\n",
    "credit_cards_deep_learning_test = load_pre_process_dataset(url_test, False, attributes_deep_learning)\n",
    "\n",
    "print(credit_cards_deep_learning_test.shape)\n",
    "credit_cards_deep_learning_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: X is the dataframe without the credit_default label\n",
    "\n",
    "X = credit_cards_deep_learning_train.values\n",
    "#the output consists of the state with diabetes\n",
    "y = labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22146439317953862, 0.7785356068204614)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's split the dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 22.1% of customers have defaulted, while 77.8% do not.  This means we can get an accuracy of 77.8% without any model - just declare that no one has defaulted. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 77.8%% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "#we train both with X input data and Y input data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.817\n",
      "roc-auc is 0.788\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test) #HARD\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test) #SOFT\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_train_validation_loss(keras_model):\n",
    "       #plot accuracy of second deep learning model\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(keras_model.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "    ax.plot(keras_model.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    \n",
    "def model_compute_test_validation_accuracy(keras_model):    \n",
    "    y_pred_class_nn_1 = keras_model.predict_classes(X_test_norm)\n",
    "    y_pred_prob_nn_1 = keras_model.predict(X_test_norm)\n",
    "\n",
    "    # Print model performance and plot the roc curve\n",
    "    print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "    print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "    plot_roc(y_test, y_pred_prob_nn_1, 'NN')\n",
    "    \n",
    "def output_labels_given_model_data(keras_model, credit_cards_deep_learning_test):\n",
    "    #firstly, normalize the test set\n",
    "    X_data = normalizer.fit_transform(credit_cards_deep_learning_test)\n",
    "    \n",
    "    y_labels = keras_model.predict_classes(X_data)\n",
    "    \n",
    "    list_elements = np.arange(0, len(y_labels))\n",
    "\n",
    "    \n",
    "    #and now let's co\n",
    "    \n",
    "    return(list_elements, y_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 9-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(27,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 12)                336       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 349\n",
      "Trainable params: 349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7477 samples, validate on 2493 samples\n",
      "Epoch 1/200\n",
      "7477/7477 [==============================] - 0s 66us/step - loss: 0.6820 - acc: 0.5891 - val_loss: 0.5961 - val_acc: 0.6887\n",
      "Epoch 2/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.5795 - acc: 0.7332 - val_loss: 0.5480 - val_acc: 0.7669\n",
      "Epoch 3/200\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.5487 - acc: 0.7769 - val_loss: 0.5272 - val_acc: 0.7838\n",
      "Epoch 4/200\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.5329 - acc: 0.7907 - val_loss: 0.5145 - val_acc: 0.7886\n",
      "Epoch 5/200\n",
      "7477/7477 [==============================] - 0s 41us/step - loss: 0.5221 - acc: 0.7956 - val_loss: 0.5057 - val_acc: 0.7954\n",
      "Epoch 6/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.5139 - acc: 0.7984 - val_loss: 0.4989 - val_acc: 0.8006\n",
      "Epoch 7/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.5072 - acc: 0.8003 - val_loss: 0.4933 - val_acc: 0.8043\n",
      "Epoch 8/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.5015 - acc: 0.8017 - val_loss: 0.4886 - val_acc: 0.8055\n",
      "Epoch 9/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4966 - acc: 0.8026 - val_loss: 0.4846 - val_acc: 0.8039\n",
      "Epoch 10/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4922 - acc: 0.8035 - val_loss: 0.4811 - val_acc: 0.8059\n",
      "Epoch 11/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4884 - acc: 0.8035 - val_loss: 0.4780 - val_acc: 0.8071\n",
      "Epoch 12/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4850 - acc: 0.8038 - val_loss: 0.4752 - val_acc: 0.8063\n",
      "Epoch 13/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4820 - acc: 0.8035 - val_loss: 0.4728 - val_acc: 0.8075\n",
      "Epoch 14/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4792 - acc: 0.8038 - val_loss: 0.4707 - val_acc: 0.8071\n",
      "Epoch 15/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4768 - acc: 0.8045 - val_loss: 0.4687 - val_acc: 0.8087\n",
      "Epoch 16/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4745 - acc: 0.8051 - val_loss: 0.4669 - val_acc: 0.8075\n",
      "Epoch 17/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4725 - acc: 0.8047 - val_loss: 0.4652 - val_acc: 0.8079\n",
      "Epoch 18/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4707 - acc: 0.8046 - val_loss: 0.4638 - val_acc: 0.8075\n",
      "Epoch 19/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4689 - acc: 0.8054 - val_loss: 0.4625 - val_acc: 0.8075\n",
      "Epoch 20/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4674 - acc: 0.8065 - val_loss: 0.4612 - val_acc: 0.8075\n",
      "Epoch 21/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4659 - acc: 0.8057 - val_loss: 0.4600 - val_acc: 0.8071\n",
      "Epoch 22/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4646 - acc: 0.8062 - val_loss: 0.4590 - val_acc: 0.8079\n",
      "Epoch 23/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4634 - acc: 0.8059 - val_loss: 0.4581 - val_acc: 0.8083\n",
      "Epoch 24/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4623 - acc: 0.8063 - val_loss: 0.4571 - val_acc: 0.8083\n",
      "Epoch 25/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4612 - acc: 0.8070 - val_loss: 0.4562 - val_acc: 0.8083\n",
      "Epoch 26/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4603 - acc: 0.8073 - val_loss: 0.4554 - val_acc: 0.8091\n",
      "Epoch 27/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4594 - acc: 0.8065 - val_loss: 0.4548 - val_acc: 0.8099\n",
      "Epoch 28/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4585 - acc: 0.8070 - val_loss: 0.4542 - val_acc: 0.8115\n",
      "Epoch 29/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4578 - acc: 0.8074 - val_loss: 0.4536 - val_acc: 0.8119\n",
      "Epoch 30/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4570 - acc: 0.8069 - val_loss: 0.4530 - val_acc: 0.8107\n",
      "Epoch 31/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4564 - acc: 0.8075 - val_loss: 0.4523 - val_acc: 0.8103\n",
      "Epoch 32/200\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4557 - acc: 0.8075 - val_loss: 0.4518 - val_acc: 0.8107\n",
      "Epoch 33/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4552 - acc: 0.8081 - val_loss: 0.4513 - val_acc: 0.8095\n",
      "Epoch 34/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4546 - acc: 0.8086 - val_loss: 0.4508 - val_acc: 0.8099\n",
      "Epoch 35/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4541 - acc: 0.8083 - val_loss: 0.4504 - val_acc: 0.8095\n",
      "Epoch 36/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4536 - acc: 0.8083 - val_loss: 0.4499 - val_acc: 0.8095\n",
      "Epoch 37/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4532 - acc: 0.8083 - val_loss: 0.4496 - val_acc: 0.8095\n",
      "Epoch 38/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4527 - acc: 0.8087 - val_loss: 0.4493 - val_acc: 0.8099\n",
      "Epoch 39/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4523 - acc: 0.8082 - val_loss: 0.4489 - val_acc: 0.8099\n",
      "Epoch 40/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4519 - acc: 0.8083 - val_loss: 0.4485 - val_acc: 0.8107\n",
      "Epoch 41/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4515 - acc: 0.8086 - val_loss: 0.4482 - val_acc: 0.8107\n",
      "Epoch 42/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4512 - acc: 0.8083 - val_loss: 0.4479 - val_acc: 0.8115\n",
      "Epoch 43/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4508 - acc: 0.8089 - val_loss: 0.4477 - val_acc: 0.8123\n",
      "Epoch 44/200\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4505 - acc: 0.8089 - val_loss: 0.4474 - val_acc: 0.8127\n",
      "Epoch 45/200\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4502 - acc: 0.8090 - val_loss: 0.4470 - val_acc: 0.8123\n",
      "Epoch 46/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4498 - acc: 0.8091 - val_loss: 0.4467 - val_acc: 0.8123\n",
      "Epoch 47/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4495 - acc: 0.8086 - val_loss: 0.4464 - val_acc: 0.8127\n",
      "Epoch 48/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4492 - acc: 0.8089 - val_loss: 0.4462 - val_acc: 0.8127\n",
      "Epoch 49/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4489 - acc: 0.8090 - val_loss: 0.4461 - val_acc: 0.8127\n",
      "Epoch 50/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4486 - acc: 0.8095 - val_loss: 0.4457 - val_acc: 0.8127\n",
      "Epoch 51/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4484 - acc: 0.8090 - val_loss: 0.4456 - val_acc: 0.8127\n",
      "Epoch 52/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4481 - acc: 0.8090 - val_loss: 0.4454 - val_acc: 0.8123\n",
      "Epoch 53/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4478 - acc: 0.8093 - val_loss: 0.4453 - val_acc: 0.8139\n",
      "Epoch 54/200\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4476 - acc: 0.8097 - val_loss: 0.4451 - val_acc: 0.8143\n",
      "Epoch 55/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4474 - acc: 0.8094 - val_loss: 0.4449 - val_acc: 0.8143\n",
      "Epoch 56/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4471 - acc: 0.8101 - val_loss: 0.4447 - val_acc: 0.8147\n",
      "Epoch 57/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4469 - acc: 0.8100 - val_loss: 0.4447 - val_acc: 0.8143\n",
      "Epoch 58/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4467 - acc: 0.8110 - val_loss: 0.4444 - val_acc: 0.8143\n",
      "Epoch 59/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4465 - acc: 0.8109 - val_loss: 0.4444 - val_acc: 0.8143\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4463 - acc: 0.8109 - val_loss: 0.4441 - val_acc: 0.8143\n",
      "Epoch 61/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4461 - acc: 0.8106 - val_loss: 0.4440 - val_acc: 0.8143\n",
      "Epoch 62/200\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4459 - acc: 0.8110 - val_loss: 0.4439 - val_acc: 0.8135\n",
      "Epoch 63/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4457 - acc: 0.8109 - val_loss: 0.4437 - val_acc: 0.8139\n",
      "Epoch 64/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4455 - acc: 0.8110 - val_loss: 0.4435 - val_acc: 0.8143\n",
      "Epoch 65/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4453 - acc: 0.8108 - val_loss: 0.4433 - val_acc: 0.8135\n",
      "Epoch 66/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4452 - acc: 0.8108 - val_loss: 0.4433 - val_acc: 0.8139\n",
      "Epoch 67/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4450 - acc: 0.8117 - val_loss: 0.4430 - val_acc: 0.8139\n",
      "Epoch 68/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4449 - acc: 0.8113 - val_loss: 0.4429 - val_acc: 0.8139\n",
      "Epoch 69/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4447 - acc: 0.8112 - val_loss: 0.4428 - val_acc: 0.8143\n",
      "Epoch 70/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4446 - acc: 0.8113 - val_loss: 0.4428 - val_acc: 0.8143\n",
      "Epoch 71/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4444 - acc: 0.8118 - val_loss: 0.4426 - val_acc: 0.8143\n",
      "Epoch 72/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4443 - acc: 0.8122 - val_loss: 0.4425 - val_acc: 0.8143\n",
      "Epoch 73/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4442 - acc: 0.8121 - val_loss: 0.4424 - val_acc: 0.8147\n",
      "Epoch 74/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4441 - acc: 0.8126 - val_loss: 0.4423 - val_acc: 0.8143\n",
      "Epoch 75/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4439 - acc: 0.8125 - val_loss: 0.4423 - val_acc: 0.8143\n",
      "Epoch 76/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4438 - acc: 0.8130 - val_loss: 0.4421 - val_acc: 0.8143\n",
      "Epoch 77/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4437 - acc: 0.8125 - val_loss: 0.4421 - val_acc: 0.8147\n",
      "Epoch 78/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4436 - acc: 0.8129 - val_loss: 0.4418 - val_acc: 0.8147\n",
      "Epoch 79/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4434 - acc: 0.8125 - val_loss: 0.4419 - val_acc: 0.8151\n",
      "Epoch 80/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4433 - acc: 0.8130 - val_loss: 0.4416 - val_acc: 0.8155\n",
      "Epoch 81/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4432 - acc: 0.8128 - val_loss: 0.4417 - val_acc: 0.8147\n",
      "Epoch 82/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4431 - acc: 0.8132 - val_loss: 0.4415 - val_acc: 0.8151\n",
      "Epoch 83/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4430 - acc: 0.8128 - val_loss: 0.4416 - val_acc: 0.8147\n",
      "Epoch 84/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4429 - acc: 0.8129 - val_loss: 0.4414 - val_acc: 0.8147\n",
      "Epoch 85/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4428 - acc: 0.8130 - val_loss: 0.4413 - val_acc: 0.8147\n",
      "Epoch 86/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4427 - acc: 0.8129 - val_loss: 0.4412 - val_acc: 0.8147\n",
      "Epoch 87/200\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4426 - acc: 0.8134 - val_loss: 0.4411 - val_acc: 0.8151\n",
      "Epoch 88/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4425 - acc: 0.8132 - val_loss: 0.4411 - val_acc: 0.8151\n",
      "Epoch 89/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4424 - acc: 0.8134 - val_loss: 0.4407 - val_acc: 0.8143\n",
      "Epoch 90/200\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4423 - acc: 0.8134 - val_loss: 0.4407 - val_acc: 0.8147\n",
      "Epoch 91/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4422 - acc: 0.8130 - val_loss: 0.4408 - val_acc: 0.8147\n",
      "Epoch 92/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4421 - acc: 0.8126 - val_loss: 0.4409 - val_acc: 0.8163\n",
      "Epoch 93/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4420 - acc: 0.8142 - val_loss: 0.4406 - val_acc: 0.8155\n",
      "Epoch 94/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4419 - acc: 0.8142 - val_loss: 0.4404 - val_acc: 0.8155\n",
      "Epoch 95/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4419 - acc: 0.8138 - val_loss: 0.4403 - val_acc: 0.8159\n",
      "Epoch 96/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4417 - acc: 0.8134 - val_loss: 0.4404 - val_acc: 0.8167\n",
      "Epoch 97/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4416 - acc: 0.8154 - val_loss: 0.4402 - val_acc: 0.8159\n",
      "Epoch 98/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4416 - acc: 0.8140 - val_loss: 0.4402 - val_acc: 0.8159\n",
      "Epoch 99/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4415 - acc: 0.8142 - val_loss: 0.4400 - val_acc: 0.8167\n",
      "Epoch 100/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4414 - acc: 0.8145 - val_loss: 0.4399 - val_acc: 0.8163\n",
      "Epoch 101/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4413 - acc: 0.8149 - val_loss: 0.4400 - val_acc: 0.8167\n",
      "Epoch 102/200\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4412 - acc: 0.8144 - val_loss: 0.4401 - val_acc: 0.8167\n",
      "Epoch 103/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4411 - acc: 0.8153 - val_loss: 0.4400 - val_acc: 0.8171\n",
      "Epoch 104/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4411 - acc: 0.8154 - val_loss: 0.4398 - val_acc: 0.8167\n",
      "Epoch 105/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4409 - acc: 0.8140 - val_loss: 0.4398 - val_acc: 0.8167\n",
      "Epoch 106/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4408 - acc: 0.8156 - val_loss: 0.4394 - val_acc: 0.8167\n",
      "Epoch 107/200\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4408 - acc: 0.8156 - val_loss: 0.4395 - val_acc: 0.8163\n",
      "Epoch 108/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4407 - acc: 0.8158 - val_loss: 0.4393 - val_acc: 0.8163\n",
      "Epoch 109/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4406 - acc: 0.8154 - val_loss: 0.4396 - val_acc: 0.8171\n",
      "Epoch 110/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4406 - acc: 0.8153 - val_loss: 0.4394 - val_acc: 0.8171\n",
      "Epoch 111/200\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4405 - acc: 0.8165 - val_loss: 0.4395 - val_acc: 0.8167\n",
      "Epoch 112/200\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4404 - acc: 0.8162 - val_loss: 0.4392 - val_acc: 0.8167\n",
      "Epoch 113/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4403 - acc: 0.8160 - val_loss: 0.4391 - val_acc: 0.8163\n",
      "Epoch 114/200\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4403 - acc: 0.8158 - val_loss: 0.4392 - val_acc: 0.8163\n",
      "Epoch 115/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4402 - acc: 0.8160 - val_loss: 0.4391 - val_acc: 0.8171\n",
      "Epoch 116/200\n",
      "7477/7477 [==============================] - 0s 43us/step - loss: 0.4402 - acc: 0.8165 - val_loss: 0.4390 - val_acc: 0.8167\n",
      "Epoch 117/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4400 - acc: 0.8157 - val_loss: 0.4391 - val_acc: 0.8179\n",
      "Epoch 118/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4400 - acc: 0.8162 - val_loss: 0.4389 - val_acc: 0.8179\n",
      "Epoch 119/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4400 - acc: 0.8166 - val_loss: 0.4387 - val_acc: 0.8179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "7477/7477 [==============================] - 0s 45us/step - loss: 0.4399 - acc: 0.8164 - val_loss: 0.4388 - val_acc: 0.8183\n",
      "Epoch 121/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4398 - acc: 0.8168 - val_loss: 0.4386 - val_acc: 0.8183\n",
      "Epoch 122/200\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4398 - acc: 0.8164 - val_loss: 0.4387 - val_acc: 0.8175\n",
      "Epoch 123/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4397 - acc: 0.8169 - val_loss: 0.4387 - val_acc: 0.8171\n",
      "Epoch 124/200\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4396 - acc: 0.8172 - val_loss: 0.4386 - val_acc: 0.8175\n",
      "Epoch 125/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4396 - acc: 0.8173 - val_loss: 0.4387 - val_acc: 0.8171\n",
      "Epoch 126/200\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4395 - acc: 0.8174 - val_loss: 0.4384 - val_acc: 0.8167\n",
      "Epoch 127/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4395 - acc: 0.8162 - val_loss: 0.4384 - val_acc: 0.8171\n",
      "Epoch 128/200\n",
      "7477/7477 [==============================] - 0s 42us/step - loss: 0.4394 - acc: 0.8165 - val_loss: 0.4382 - val_acc: 0.8175\n",
      "Epoch 129/200\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4393 - acc: 0.8169 - val_loss: 0.4384 - val_acc: 0.8175\n",
      "Epoch 130/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4393 - acc: 0.8177 - val_loss: 0.4382 - val_acc: 0.8175\n",
      "Epoch 131/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4392 - acc: 0.8166 - val_loss: 0.4381 - val_acc: 0.8175\n",
      "Epoch 132/200\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4391 - acc: 0.8170 - val_loss: 0.4381 - val_acc: 0.8171\n",
      "Epoch 133/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4391 - acc: 0.8173 - val_loss: 0.4382 - val_acc: 0.8171\n",
      "Epoch 134/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4390 - acc: 0.8177 - val_loss: 0.4381 - val_acc: 0.8175\n",
      "Epoch 135/200\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4390 - acc: 0.8182 - val_loss: 0.4381 - val_acc: 0.8171\n",
      "Epoch 136/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4389 - acc: 0.8174 - val_loss: 0.4380 - val_acc: 0.8175\n",
      "Epoch 137/200\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4388 - acc: 0.8174 - val_loss: 0.4380 - val_acc: 0.8167\n",
      "Epoch 138/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4388 - acc: 0.8180 - val_loss: 0.4383 - val_acc: 0.8171\n",
      "Epoch 139/200\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4387 - acc: 0.8172 - val_loss: 0.4381 - val_acc: 0.8171\n",
      "Epoch 140/200\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4387 - acc: 0.8180 - val_loss: 0.4379 - val_acc: 0.8167\n",
      "Epoch 141/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4386 - acc: 0.8184 - val_loss: 0.4377 - val_acc: 0.8179\n",
      "Epoch 142/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4385 - acc: 0.8178 - val_loss: 0.4376 - val_acc: 0.8171\n",
      "Epoch 143/200\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4385 - acc: 0.8177 - val_loss: 0.4377 - val_acc: 0.8175\n",
      "Epoch 144/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4384 - acc: 0.8176 - val_loss: 0.4377 - val_acc: 0.8171\n",
      "Epoch 145/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4384 - acc: 0.8180 - val_loss: 0.4377 - val_acc: 0.8171\n",
      "Epoch 146/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4383 - acc: 0.8178 - val_loss: 0.4377 - val_acc: 0.8171\n",
      "Epoch 147/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4383 - acc: 0.8176 - val_loss: 0.4377 - val_acc: 0.8171\n",
      "Epoch 148/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4382 - acc: 0.8177 - val_loss: 0.4376 - val_acc: 0.8171\n",
      "Epoch 149/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4382 - acc: 0.8181 - val_loss: 0.4376 - val_acc: 0.8167\n",
      "Epoch 150/200\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4381 - acc: 0.8174 - val_loss: 0.4375 - val_acc: 0.8167\n",
      "Epoch 151/200\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4380 - acc: 0.8181 - val_loss: 0.4374 - val_acc: 0.8167\n",
      "Epoch 152/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4380 - acc: 0.8176 - val_loss: 0.4374 - val_acc: 0.8167\n",
      "Epoch 153/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4380 - acc: 0.8178 - val_loss: 0.4375 - val_acc: 0.8171\n",
      "Epoch 154/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4379 - acc: 0.8181 - val_loss: 0.4374 - val_acc: 0.8163\n",
      "Epoch 155/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4379 - acc: 0.8180 - val_loss: 0.4373 - val_acc: 0.8167\n",
      "Epoch 156/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4378 - acc: 0.8176 - val_loss: 0.4373 - val_acc: 0.8167\n",
      "Epoch 157/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4378 - acc: 0.8181 - val_loss: 0.4372 - val_acc: 0.8171\n",
      "Epoch 158/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4377 - acc: 0.8173 - val_loss: 0.4374 - val_acc: 0.8171\n",
      "Epoch 159/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4377 - acc: 0.8178 - val_loss: 0.4372 - val_acc: 0.8171\n",
      "Epoch 160/200\n",
      "7477/7477 [==============================] - 0s 47us/step - loss: 0.4376 - acc: 0.8180 - val_loss: 0.4371 - val_acc: 0.8175\n",
      "Epoch 161/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4375 - acc: 0.8182 - val_loss: 0.4369 - val_acc: 0.8167\n",
      "Epoch 162/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4375 - acc: 0.8172 - val_loss: 0.4371 - val_acc: 0.8175\n",
      "Epoch 163/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4375 - acc: 0.8176 - val_loss: 0.4373 - val_acc: 0.8171\n",
      "Epoch 164/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4374 - acc: 0.8184 - val_loss: 0.4373 - val_acc: 0.8171\n",
      "Epoch 165/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4374 - acc: 0.8181 - val_loss: 0.4372 - val_acc: 0.8171\n",
      "Epoch 166/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4373 - acc: 0.8190 - val_loss: 0.4370 - val_acc: 0.8175\n",
      "Epoch 167/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4373 - acc: 0.8182 - val_loss: 0.4369 - val_acc: 0.8179\n",
      "Epoch 168/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4373 - acc: 0.8182 - val_loss: 0.4368 - val_acc: 0.8175\n",
      "Epoch 169/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4372 - acc: 0.8188 - val_loss: 0.4370 - val_acc: 0.8175\n",
      "Epoch 170/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4372 - acc: 0.8186 - val_loss: 0.4369 - val_acc: 0.8179\n",
      "Epoch 171/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4371 - acc: 0.8182 - val_loss: 0.4369 - val_acc: 0.8175\n",
      "Epoch 172/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4371 - acc: 0.8188 - val_loss: 0.4367 - val_acc: 0.8179\n",
      "Epoch 173/200\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4370 - acc: 0.8180 - val_loss: 0.4369 - val_acc: 0.8175\n",
      "Epoch 174/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4370 - acc: 0.8185 - val_loss: 0.4366 - val_acc: 0.8175\n",
      "Epoch 175/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4369 - acc: 0.8192 - val_loss: 0.4366 - val_acc: 0.8171\n",
      "Epoch 176/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4368 - acc: 0.8177 - val_loss: 0.4370 - val_acc: 0.8171\n",
      "Epoch 177/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4368 - acc: 0.8188 - val_loss: 0.4368 - val_acc: 0.8175\n",
      "Epoch 178/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4367 - acc: 0.8186 - val_loss: 0.4369 - val_acc: 0.8171\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4367 - acc: 0.8186 - val_loss: 0.4371 - val_acc: 0.8183\n",
      "Epoch 180/200\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4367 - acc: 0.8188 - val_loss: 0.4371 - val_acc: 0.8183\n",
      "Epoch 181/200\n",
      "7477/7477 [==============================] - 0s 47us/step - loss: 0.4366 - acc: 0.8197 - val_loss: 0.4366 - val_acc: 0.8175\n",
      "Epoch 182/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4366 - acc: 0.8192 - val_loss: 0.4366 - val_acc: 0.8167\n",
      "Epoch 183/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4366 - acc: 0.8190 - val_loss: 0.4365 - val_acc: 0.8167\n",
      "Epoch 184/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4365 - acc: 0.8190 - val_loss: 0.4367 - val_acc: 0.8171\n",
      "Epoch 185/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4365 - acc: 0.8189 - val_loss: 0.4366 - val_acc: 0.8167\n",
      "Epoch 186/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4364 - acc: 0.8197 - val_loss: 0.4365 - val_acc: 0.8163\n",
      "Epoch 187/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4363 - acc: 0.8197 - val_loss: 0.4364 - val_acc: 0.8175\n",
      "Epoch 188/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4363 - acc: 0.8192 - val_loss: 0.4367 - val_acc: 0.8167\n",
      "Epoch 189/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4362 - acc: 0.8197 - val_loss: 0.4363 - val_acc: 0.8171\n",
      "Epoch 190/200\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4362 - acc: 0.8192 - val_loss: 0.4362 - val_acc: 0.8167\n",
      "Epoch 191/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4361 - acc: 0.8188 - val_loss: 0.4365 - val_acc: 0.8163\n",
      "Epoch 192/200\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4361 - acc: 0.8192 - val_loss: 0.4365 - val_acc: 0.8163\n",
      "Epoch 193/200\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4360 - acc: 0.8200 - val_loss: 0.4362 - val_acc: 0.8167\n",
      "Epoch 194/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4360 - acc: 0.8190 - val_loss: 0.4365 - val_acc: 0.8163\n",
      "Epoch 195/200\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4359 - acc: 0.8196 - val_loss: 0.4366 - val_acc: 0.8175\n",
      "Epoch 196/200\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4359 - acc: 0.8200 - val_loss: 0.4362 - val_acc: 0.8167\n",
      "Epoch 197/200\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4358 - acc: 0.8200 - val_loss: 0.4363 - val_acc: 0.8159\n",
      "Epoch 198/200\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4358 - acc: 0.8190 - val_loss: 0.4362 - val_acc: 0.8159\n",
      "Epoch 199/200\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4358 - acc: 0.8196 - val_loss: 0.4363 - val_acc: 0.8175\n",
      "Epoch 200/200\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4357 - acc: 0.8200 - val_loss: 0.4361 - val_acc: 0.8167\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "plot_model_train_validation_loss(run_hist_1)\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f489c383a58>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7477 samples, validate on 2493 samples\n",
      "Epoch 1/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4356 - acc: 0.8198 - val_loss: 0.4361 - val_acc: 0.8163\n",
      "Epoch 2/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4356 - acc: 0.8201 - val_loss: 0.4361 - val_acc: 0.8163\n",
      "Epoch 3/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4355 - acc: 0.8201 - val_loss: 0.4361 - val_acc: 0.8167\n",
      "Epoch 4/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4355 - acc: 0.8202 - val_loss: 0.4362 - val_acc: 0.8167\n",
      "Epoch 5/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4354 - acc: 0.8201 - val_loss: 0.4363 - val_acc: 0.8171\n",
      "Epoch 6/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4354 - acc: 0.8197 - val_loss: 0.4361 - val_acc: 0.8167\n",
      "Epoch 7/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4353 - acc: 0.8204 - val_loss: 0.4359 - val_acc: 0.8167\n",
      "Epoch 8/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4353 - acc: 0.8201 - val_loss: 0.4359 - val_acc: 0.8167\n",
      "Epoch 9/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4353 - acc: 0.8194 - val_loss: 0.4360 - val_acc: 0.8167\n",
      "Epoch 10/1000\n",
      "7477/7477 [==============================] - 0s 37us/step - loss: 0.4352 - acc: 0.8200 - val_loss: 0.4359 - val_acc: 0.8167\n",
      "Epoch 11/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4352 - acc: 0.8202 - val_loss: 0.4360 - val_acc: 0.8175\n",
      "Epoch 12/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4351 - acc: 0.8201 - val_loss: 0.4359 - val_acc: 0.8175\n",
      "Epoch 13/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4351 - acc: 0.8193 - val_loss: 0.4360 - val_acc: 0.8175\n",
      "Epoch 14/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4350 - acc: 0.8198 - val_loss: 0.4361 - val_acc: 0.8183\n",
      "Epoch 15/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4350 - acc: 0.8200 - val_loss: 0.4359 - val_acc: 0.8175\n",
      "Epoch 16/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4350 - acc: 0.8197 - val_loss: 0.4359 - val_acc: 0.8183\n",
      "Epoch 17/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4349 - acc: 0.8202 - val_loss: 0.4357 - val_acc: 0.8163\n",
      "Epoch 18/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4348 - acc: 0.8198 - val_loss: 0.4361 - val_acc: 0.8179\n",
      "Epoch 19/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4348 - acc: 0.8200 - val_loss: 0.4363 - val_acc: 0.8187\n",
      "Epoch 20/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4347 - acc: 0.8205 - val_loss: 0.4357 - val_acc: 0.8175\n",
      "Epoch 21/1000\n",
      "7477/7477 [==============================] - 0s 46us/step - loss: 0.4347 - acc: 0.8194 - val_loss: 0.4358 - val_acc: 0.8175\n",
      "Epoch 22/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4347 - acc: 0.8202 - val_loss: 0.4359 - val_acc: 0.8163\n",
      "Epoch 23/1000\n",
      "7477/7477 [==============================] - 0s 48us/step - loss: 0.4346 - acc: 0.8200 - val_loss: 0.4358 - val_acc: 0.8175\n",
      "Epoch 24/1000\n",
      "7477/7477 [==============================] - 0s 41us/step - loss: 0.4346 - acc: 0.8204 - val_loss: 0.4358 - val_acc: 0.8187\n",
      "Epoch 25/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4346 - acc: 0.8202 - val_loss: 0.4357 - val_acc: 0.8187\n",
      "Epoch 26/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4345 - acc: 0.8200 - val_loss: 0.4356 - val_acc: 0.8187\n",
      "Epoch 27/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4345 - acc: 0.8197 - val_loss: 0.4358 - val_acc: 0.8187\n",
      "Epoch 28/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4344 - acc: 0.8198 - val_loss: 0.4359 - val_acc: 0.8191\n",
      "Epoch 29/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4344 - acc: 0.8202 - val_loss: 0.4360 - val_acc: 0.8187\n",
      "Epoch 30/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4343 - acc: 0.8205 - val_loss: 0.4359 - val_acc: 0.8183\n",
      "Epoch 31/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4343 - acc: 0.8206 - val_loss: 0.4355 - val_acc: 0.8179\n",
      "Epoch 32/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4342 - acc: 0.8196 - val_loss: 0.4354 - val_acc: 0.8183\n",
      "Epoch 33/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4342 - acc: 0.8197 - val_loss: 0.4356 - val_acc: 0.8179\n",
      "Epoch 34/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4342 - acc: 0.8201 - val_loss: 0.4357 - val_acc: 0.8191\n",
      "Epoch 35/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4341 - acc: 0.8209 - val_loss: 0.4356 - val_acc: 0.8195\n",
      "Epoch 36/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4340 - acc: 0.8206 - val_loss: 0.4358 - val_acc: 0.8191\n",
      "Epoch 37/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4340 - acc: 0.8201 - val_loss: 0.4359 - val_acc: 0.8187\n",
      "Epoch 38/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4340 - acc: 0.8202 - val_loss: 0.4356 - val_acc: 0.8191\n",
      "Epoch 39/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4339 - acc: 0.8205 - val_loss: 0.4352 - val_acc: 0.8183\n",
      "Epoch 40/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4339 - acc: 0.8206 - val_loss: 0.4350 - val_acc: 0.8183\n",
      "Epoch 41/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4339 - acc: 0.8200 - val_loss: 0.4352 - val_acc: 0.8183\n",
      "Epoch 42/1000\n",
      "7477/7477 [==============================] - 0s 42us/step - loss: 0.4338 - acc: 0.8211 - val_loss: 0.4350 - val_acc: 0.8183\n",
      "Epoch 43/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4338 - acc: 0.8208 - val_loss: 0.4348 - val_acc: 0.8183\n",
      "Epoch 44/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4338 - acc: 0.8201 - val_loss: 0.4351 - val_acc: 0.8171\n",
      "Epoch 45/1000\n",
      "7477/7477 [==============================] - 0s 41us/step - loss: 0.4337 - acc: 0.8205 - val_loss: 0.4352 - val_acc: 0.8175\n",
      "Epoch 46/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4336 - acc: 0.8206 - val_loss: 0.4354 - val_acc: 0.8199\n",
      "Epoch 47/1000\n",
      "7477/7477 [==============================] - 0s 44us/step - loss: 0.4336 - acc: 0.8206 - val_loss: 0.4352 - val_acc: 0.8195\n",
      "Epoch 48/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4335 - acc: 0.8215 - val_loss: 0.4350 - val_acc: 0.8171\n",
      "Epoch 49/1000\n",
      "7477/7477 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.8211 - val_loss: 0.4349 - val_acc: 0.8171\n",
      "Epoch 50/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4335 - acc: 0.8201 - val_loss: 0.4351 - val_acc: 0.8195\n",
      "Epoch 51/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4334 - acc: 0.8209 - val_loss: 0.4348 - val_acc: 0.8179\n",
      "Epoch 52/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4334 - acc: 0.8208 - val_loss: 0.4349 - val_acc: 0.8179\n",
      "Epoch 53/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4334 - acc: 0.8208 - val_loss: 0.4351 - val_acc: 0.8195\n",
      "Epoch 54/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4333 - acc: 0.8219 - val_loss: 0.4346 - val_acc: 0.8179\n",
      "Epoch 55/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4333 - acc: 0.8211 - val_loss: 0.4347 - val_acc: 0.8163\n",
      "Epoch 56/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4332 - acc: 0.8211 - val_loss: 0.4349 - val_acc: 0.8171\n",
      "Epoch 57/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4332 - acc: 0.8211 - val_loss: 0.4349 - val_acc: 0.8167\n",
      "Epoch 58/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4331 - acc: 0.8219 - val_loss: 0.4346 - val_acc: 0.8167\n",
      "Epoch 59/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4331 - acc: 0.8215 - val_loss: 0.4347 - val_acc: 0.8163\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 37us/step - loss: 0.4331 - acc: 0.8216 - val_loss: 0.4345 - val_acc: 0.8171\n",
      "Epoch 61/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4330 - acc: 0.8215 - val_loss: 0.4346 - val_acc: 0.8163\n",
      "Epoch 62/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4330 - acc: 0.8212 - val_loss: 0.4347 - val_acc: 0.8171\n",
      "Epoch 63/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4329 - acc: 0.8204 - val_loss: 0.4348 - val_acc: 0.8171\n",
      "Epoch 64/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4329 - acc: 0.8216 - val_loss: 0.4343 - val_acc: 0.8175\n",
      "Epoch 65/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4329 - acc: 0.8212 - val_loss: 0.4344 - val_acc: 0.8171\n",
      "Epoch 66/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4328 - acc: 0.8215 - val_loss: 0.4344 - val_acc: 0.8171\n",
      "Epoch 67/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4328 - acc: 0.8211 - val_loss: 0.4343 - val_acc: 0.8175\n",
      "Epoch 68/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4327 - acc: 0.8221 - val_loss: 0.4342 - val_acc: 0.8175\n",
      "Epoch 69/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4327 - acc: 0.8219 - val_loss: 0.4342 - val_acc: 0.8171\n",
      "Epoch 70/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4327 - acc: 0.8216 - val_loss: 0.4344 - val_acc: 0.8171\n",
      "Epoch 71/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4326 - acc: 0.8215 - val_loss: 0.4341 - val_acc: 0.8175\n",
      "Epoch 72/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4326 - acc: 0.8220 - val_loss: 0.4343 - val_acc: 0.8171\n",
      "Epoch 73/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4326 - acc: 0.8216 - val_loss: 0.4341 - val_acc: 0.8175\n",
      "Epoch 74/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4325 - acc: 0.8217 - val_loss: 0.4341 - val_acc: 0.8171\n",
      "Epoch 75/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4325 - acc: 0.8217 - val_loss: 0.4342 - val_acc: 0.8175\n",
      "Epoch 76/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4324 - acc: 0.8228 - val_loss: 0.4343 - val_acc: 0.8175\n",
      "Epoch 77/1000\n",
      "7477/7477 [==============================] - 0s 41us/step - loss: 0.4323 - acc: 0.8219 - val_loss: 0.4343 - val_acc: 0.8171\n",
      "Epoch 78/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4323 - acc: 0.8217 - val_loss: 0.4344 - val_acc: 0.8171\n",
      "Epoch 79/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4323 - acc: 0.8215 - val_loss: 0.4343 - val_acc: 0.8171\n",
      "Epoch 80/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4323 - acc: 0.8221 - val_loss: 0.4343 - val_acc: 0.8171\n",
      "Epoch 81/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4322 - acc: 0.8217 - val_loss: 0.4339 - val_acc: 0.8167\n",
      "Epoch 82/1000\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4322 - acc: 0.8220 - val_loss: 0.4340 - val_acc: 0.8167\n",
      "Epoch 83/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4322 - acc: 0.8219 - val_loss: 0.4340 - val_acc: 0.8167\n",
      "Epoch 84/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4321 - acc: 0.8220 - val_loss: 0.4338 - val_acc: 0.8167\n",
      "Epoch 85/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4321 - acc: 0.8220 - val_loss: 0.4340 - val_acc: 0.8171\n",
      "Epoch 86/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4320 - acc: 0.8228 - val_loss: 0.4337 - val_acc: 0.8171\n",
      "Epoch 87/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4320 - acc: 0.8231 - val_loss: 0.4338 - val_acc: 0.8167\n",
      "Epoch 88/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4320 - acc: 0.8229 - val_loss: 0.4340 - val_acc: 0.8163\n",
      "Epoch 89/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4319 - acc: 0.8209 - val_loss: 0.4343 - val_acc: 0.8167\n",
      "Epoch 90/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4320 - acc: 0.8219 - val_loss: 0.4341 - val_acc: 0.8163\n",
      "Epoch 91/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4318 - acc: 0.8225 - val_loss: 0.4336 - val_acc: 0.8167\n",
      "Epoch 92/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4318 - acc: 0.8215 - val_loss: 0.4338 - val_acc: 0.8163\n",
      "Epoch 93/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4318 - acc: 0.8223 - val_loss: 0.4337 - val_acc: 0.8167\n",
      "Epoch 94/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4318 - acc: 0.8220 - val_loss: 0.4339 - val_acc: 0.8171\n",
      "Epoch 95/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4317 - acc: 0.8216 - val_loss: 0.4341 - val_acc: 0.8171\n",
      "Epoch 96/1000\n",
      "7477/7477 [==============================] - 0s 37us/step - loss: 0.4317 - acc: 0.8227 - val_loss: 0.4338 - val_acc: 0.8163\n",
      "Epoch 97/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4316 - acc: 0.8223 - val_loss: 0.4341 - val_acc: 0.8163\n",
      "Epoch 98/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4316 - acc: 0.8217 - val_loss: 0.4336 - val_acc: 0.8167\n",
      "Epoch 99/1000\n",
      "7477/7477 [==============================] - 0s 41us/step - loss: 0.4316 - acc: 0.8217 - val_loss: 0.4337 - val_acc: 0.8175\n",
      "Epoch 100/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4315 - acc: 0.8220 - val_loss: 0.4333 - val_acc: 0.8175\n",
      "Epoch 101/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4315 - acc: 0.8220 - val_loss: 0.4334 - val_acc: 0.8171\n",
      "Epoch 102/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4315 - acc: 0.8225 - val_loss: 0.4335 - val_acc: 0.8171\n",
      "Epoch 103/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4315 - acc: 0.8219 - val_loss: 0.4335 - val_acc: 0.8175\n",
      "Epoch 104/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4314 - acc: 0.8228 - val_loss: 0.4336 - val_acc: 0.8171\n",
      "Epoch 105/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4313 - acc: 0.8220 - val_loss: 0.4333 - val_acc: 0.8175\n",
      "Epoch 106/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4314 - acc: 0.8213 - val_loss: 0.4331 - val_acc: 0.8179\n",
      "Epoch 107/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4313 - acc: 0.8215 - val_loss: 0.4338 - val_acc: 0.8175\n",
      "Epoch 108/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4313 - acc: 0.8219 - val_loss: 0.4333 - val_acc: 0.8171\n",
      "Epoch 109/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4313 - acc: 0.8221 - val_loss: 0.4333 - val_acc: 0.8171\n",
      "Epoch 110/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4312 - acc: 0.8217 - val_loss: 0.4332 - val_acc: 0.8171\n",
      "Epoch 111/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4312 - acc: 0.8208 - val_loss: 0.4334 - val_acc: 0.8175\n",
      "Epoch 112/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4312 - acc: 0.8225 - val_loss: 0.4335 - val_acc: 0.8175\n",
      "Epoch 113/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4311 - acc: 0.8225 - val_loss: 0.4333 - val_acc: 0.8171\n",
      "Epoch 114/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4311 - acc: 0.8220 - val_loss: 0.4332 - val_acc: 0.8171\n",
      "Epoch 115/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4310 - acc: 0.8221 - val_loss: 0.4329 - val_acc: 0.8179\n",
      "Epoch 116/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4310 - acc: 0.8221 - val_loss: 0.4328 - val_acc: 0.8179\n",
      "Epoch 117/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4310 - acc: 0.8219 - val_loss: 0.4329 - val_acc: 0.8179\n",
      "Epoch 118/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4310 - acc: 0.8227 - val_loss: 0.4329 - val_acc: 0.8171\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4309 - acc: 0.8227 - val_loss: 0.4329 - val_acc: 0.8171\n",
      "Epoch 120/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4309 - acc: 0.8227 - val_loss: 0.4332 - val_acc: 0.8175\n",
      "Epoch 121/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4308 - acc: 0.8220 - val_loss: 0.4330 - val_acc: 0.8179\n",
      "Epoch 122/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4308 - acc: 0.8229 - val_loss: 0.4330 - val_acc: 0.8175\n",
      "Epoch 123/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4307 - acc: 0.8211 - val_loss: 0.4331 - val_acc: 0.8175\n",
      "Epoch 124/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4307 - acc: 0.8227 - val_loss: 0.4333 - val_acc: 0.8171\n",
      "Epoch 125/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4307 - acc: 0.8221 - val_loss: 0.4329 - val_acc: 0.8175\n",
      "Epoch 126/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4307 - acc: 0.8215 - val_loss: 0.4331 - val_acc: 0.8171\n",
      "Epoch 127/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4306 - acc: 0.8223 - val_loss: 0.4329 - val_acc: 0.8175\n",
      "Epoch 128/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4305 - acc: 0.8227 - val_loss: 0.4326 - val_acc: 0.8183\n",
      "Epoch 129/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4306 - acc: 0.8225 - val_loss: 0.4327 - val_acc: 0.8183\n",
      "Epoch 130/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4305 - acc: 0.8216 - val_loss: 0.4329 - val_acc: 0.8179\n",
      "Epoch 131/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4305 - acc: 0.8224 - val_loss: 0.4328 - val_acc: 0.8183\n",
      "Epoch 132/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4304 - acc: 0.8209 - val_loss: 0.4330 - val_acc: 0.8171\n",
      "Epoch 133/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4304 - acc: 0.8229 - val_loss: 0.4328 - val_acc: 0.8183\n",
      "Epoch 134/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4303 - acc: 0.8224 - val_loss: 0.4325 - val_acc: 0.8179\n",
      "Epoch 135/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4303 - acc: 0.8219 - val_loss: 0.4326 - val_acc: 0.8183\n",
      "Epoch 136/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4303 - acc: 0.8219 - val_loss: 0.4328 - val_acc: 0.8179\n",
      "Epoch 137/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4302 - acc: 0.8228 - val_loss: 0.4326 - val_acc: 0.8175\n",
      "Epoch 138/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4302 - acc: 0.8220 - val_loss: 0.4325 - val_acc: 0.8179\n",
      "Epoch 139/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4301 - acc: 0.8221 - val_loss: 0.4329 - val_acc: 0.8175\n",
      "Epoch 140/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4301 - acc: 0.8216 - val_loss: 0.4327 - val_acc: 0.8183\n",
      "Epoch 141/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4300 - acc: 0.8223 - val_loss: 0.4331 - val_acc: 0.8187\n",
      "Epoch 142/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4300 - acc: 0.8223 - val_loss: 0.4332 - val_acc: 0.8187\n",
      "Epoch 143/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4299 - acc: 0.8224 - val_loss: 0.4325 - val_acc: 0.8183\n",
      "Epoch 144/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4299 - acc: 0.8229 - val_loss: 0.4327 - val_acc: 0.8175\n",
      "Epoch 145/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4299 - acc: 0.8221 - val_loss: 0.4328 - val_acc: 0.8179\n",
      "Epoch 146/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4298 - acc: 0.8219 - val_loss: 0.4324 - val_acc: 0.8183\n",
      "Epoch 147/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4298 - acc: 0.8220 - val_loss: 0.4326 - val_acc: 0.8179\n",
      "Epoch 148/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4298 - acc: 0.8224 - val_loss: 0.4328 - val_acc: 0.8183\n",
      "Epoch 149/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4298 - acc: 0.8224 - val_loss: 0.4327 - val_acc: 0.8179\n",
      "Epoch 150/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4297 - acc: 0.8228 - val_loss: 0.4323 - val_acc: 0.8175\n",
      "Epoch 151/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4297 - acc: 0.8220 - val_loss: 0.4324 - val_acc: 0.8175\n",
      "Epoch 152/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4296 - acc: 0.8224 - val_loss: 0.4323 - val_acc: 0.8175\n",
      "Epoch 153/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4296 - acc: 0.8221 - val_loss: 0.4329 - val_acc: 0.8179\n",
      "Epoch 154/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4296 - acc: 0.8220 - val_loss: 0.4326 - val_acc: 0.8171\n",
      "Epoch 155/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4296 - acc: 0.8221 - val_loss: 0.4326 - val_acc: 0.8183\n",
      "Epoch 156/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4295 - acc: 0.8227 - val_loss: 0.4324 - val_acc: 0.8171\n",
      "Epoch 157/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4295 - acc: 0.8227 - val_loss: 0.4326 - val_acc: 0.8175\n",
      "Epoch 158/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4295 - acc: 0.8212 - val_loss: 0.4323 - val_acc: 0.8183\n",
      "Epoch 159/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4294 - acc: 0.8217 - val_loss: 0.4322 - val_acc: 0.8175\n",
      "Epoch 160/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4294 - acc: 0.8224 - val_loss: 0.4324 - val_acc: 0.8171\n",
      "Epoch 161/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4294 - acc: 0.8223 - val_loss: 0.4326 - val_acc: 0.8175\n",
      "Epoch 162/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4294 - acc: 0.8225 - val_loss: 0.4323 - val_acc: 0.8179\n",
      "Epoch 163/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4293 - acc: 0.8224 - val_loss: 0.4322 - val_acc: 0.8175\n",
      "Epoch 164/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4293 - acc: 0.8212 - val_loss: 0.4320 - val_acc: 0.8179\n",
      "Epoch 165/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4293 - acc: 0.8221 - val_loss: 0.4326 - val_acc: 0.8183\n",
      "Epoch 166/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4293 - acc: 0.8225 - val_loss: 0.4325 - val_acc: 0.8183\n",
      "Epoch 167/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4292 - acc: 0.8221 - val_loss: 0.4324 - val_acc: 0.8183\n",
      "Epoch 168/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4292 - acc: 0.8233 - val_loss: 0.4326 - val_acc: 0.8179\n",
      "Epoch 169/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4292 - acc: 0.8221 - val_loss: 0.4323 - val_acc: 0.8179\n",
      "Epoch 170/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4292 - acc: 0.8221 - val_loss: 0.4322 - val_acc: 0.8179\n",
      "Epoch 171/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4291 - acc: 0.8223 - val_loss: 0.4324 - val_acc: 0.8179\n",
      "Epoch 172/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4291 - acc: 0.8227 - val_loss: 0.4323 - val_acc: 0.8175\n",
      "Epoch 173/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4290 - acc: 0.8219 - val_loss: 0.4325 - val_acc: 0.8175\n",
      "Epoch 174/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4290 - acc: 0.8225 - val_loss: 0.4323 - val_acc: 0.8191\n",
      "Epoch 175/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4290 - acc: 0.8217 - val_loss: 0.4327 - val_acc: 0.8191\n",
      "Epoch 176/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4290 - acc: 0.8220 - val_loss: 0.4325 - val_acc: 0.8179\n",
      "Epoch 177/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4289 - acc: 0.8220 - val_loss: 0.4320 - val_acc: 0.8183\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4289 - acc: 0.8220 - val_loss: 0.4323 - val_acc: 0.8187\n",
      "Epoch 179/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4288 - acc: 0.8221 - val_loss: 0.4321 - val_acc: 0.8163\n",
      "Epoch 180/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4288 - acc: 0.8211 - val_loss: 0.4321 - val_acc: 0.8191\n",
      "Epoch 181/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4288 - acc: 0.8223 - val_loss: 0.4321 - val_acc: 0.8183\n",
      "Epoch 182/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4287 - acc: 0.8216 - val_loss: 0.4318 - val_acc: 0.8175\n",
      "Epoch 183/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4288 - acc: 0.8211 - val_loss: 0.4323 - val_acc: 0.8183\n",
      "Epoch 184/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4287 - acc: 0.8225 - val_loss: 0.4319 - val_acc: 0.8187\n",
      "Epoch 185/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4287 - acc: 0.8221 - val_loss: 0.4324 - val_acc: 0.8179\n",
      "Epoch 186/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4287 - acc: 0.8221 - val_loss: 0.4322 - val_acc: 0.8175\n",
      "Epoch 187/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4286 - acc: 0.8220 - val_loss: 0.4320 - val_acc: 0.8183\n",
      "Epoch 188/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4287 - acc: 0.8216 - val_loss: 0.4319 - val_acc: 0.8183\n",
      "Epoch 189/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4286 - acc: 0.8219 - val_loss: 0.4319 - val_acc: 0.8187\n",
      "Epoch 190/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4286 - acc: 0.8219 - val_loss: 0.4320 - val_acc: 0.8179\n",
      "Epoch 191/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4286 - acc: 0.8220 - val_loss: 0.4318 - val_acc: 0.8187\n",
      "Epoch 192/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4285 - acc: 0.8217 - val_loss: 0.4317 - val_acc: 0.8183\n",
      "Epoch 193/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4285 - acc: 0.8217 - val_loss: 0.4317 - val_acc: 0.8187\n",
      "Epoch 194/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4285 - acc: 0.8217 - val_loss: 0.4316 - val_acc: 0.8179\n",
      "Epoch 195/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4284 - acc: 0.8220 - val_loss: 0.4317 - val_acc: 0.8179\n",
      "Epoch 196/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4284 - acc: 0.8223 - val_loss: 0.4321 - val_acc: 0.8179\n",
      "Epoch 197/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4284 - acc: 0.8223 - val_loss: 0.4321 - val_acc: 0.8179\n",
      "Epoch 198/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4283 - acc: 0.8215 - val_loss: 0.4316 - val_acc: 0.8183\n",
      "Epoch 199/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4283 - acc: 0.8216 - val_loss: 0.4321 - val_acc: 0.8183\n",
      "Epoch 200/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4283 - acc: 0.8223 - val_loss: 0.4317 - val_acc: 0.8179\n",
      "Epoch 201/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4283 - acc: 0.8220 - val_loss: 0.4318 - val_acc: 0.8183\n",
      "Epoch 202/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4282 - acc: 0.8220 - val_loss: 0.4315 - val_acc: 0.8183\n",
      "Epoch 203/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4283 - acc: 0.8224 - val_loss: 0.4319 - val_acc: 0.8183\n",
      "Epoch 204/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4282 - acc: 0.8224 - val_loss: 0.4316 - val_acc: 0.8183\n",
      "Epoch 205/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4282 - acc: 0.8215 - val_loss: 0.4319 - val_acc: 0.8179\n",
      "Epoch 206/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4282 - acc: 0.8227 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 207/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4282 - acc: 0.8225 - val_loss: 0.4318 - val_acc: 0.8175\n",
      "Epoch 208/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4282 - acc: 0.8223 - val_loss: 0.4319 - val_acc: 0.8179\n",
      "Epoch 209/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4281 - acc: 0.8224 - val_loss: 0.4318 - val_acc: 0.8175\n",
      "Epoch 210/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4281 - acc: 0.8224 - val_loss: 0.4316 - val_acc: 0.8179\n",
      "Epoch 211/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4281 - acc: 0.8225 - val_loss: 0.4320 - val_acc: 0.8179\n",
      "Epoch 212/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4281 - acc: 0.8224 - val_loss: 0.4316 - val_acc: 0.8179\n",
      "Epoch 213/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4280 - acc: 0.8227 - val_loss: 0.4315 - val_acc: 0.8183\n",
      "Epoch 214/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4280 - acc: 0.8216 - val_loss: 0.4320 - val_acc: 0.8175\n",
      "Epoch 215/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4280 - acc: 0.8221 - val_loss: 0.4317 - val_acc: 0.8175\n",
      "Epoch 216/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4280 - acc: 0.8223 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 217/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4279 - acc: 0.8221 - val_loss: 0.4321 - val_acc: 0.8179\n",
      "Epoch 218/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4279 - acc: 0.8227 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 219/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4279 - acc: 0.8221 - val_loss: 0.4320 - val_acc: 0.8183\n",
      "Epoch 220/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4279 - acc: 0.8228 - val_loss: 0.4316 - val_acc: 0.8179\n",
      "Epoch 221/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4279 - acc: 0.8228 - val_loss: 0.4315 - val_acc: 0.8175\n",
      "Epoch 222/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4278 - acc: 0.8224 - val_loss: 0.4317 - val_acc: 0.8175\n",
      "Epoch 223/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4278 - acc: 0.8215 - val_loss: 0.4320 - val_acc: 0.8179\n",
      "Epoch 224/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4278 - acc: 0.8231 - val_loss: 0.4315 - val_acc: 0.8171\n",
      "Epoch 225/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4278 - acc: 0.8220 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 226/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4278 - acc: 0.8227 - val_loss: 0.4319 - val_acc: 0.8179\n",
      "Epoch 227/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4277 - acc: 0.8227 - val_loss: 0.4316 - val_acc: 0.8171\n",
      "Epoch 228/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8223 - val_loss: 0.4312 - val_acc: 0.8175\n",
      "Epoch 229/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4277 - acc: 0.8229 - val_loss: 0.4317 - val_acc: 0.8171\n",
      "Epoch 230/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4277 - acc: 0.8225 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 231/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8227 - val_loss: 0.4314 - val_acc: 0.8179\n",
      "Epoch 232/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8227 - val_loss: 0.4317 - val_acc: 0.8175\n",
      "Epoch 233/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8231 - val_loss: 0.4319 - val_acc: 0.8175\n",
      "Epoch 234/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8223 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 235/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8235 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 236/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4275 - acc: 0.8223 - val_loss: 0.4319 - val_acc: 0.8183\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4276 - acc: 0.8231 - val_loss: 0.4317 - val_acc: 0.8179\n",
      "Epoch 238/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4275 - acc: 0.8219 - val_loss: 0.4318 - val_acc: 0.8179\n",
      "Epoch 239/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4275 - acc: 0.8227 - val_loss: 0.4315 - val_acc: 0.8171\n",
      "Epoch 240/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4275 - acc: 0.8225 - val_loss: 0.4314 - val_acc: 0.8179\n",
      "Epoch 241/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4274 - acc: 0.8233 - val_loss: 0.4317 - val_acc: 0.8179\n",
      "Epoch 242/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4274 - acc: 0.8225 - val_loss: 0.4315 - val_acc: 0.8175\n",
      "Epoch 243/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4274 - acc: 0.8225 - val_loss: 0.4315 - val_acc: 0.8163\n",
      "Epoch 244/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4274 - acc: 0.8220 - val_loss: 0.4317 - val_acc: 0.8183\n",
      "Epoch 245/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4274 - acc: 0.8223 - val_loss: 0.4316 - val_acc: 0.8183\n",
      "Epoch 246/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4272 - acc: 0.8220 - val_loss: 0.4309 - val_acc: 0.8175\n",
      "Epoch 247/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4273 - acc: 0.8221 - val_loss: 0.4316 - val_acc: 0.8171\n",
      "Epoch 248/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4273 - acc: 0.8213 - val_loss: 0.4315 - val_acc: 0.8179\n",
      "Epoch 249/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4272 - acc: 0.8219 - val_loss: 0.4313 - val_acc: 0.8183\n",
      "Epoch 250/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4272 - acc: 0.8227 - val_loss: 0.4312 - val_acc: 0.8179\n",
      "Epoch 251/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4272 - acc: 0.8228 - val_loss: 0.4313 - val_acc: 0.8171\n",
      "Epoch 252/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4272 - acc: 0.8223 - val_loss: 0.4319 - val_acc: 0.8175\n",
      "Epoch 253/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4271 - acc: 0.8211 - val_loss: 0.4311 - val_acc: 0.8187\n",
      "Epoch 254/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4271 - acc: 0.8225 - val_loss: 0.4316 - val_acc: 0.8183\n",
      "Epoch 255/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4271 - acc: 0.8225 - val_loss: 0.4318 - val_acc: 0.8167\n",
      "Epoch 256/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4271 - acc: 0.8224 - val_loss: 0.4316 - val_acc: 0.8171\n",
      "Epoch 257/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4271 - acc: 0.8223 - val_loss: 0.4313 - val_acc: 0.8167\n",
      "Epoch 258/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4270 - acc: 0.8213 - val_loss: 0.4314 - val_acc: 0.8171\n",
      "Epoch 259/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4270 - acc: 0.8224 - val_loss: 0.4318 - val_acc: 0.8175\n",
      "Epoch 260/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4270 - acc: 0.8221 - val_loss: 0.4315 - val_acc: 0.8171\n",
      "Epoch 261/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4269 - acc: 0.8219 - val_loss: 0.4310 - val_acc: 0.8171\n",
      "Epoch 262/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4270 - acc: 0.8223 - val_loss: 0.4311 - val_acc: 0.8171\n",
      "Epoch 263/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4269 - acc: 0.8231 - val_loss: 0.4313 - val_acc: 0.8167\n",
      "Epoch 264/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4269 - acc: 0.8216 - val_loss: 0.4314 - val_acc: 0.8175\n",
      "Epoch 265/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4269 - acc: 0.8229 - val_loss: 0.4312 - val_acc: 0.8171\n",
      "Epoch 266/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4268 - acc: 0.8227 - val_loss: 0.4311 - val_acc: 0.8171\n",
      "Epoch 267/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4268 - acc: 0.8221 - val_loss: 0.4317 - val_acc: 0.8171\n",
      "Epoch 268/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4268 - acc: 0.8231 - val_loss: 0.4312 - val_acc: 0.8175\n",
      "Epoch 269/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4267 - acc: 0.8220 - val_loss: 0.4317 - val_acc: 0.8175\n",
      "Epoch 270/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4266 - acc: 0.8225 - val_loss: 0.4310 - val_acc: 0.8167\n",
      "Epoch 271/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4267 - acc: 0.8221 - val_loss: 0.4314 - val_acc: 0.8175\n",
      "Epoch 272/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4267 - acc: 0.8224 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 273/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4267 - acc: 0.8213 - val_loss: 0.4315 - val_acc: 0.8171\n",
      "Epoch 274/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4266 - acc: 0.8223 - val_loss: 0.4314 - val_acc: 0.8175\n",
      "Epoch 275/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4266 - acc: 0.8224 - val_loss: 0.4314 - val_acc: 0.8171\n",
      "Epoch 276/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4266 - acc: 0.8225 - val_loss: 0.4311 - val_acc: 0.8175\n",
      "Epoch 277/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4265 - acc: 0.8220 - val_loss: 0.4308 - val_acc: 0.8179\n",
      "Epoch 278/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4266 - acc: 0.8221 - val_loss: 0.4308 - val_acc: 0.8183\n",
      "Epoch 279/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4266 - acc: 0.8219 - val_loss: 0.4309 - val_acc: 0.8183\n",
      "Epoch 280/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4266 - acc: 0.8220 - val_loss: 0.4311 - val_acc: 0.8183\n",
      "Epoch 281/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4265 - acc: 0.8223 - val_loss: 0.4313 - val_acc: 0.8183\n",
      "Epoch 282/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4265 - acc: 0.8221 - val_loss: 0.4309 - val_acc: 0.8183\n",
      "Epoch 283/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4265 - acc: 0.8224 - val_loss: 0.4312 - val_acc: 0.8179\n",
      "Epoch 284/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4264 - acc: 0.8224 - val_loss: 0.4315 - val_acc: 0.8179\n",
      "Epoch 285/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4264 - acc: 0.8217 - val_loss: 0.4308 - val_acc: 0.8183\n",
      "Epoch 286/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4264 - acc: 0.8227 - val_loss: 0.4311 - val_acc: 0.8175\n",
      "Epoch 287/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4264 - acc: 0.8225 - val_loss: 0.4309 - val_acc: 0.8183\n",
      "Epoch 288/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4264 - acc: 0.8224 - val_loss: 0.4312 - val_acc: 0.8179\n",
      "Epoch 289/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4263 - acc: 0.8219 - val_loss: 0.4309 - val_acc: 0.8183\n",
      "Epoch 290/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4263 - acc: 0.8219 - val_loss: 0.4310 - val_acc: 0.8183\n",
      "Epoch 291/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4263 - acc: 0.8220 - val_loss: 0.4306 - val_acc: 0.8183\n",
      "Epoch 292/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4263 - acc: 0.8220 - val_loss: 0.4309 - val_acc: 0.8183\n",
      "Epoch 293/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4263 - acc: 0.8228 - val_loss: 0.4309 - val_acc: 0.8183\n",
      "Epoch 294/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4262 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8175\n",
      "Epoch 295/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4261 - acc: 0.8225 - val_loss: 0.4305 - val_acc: 0.8179\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4263 - acc: 0.8227 - val_loss: 0.4309 - val_acc: 0.8179\n",
      "Epoch 297/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4262 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8179\n",
      "Epoch 298/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4262 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8179\n",
      "Epoch 299/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4262 - acc: 0.8225 - val_loss: 0.4309 - val_acc: 0.8175\n",
      "Epoch 300/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4261 - acc: 0.8224 - val_loss: 0.4312 - val_acc: 0.8175\n",
      "Epoch 301/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4262 - acc: 0.8225 - val_loss: 0.4312 - val_acc: 0.8175\n",
      "Epoch 302/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4261 - acc: 0.8217 - val_loss: 0.4308 - val_acc: 0.8175\n",
      "Epoch 303/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4261 - acc: 0.8220 - val_loss: 0.4307 - val_acc: 0.8171\n",
      "Epoch 304/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4261 - acc: 0.8221 - val_loss: 0.4309 - val_acc: 0.8175\n",
      "Epoch 305/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4260 - acc: 0.8228 - val_loss: 0.4310 - val_acc: 0.8175\n",
      "Epoch 306/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4260 - acc: 0.8224 - val_loss: 0.4306 - val_acc: 0.8175\n",
      "Epoch 307/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4260 - acc: 0.8219 - val_loss: 0.4307 - val_acc: 0.8171\n",
      "Epoch 308/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4260 - acc: 0.8228 - val_loss: 0.4305 - val_acc: 0.8183\n",
      "Epoch 309/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4260 - acc: 0.8225 - val_loss: 0.4305 - val_acc: 0.8183\n",
      "Epoch 310/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4259 - acc: 0.8223 - val_loss: 0.4306 - val_acc: 0.8175\n",
      "Epoch 311/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4259 - acc: 0.8229 - val_loss: 0.4306 - val_acc: 0.8175\n",
      "Epoch 312/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4259 - acc: 0.8221 - val_loss: 0.4307 - val_acc: 0.8175\n",
      "Epoch 313/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4259 - acc: 0.8219 - val_loss: 0.4306 - val_acc: 0.8175\n",
      "Epoch 314/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4258 - acc: 0.8221 - val_loss: 0.4309 - val_acc: 0.8175\n",
      "Epoch 315/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4259 - acc: 0.8223 - val_loss: 0.4307 - val_acc: 0.8175\n",
      "Epoch 316/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4258 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8179\n",
      "Epoch 317/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4258 - acc: 0.8217 - val_loss: 0.4305 - val_acc: 0.8175\n",
      "Epoch 318/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4258 - acc: 0.8220 - val_loss: 0.4309 - val_acc: 0.8175\n",
      "Epoch 319/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4256 - acc: 0.8223 - val_loss: 0.4316 - val_acc: 0.8175\n",
      "Epoch 320/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4258 - acc: 0.8221 - val_loss: 0.4308 - val_acc: 0.8175\n",
      "Epoch 321/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4257 - acc: 0.8221 - val_loss: 0.4307 - val_acc: 0.8171\n",
      "Epoch 322/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4257 - acc: 0.8220 - val_loss: 0.4304 - val_acc: 0.8167\n",
      "Epoch 323/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4257 - acc: 0.8224 - val_loss: 0.4306 - val_acc: 0.8183\n",
      "Epoch 324/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4257 - acc: 0.8219 - val_loss: 0.4306 - val_acc: 0.8175\n",
      "Epoch 325/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4257 - acc: 0.8225 - val_loss: 0.4306 - val_acc: 0.8171\n",
      "Epoch 326/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4256 - acc: 0.8228 - val_loss: 0.4307 - val_acc: 0.8179\n",
      "Epoch 327/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4256 - acc: 0.8223 - val_loss: 0.4302 - val_acc: 0.8183\n",
      "Epoch 328/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4256 - acc: 0.8221 - val_loss: 0.4304 - val_acc: 0.8179\n",
      "Epoch 329/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4256 - acc: 0.8225 - val_loss: 0.4307 - val_acc: 0.8179\n",
      "Epoch 330/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4256 - acc: 0.8224 - val_loss: 0.4306 - val_acc: 0.8171\n",
      "Epoch 331/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4256 - acc: 0.8217 - val_loss: 0.4304 - val_acc: 0.8175\n",
      "Epoch 332/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4256 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8175\n",
      "Epoch 333/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4255 - acc: 0.8223 - val_loss: 0.4304 - val_acc: 0.8171\n",
      "Epoch 334/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4255 - acc: 0.8225 - val_loss: 0.4303 - val_acc: 0.8167\n",
      "Epoch 335/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4255 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8171\n",
      "Epoch 336/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4255 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8171\n",
      "Epoch 337/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4254 - acc: 0.8221 - val_loss: 0.4307 - val_acc: 0.8175\n",
      "Epoch 338/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4254 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8171\n",
      "Epoch 339/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4254 - acc: 0.8221 - val_loss: 0.4303 - val_acc: 0.8183\n",
      "Epoch 340/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4254 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8183\n",
      "Epoch 341/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4254 - acc: 0.8227 - val_loss: 0.4304 - val_acc: 0.8175\n",
      "Epoch 342/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4254 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8175\n",
      "Epoch 343/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4254 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8167\n",
      "Epoch 344/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4253 - acc: 0.8224 - val_loss: 0.4302 - val_acc: 0.8175\n",
      "Epoch 345/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4254 - acc: 0.8228 - val_loss: 0.4302 - val_acc: 0.8175\n",
      "Epoch 346/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4254 - acc: 0.8221 - val_loss: 0.4301 - val_acc: 0.8175\n",
      "Epoch 347/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4254 - acc: 0.8224 - val_loss: 0.4304 - val_acc: 0.8179\n",
      "Epoch 348/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4252 - acc: 0.8233 - val_loss: 0.4310 - val_acc: 0.8179\n",
      "Epoch 349/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4253 - acc: 0.8223 - val_loss: 0.4306 - val_acc: 0.8179\n",
      "Epoch 350/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4253 - acc: 0.8221 - val_loss: 0.4304 - val_acc: 0.8175\n",
      "Epoch 351/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4252 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8175\n",
      "Epoch 352/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4252 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8179\n",
      "Epoch 353/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4250 - acc: 0.8223 - val_loss: 0.4299 - val_acc: 0.8183\n",
      "Epoch 354/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4253 - acc: 0.8228 - val_loss: 0.4302 - val_acc: 0.8183\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4252 - acc: 0.8225 - val_loss: 0.4302 - val_acc: 0.8179\n",
      "Epoch 356/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4251 - acc: 0.8232 - val_loss: 0.4305 - val_acc: 0.8179\n",
      "Epoch 357/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4250 - acc: 0.8223 - val_loss: 0.4300 - val_acc: 0.8191\n",
      "Epoch 358/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4251 - acc: 0.8221 - val_loss: 0.4304 - val_acc: 0.8183\n",
      "Epoch 359/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4251 - acc: 0.8232 - val_loss: 0.4305 - val_acc: 0.8187\n",
      "Epoch 360/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4251 - acc: 0.8224 - val_loss: 0.4301 - val_acc: 0.8183\n",
      "Epoch 361/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4251 - acc: 0.8227 - val_loss: 0.4300 - val_acc: 0.8187\n",
      "Epoch 362/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4251 - acc: 0.8228 - val_loss: 0.4300 - val_acc: 0.8191\n",
      "Epoch 363/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4251 - acc: 0.8220 - val_loss: 0.4304 - val_acc: 0.8191\n",
      "Epoch 364/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4250 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8183\n",
      "Epoch 365/1000\n",
      "7477/7477 [==============================] - ETA: 0s - loss: 0.4226 - acc: 0.824 - 0s 27us/step - loss: 0.4249 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8175\n",
      "Epoch 366/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4250 - acc: 0.8233 - val_loss: 0.4306 - val_acc: 0.8175\n",
      "Epoch 367/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4250 - acc: 0.8223 - val_loss: 0.4300 - val_acc: 0.8195\n",
      "Epoch 368/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4250 - acc: 0.8219 - val_loss: 0.4300 - val_acc: 0.8191\n",
      "Epoch 369/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4249 - acc: 0.8227 - val_loss: 0.4304 - val_acc: 0.8187\n",
      "Epoch 370/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4248 - acc: 0.8216 - val_loss: 0.4308 - val_acc: 0.8187\n",
      "Epoch 371/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4250 - acc: 0.8225 - val_loss: 0.4302 - val_acc: 0.8187\n",
      "Epoch 372/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4249 - acc: 0.8225 - val_loss: 0.4300 - val_acc: 0.8187\n",
      "Epoch 373/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4249 - acc: 0.8223 - val_loss: 0.4306 - val_acc: 0.8191\n",
      "Epoch 374/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4249 - acc: 0.8223 - val_loss: 0.4299 - val_acc: 0.8203\n",
      "Epoch 375/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4249 - acc: 0.8224 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 376/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4248 - acc: 0.8225 - val_loss: 0.4299 - val_acc: 0.8199\n",
      "Epoch 377/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4249 - acc: 0.8228 - val_loss: 0.4301 - val_acc: 0.8191\n",
      "Epoch 378/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4248 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8191\n",
      "Epoch 379/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4248 - acc: 0.8225 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 380/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4247 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8191\n",
      "Epoch 381/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4248 - acc: 0.8223 - val_loss: 0.4299 - val_acc: 0.8191\n",
      "Epoch 382/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4247 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8195\n",
      "Epoch 383/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4247 - acc: 0.8225 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 384/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8228 - val_loss: 0.4297 - val_acc: 0.8203\n",
      "Epoch 385/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8223 - val_loss: 0.4296 - val_acc: 0.8195\n",
      "Epoch 386/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4247 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8191\n",
      "Epoch 387/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4246 - acc: 0.8224 - val_loss: 0.4299 - val_acc: 0.8195\n",
      "Epoch 388/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8228 - val_loss: 0.4300 - val_acc: 0.8199\n",
      "Epoch 389/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8228 - val_loss: 0.4299 - val_acc: 0.8191\n",
      "Epoch 390/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8228 - val_loss: 0.4298 - val_acc: 0.8183\n",
      "Epoch 391/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8223 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 392/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4246 - acc: 0.8229 - val_loss: 0.4301 - val_acc: 0.8195\n",
      "Epoch 393/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4245 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8195\n",
      "Epoch 394/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4245 - acc: 0.8231 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 395/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4244 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8187\n",
      "Epoch 396/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4245 - acc: 0.8227 - val_loss: 0.4304 - val_acc: 0.8191\n",
      "Epoch 397/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4244 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8195\n",
      "Epoch 398/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4245 - acc: 0.8224 - val_loss: 0.4303 - val_acc: 0.8191\n",
      "Epoch 399/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4245 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8191\n",
      "Epoch 400/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4245 - acc: 0.8225 - val_loss: 0.4300 - val_acc: 0.8195\n",
      "Epoch 401/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4244 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8191\n",
      "Epoch 402/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4244 - acc: 0.8223 - val_loss: 0.4298 - val_acc: 0.8203\n",
      "Epoch 403/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4244 - acc: 0.8223 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 404/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4243 - acc: 0.8229 - val_loss: 0.4297 - val_acc: 0.8207\n",
      "Epoch 405/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4243 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 406/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4243 - acc: 0.8227 - val_loss: 0.4300 - val_acc: 0.8191\n",
      "Epoch 407/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4243 - acc: 0.8217 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 408/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4243 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8211\n",
      "Epoch 409/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4243 - acc: 0.8217 - val_loss: 0.4298 - val_acc: 0.8199\n",
      "Epoch 410/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4242 - acc: 0.8223 - val_loss: 0.4298 - val_acc: 0.8203\n",
      "Epoch 411/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4243 - acc: 0.8228 - val_loss: 0.4299 - val_acc: 0.8207\n",
      "Epoch 412/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4243 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 413/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4243 - acc: 0.8231 - val_loss: 0.4301 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4242 - acc: 0.8229 - val_loss: 0.4297 - val_acc: 0.8215\n",
      "Epoch 415/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4242 - acc: 0.8221 - val_loss: 0.4302 - val_acc: 0.8199\n",
      "Epoch 416/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4241 - acc: 0.8224 - val_loss: 0.4296 - val_acc: 0.8199\n",
      "Epoch 417/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4241 - acc: 0.8217 - val_loss: 0.4303 - val_acc: 0.8195\n",
      "Epoch 418/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4242 - acc: 0.8224 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 419/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4241 - acc: 0.8225 - val_loss: 0.4297 - val_acc: 0.8211\n",
      "Epoch 420/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4242 - acc: 0.8225 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 421/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4241 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 422/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4241 - acc: 0.8227 - val_loss: 0.4298 - val_acc: 0.8199\n",
      "Epoch 423/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4241 - acc: 0.8225 - val_loss: 0.4297 - val_acc: 0.8199\n",
      "Epoch 424/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4241 - acc: 0.8232 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 425/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4241 - acc: 0.8225 - val_loss: 0.4300 - val_acc: 0.8203\n",
      "Epoch 426/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4240 - acc: 0.8225 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 427/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4240 - acc: 0.8224 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 428/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4241 - acc: 0.8229 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 429/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4241 - acc: 0.8225 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 430/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4240 - acc: 0.8229 - val_loss: 0.4299 - val_acc: 0.8207\n",
      "Epoch 431/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4240 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 432/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4239 - acc: 0.8229 - val_loss: 0.4310 - val_acc: 0.8199\n",
      "Epoch 433/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4241 - acc: 0.8224 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 434/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4240 - acc: 0.8232 - val_loss: 0.4302 - val_acc: 0.8199\n",
      "Epoch 435/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4240 - acc: 0.8235 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 436/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4240 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 437/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4239 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 438/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4240 - acc: 0.8228 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 439/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4239 - acc: 0.8227 - val_loss: 0.4299 - val_acc: 0.8219\n",
      "Epoch 440/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4239 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 441/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 442/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8232 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 443/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4239 - acc: 0.8232 - val_loss: 0.4307 - val_acc: 0.8199\n",
      "Epoch 444/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4239 - acc: 0.8228 - val_loss: 0.4302 - val_acc: 0.8211\n",
      "Epoch 445/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 446/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8227 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 447/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8235 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 448/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4238 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 449/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4238 - acc: 0.8235 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 450/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4237 - acc: 0.8229 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 451/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4237 - acc: 0.8224 - val_loss: 0.4298 - val_acc: 0.8215\n",
      "Epoch 452/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4237 - acc: 0.8225 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 453/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4238 - acc: 0.8228 - val_loss: 0.4298 - val_acc: 0.8215\n",
      "Epoch 454/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4238 - acc: 0.8232 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 455/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 456/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8216 - val_loss: 0.4299 - val_acc: 0.8215\n",
      "Epoch 457/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8232 - val_loss: 0.4300 - val_acc: 0.8211\n",
      "Epoch 458/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4236 - acc: 0.8228 - val_loss: 0.4297 - val_acc: 0.8219\n",
      "Epoch 459/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8229 - val_loss: 0.4298 - val_acc: 0.8215\n",
      "Epoch 460/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8229 - val_loss: 0.4299 - val_acc: 0.8211\n",
      "Epoch 461/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8233 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 462/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4236 - acc: 0.8223 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 463/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4237 - acc: 0.8231 - val_loss: 0.4302 - val_acc: 0.8211\n",
      "Epoch 464/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4235 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 465/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4236 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8195\n",
      "Epoch 466/1000\n",
      "7477/7477 [==============================] - 0s 44us/step - loss: 0.4236 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8211\n",
      "Epoch 467/1000\n",
      "7477/7477 [==============================] - 0s 48us/step - loss: 0.4235 - acc: 0.8236 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 468/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4234 - acc: 0.8231 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 469/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4236 - acc: 0.8233 - val_loss: 0.4304 - val_acc: 0.8211\n",
      "Epoch 470/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4236 - acc: 0.8237 - val_loss: 0.4298 - val_acc: 0.8211\n",
      "Epoch 471/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4235 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 472/1000\n",
      "7477/7477 [==============================] - 0s 47us/step - loss: 0.4235 - acc: 0.8227 - val_loss: 0.4300 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4235 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 474/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4235 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 475/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4235 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 476/1000\n",
      "7477/7477 [==============================] - 0s 37us/step - loss: 0.4235 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 477/1000\n",
      "7477/7477 [==============================] - 0s 45us/step - loss: 0.4234 - acc: 0.8228 - val_loss: 0.4298 - val_acc: 0.8215\n",
      "Epoch 478/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4235 - acc: 0.8233 - val_loss: 0.4298 - val_acc: 0.8211\n",
      "Epoch 479/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4234 - acc: 0.8235 - val_loss: 0.4298 - val_acc: 0.8211\n",
      "Epoch 480/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4235 - acc: 0.8227 - val_loss: 0.4300 - val_acc: 0.8203\n",
      "Epoch 481/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4233 - acc: 0.8232 - val_loss: 0.4298 - val_acc: 0.8211\n",
      "Epoch 482/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4233 - acc: 0.8228 - val_loss: 0.4295 - val_acc: 0.8215\n",
      "Epoch 483/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4235 - acc: 0.8231 - val_loss: 0.4300 - val_acc: 0.8203\n",
      "Epoch 484/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 485/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4234 - acc: 0.8229 - val_loss: 0.4299 - val_acc: 0.8211\n",
      "Epoch 486/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8232 - val_loss: 0.4297 - val_acc: 0.8207\n",
      "Epoch 487/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4233 - acc: 0.8232 - val_loss: 0.4299 - val_acc: 0.8211\n",
      "Epoch 488/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4233 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 489/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4233 - acc: 0.8232 - val_loss: 0.4298 - val_acc: 0.8207\n",
      "Epoch 490/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4233 - acc: 0.8232 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 491/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4233 - acc: 0.8236 - val_loss: 0.4302 - val_acc: 0.8211\n",
      "Epoch 492/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4232 - acc: 0.8219 - val_loss: 0.4299 - val_acc: 0.8215\n",
      "Epoch 493/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4233 - acc: 0.8220 - val_loss: 0.4300 - val_acc: 0.8203\n",
      "Epoch 494/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4232 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 495/1000\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4233 - acc: 0.8235 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 496/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4233 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 497/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4232 - acc: 0.8231 - val_loss: 0.4299 - val_acc: 0.8203\n",
      "Epoch 498/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4232 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 499/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4232 - acc: 0.8232 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 500/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4232 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8215\n",
      "Epoch 501/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4231 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8215\n",
      "Epoch 502/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4232 - acc: 0.8228 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 503/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4231 - acc: 0.8233 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 504/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4231 - acc: 0.8225 - val_loss: 0.4306 - val_acc: 0.8199\n",
      "Epoch 505/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4231 - acc: 0.8231 - val_loss: 0.4301 - val_acc: 0.8215\n",
      "Epoch 506/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4231 - acc: 0.8228 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 507/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4232 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 508/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4231 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 509/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4231 - acc: 0.8225 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 510/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4231 - acc: 0.8233 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 511/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4231 - acc: 0.8225 - val_loss: 0.4303 - val_acc: 0.8215\n",
      "Epoch 512/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4231 - acc: 0.8227 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 513/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4230 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 514/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4230 - acc: 0.8223 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 515/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4230 - acc: 0.8232 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 516/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4230 - acc: 0.8228 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 517/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4229 - acc: 0.8235 - val_loss: 0.4299 - val_acc: 0.8219\n",
      "Epoch 518/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4229 - acc: 0.8225 - val_loss: 0.4311 - val_acc: 0.8207\n",
      "Epoch 519/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4230 - acc: 0.8228 - val_loss: 0.4302 - val_acc: 0.8219\n",
      "Epoch 520/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4229 - acc: 0.8219 - val_loss: 0.4299 - val_acc: 0.8211\n",
      "Epoch 521/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4230 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 522/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4228 - acc: 0.8228 - val_loss: 0.4311 - val_acc: 0.8199\n",
      "Epoch 523/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4230 - acc: 0.8228 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 524/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4229 - acc: 0.8231 - val_loss: 0.4302 - val_acc: 0.8199\n",
      "Epoch 525/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4229 - acc: 0.8233 - val_loss: 0.4307 - val_acc: 0.8195\n",
      "Epoch 526/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4229 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 527/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4229 - acc: 0.8231 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 528/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4229 - acc: 0.8224 - val_loss: 0.4306 - val_acc: 0.8195\n",
      "Epoch 529/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4229 - acc: 0.8232 - val_loss: 0.4308 - val_acc: 0.8195\n",
      "Epoch 530/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4229 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 531/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4229 - acc: 0.8235 - val_loss: 0.4303 - val_acc: 0.8215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8231 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 533/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8243 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 534/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8199\n",
      "Epoch 535/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4228 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8211\n",
      "Epoch 536/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4228 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8195\n",
      "Epoch 537/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8228 - val_loss: 0.4299 - val_acc: 0.8219\n",
      "Epoch 538/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8235 - val_loss: 0.4307 - val_acc: 0.8195\n",
      "Epoch 539/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4228 - acc: 0.8236 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 540/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8223 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 541/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4228 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 542/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8232 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 543/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4228 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 544/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8232 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 545/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 546/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8233 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 547/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4228 - acc: 0.8227 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 548/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8236 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 549/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8237 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 550/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8237 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 551/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8233 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 552/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8232 - val_loss: 0.4306 - val_acc: 0.8199\n",
      "Epoch 553/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8241 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 554/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4227 - acc: 0.8233 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 555/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4227 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 556/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8191\n",
      "Epoch 557/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4225 - acc: 0.8229 - val_loss: 0.4310 - val_acc: 0.8211\n",
      "Epoch 558/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8232 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 559/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4227 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 560/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4226 - acc: 0.8232 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 561/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4226 - acc: 0.8237 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 562/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 563/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8235 - val_loss: 0.4309 - val_acc: 0.8211\n",
      "Epoch 564/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4225 - acc: 0.8233 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 565/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4226 - acc: 0.8235 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 566/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4225 - acc: 0.8237 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 567/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4224 - acc: 0.8235 - val_loss: 0.4312 - val_acc: 0.8203\n",
      "Epoch 568/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4225 - acc: 0.8228 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 569/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8237 - val_loss: 0.4309 - val_acc: 0.8207\n",
      "Epoch 570/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4225 - acc: 0.8232 - val_loss: 0.4309 - val_acc: 0.8215\n",
      "Epoch 571/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8247 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 572/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8232 - val_loss: 0.4309 - val_acc: 0.8215\n",
      "Epoch 573/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4224 - acc: 0.8233 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 574/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4225 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8215\n",
      "Epoch 575/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4224 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8211\n",
      "Epoch 576/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4224 - acc: 0.8239 - val_loss: 0.4307 - val_acc: 0.8207\n",
      "Epoch 577/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4224 - acc: 0.8235 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 578/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4224 - acc: 0.8243 - val_loss: 0.4303 - val_acc: 0.8215\n",
      "Epoch 579/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4224 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 580/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4224 - acc: 0.8237 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 581/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4223 - acc: 0.8240 - val_loss: 0.4300 - val_acc: 0.8215\n",
      "Epoch 582/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4223 - acc: 0.8240 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 583/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4222 - acc: 0.8241 - val_loss: 0.4309 - val_acc: 0.8215\n",
      "Epoch 584/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8235 - val_loss: 0.4307 - val_acc: 0.8211\n",
      "Epoch 585/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8237 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 586/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8231 - val_loss: 0.4306 - val_acc: 0.8215\n",
      "Epoch 587/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8233 - val_loss: 0.4313 - val_acc: 0.8211\n",
      "Epoch 588/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4223 - acc: 0.8232 - val_loss: 0.4302 - val_acc: 0.8219\n",
      "Epoch 589/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4223 - acc: 0.8235 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 590/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4223 - acc: 0.8241 - val_loss: 0.4305 - val_acc: 0.8215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4222 - acc: 0.8235 - val_loss: 0.4312 - val_acc: 0.8223\n",
      "Epoch 592/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4223 - acc: 0.8244 - val_loss: 0.4304 - val_acc: 0.8215\n",
      "Epoch 593/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4222 - acc: 0.8243 - val_loss: 0.4306 - val_acc: 0.8215\n",
      "Epoch 594/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8237 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 595/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8215\n",
      "Epoch 596/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8236 - val_loss: 0.4299 - val_acc: 0.8211\n",
      "Epoch 597/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8243 - val_loss: 0.4303 - val_acc: 0.8215\n",
      "Epoch 598/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 599/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8215\n",
      "Epoch 600/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4222 - acc: 0.8236 - val_loss: 0.4300 - val_acc: 0.8219\n",
      "Epoch 601/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8237 - val_loss: 0.4307 - val_acc: 0.8211\n",
      "Epoch 602/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 603/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4221 - acc: 0.8236 - val_loss: 0.4309 - val_acc: 0.8211\n",
      "Epoch 604/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4222 - acc: 0.8236 - val_loss: 0.4305 - val_acc: 0.8211\n",
      "Epoch 605/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4221 - acc: 0.8240 - val_loss: 0.4300 - val_acc: 0.8219\n",
      "Epoch 606/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8240 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 607/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8239 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 608/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8240 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 609/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8240 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 610/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8235 - val_loss: 0.4308 - val_acc: 0.8211\n",
      "Epoch 611/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4220 - acc: 0.8237 - val_loss: 0.4300 - val_acc: 0.8219\n",
      "Epoch 612/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4221 - acc: 0.8232 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 613/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8240 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 614/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4220 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 615/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4221 - acc: 0.8236 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 616/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8241 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 617/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8236 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 618/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4219 - acc: 0.8237 - val_loss: 0.4304 - val_acc: 0.8227\n",
      "Epoch 619/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8235 - val_loss: 0.4311 - val_acc: 0.8211\n",
      "Epoch 620/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8223\n",
      "Epoch 621/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4220 - acc: 0.8232 - val_loss: 0.4309 - val_acc: 0.8211\n",
      "Epoch 622/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4220 - acc: 0.8241 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 623/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8237 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 624/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4220 - acc: 0.8239 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 625/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4218 - acc: 0.8244 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 626/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4220 - acc: 0.8233 - val_loss: 0.4300 - val_acc: 0.8203\n",
      "Epoch 627/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8239 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 628/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8239 - val_loss: 0.4301 - val_acc: 0.8211\n",
      "Epoch 629/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8245 - val_loss: 0.4300 - val_acc: 0.8219\n",
      "Epoch 630/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8229 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 631/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4219 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 632/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4219 - acc: 0.8245 - val_loss: 0.4306 - val_acc: 0.8215\n",
      "Epoch 633/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8237 - val_loss: 0.4314 - val_acc: 0.8231\n",
      "Epoch 634/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 635/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8239 - val_loss: 0.4310 - val_acc: 0.8211\n",
      "Epoch 636/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8240 - val_loss: 0.4309 - val_acc: 0.8211\n",
      "Epoch 637/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4217 - acc: 0.8240 - val_loss: 0.4297 - val_acc: 0.8219\n",
      "Epoch 638/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4218 - acc: 0.8236 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 639/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4219 - acc: 0.8239 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 640/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4218 - acc: 0.8241 - val_loss: 0.4308 - val_acc: 0.8211\n",
      "Epoch 641/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8237 - val_loss: 0.4298 - val_acc: 0.8223\n",
      "Epoch 642/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4219 - acc: 0.8235 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 643/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8241 - val_loss: 0.4308 - val_acc: 0.8211\n",
      "Epoch 644/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8243 - val_loss: 0.4306 - val_acc: 0.8215\n",
      "Epoch 645/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4218 - acc: 0.8235 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 646/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4218 - acc: 0.8239 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 647/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4218 - acc: 0.8237 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 648/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4218 - acc: 0.8236 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 649/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8235 - val_loss: 0.4310 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4217 - acc: 0.8229 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 651/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8228 - val_loss: 0.4310 - val_acc: 0.8207\n",
      "Epoch 652/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8240 - val_loss: 0.4298 - val_acc: 0.8219\n",
      "Epoch 653/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8233 - val_loss: 0.4298 - val_acc: 0.8215\n",
      "Epoch 654/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4217 - acc: 0.8243 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 655/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4217 - acc: 0.8237 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 656/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8244 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 657/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8231 - val_loss: 0.4306 - val_acc: 0.8211\n",
      "Epoch 658/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 659/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8233 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 660/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8236 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 661/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4216 - acc: 0.8237 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 662/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4217 - acc: 0.8235 - val_loss: 0.4306 - val_acc: 0.8211\n",
      "Epoch 663/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4217 - acc: 0.8236 - val_loss: 0.4310 - val_acc: 0.8199\n",
      "Epoch 664/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4217 - acc: 0.8237 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 665/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8240 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 666/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4217 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 667/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8233 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 668/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8241 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 669/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8240 - val_loss: 0.4303 - val_acc: 0.8231\n",
      "Epoch 670/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8233 - val_loss: 0.4313 - val_acc: 0.8199\n",
      "Epoch 671/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4216 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8211\n",
      "Epoch 672/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4216 - acc: 0.8233 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 673/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8232 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 674/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4216 - acc: 0.8232 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 675/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4215 - acc: 0.8235 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 676/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8233 - val_loss: 0.4307 - val_acc: 0.8207\n",
      "Epoch 677/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8243 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 678/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8235 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 679/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8229 - val_loss: 0.4300 - val_acc: 0.8207\n",
      "Epoch 680/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4214 - acc: 0.8237 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 681/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4215 - acc: 0.8235 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 682/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8229 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 683/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8235 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 684/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4215 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 685/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4213 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 686/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4215 - acc: 0.8235 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 687/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4215 - acc: 0.8228 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 688/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4215 - acc: 0.8240 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 689/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8235 - val_loss: 0.4309 - val_acc: 0.8207\n",
      "Epoch 690/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4214 - acc: 0.8236 - val_loss: 0.4313 - val_acc: 0.8199\n",
      "Epoch 691/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4215 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 692/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8237 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 693/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4214 - acc: 0.8232 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 694/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8237 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 695/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 696/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8235 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 697/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8233 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 698/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8235 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 699/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8231 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 700/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4213 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8219\n",
      "Epoch 701/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 702/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8233 - val_loss: 0.4302 - val_acc: 0.8215\n",
      "Epoch 703/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8235 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 704/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8233 - val_loss: 0.4315 - val_acc: 0.8215\n",
      "Epoch 705/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4214 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 706/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4214 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 707/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 708/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 710/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4214 - acc: 0.8236 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 711/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 712/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8232 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 713/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 714/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8239 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 715/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8240 - val_loss: 0.4306 - val_acc: 0.8199\n",
      "Epoch 716/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 717/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8237 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 718/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.8235 - val_loss: 0.4309 - val_acc: 0.8199\n",
      "Epoch 719/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4212 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 720/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8237 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 721/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4212 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 722/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4211 - acc: 0.8235 - val_loss: 0.4302 - val_acc: 0.8211\n",
      "Epoch 723/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4213 - acc: 0.8237 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 724/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8232 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 725/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4213 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 726/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8223 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 727/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 728/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 729/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8225 - val_loss: 0.4311 - val_acc: 0.8207\n",
      "Epoch 730/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4212 - acc: 0.8229 - val_loss: 0.4311 - val_acc: 0.8207\n",
      "Epoch 731/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 732/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8211\n",
      "Epoch 733/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4212 - acc: 0.8231 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 734/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8235 - val_loss: 0.4311 - val_acc: 0.8203\n",
      "Epoch 735/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8237 - val_loss: 0.4314 - val_acc: 0.8199\n",
      "Epoch 736/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4212 - acc: 0.8236 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 737/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8231 - val_loss: 0.4302 - val_acc: 0.8215\n",
      "Epoch 738/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4211 - acc: 0.8231 - val_loss: 0.4312 - val_acc: 0.8203\n",
      "Epoch 739/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8221 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 740/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4211 - acc: 0.8239 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 741/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4212 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 742/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4211 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 743/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4210 - acc: 0.8227 - val_loss: 0.4314 - val_acc: 0.8207\n",
      "Epoch 744/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4211 - acc: 0.8231 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 745/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4210 - acc: 0.8236 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 746/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4210 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8211\n",
      "Epoch 747/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4210 - acc: 0.8240 - val_loss: 0.4301 - val_acc: 0.8215\n",
      "Epoch 748/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4210 - acc: 0.8225 - val_loss: 0.4307 - val_acc: 0.8211\n",
      "Epoch 749/1000\n",
      "7477/7477 [==============================] - 0s 41us/step - loss: 0.4211 - acc: 0.8231 - val_loss: 0.4307 - val_acc: 0.8211\n",
      "Epoch 750/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4211 - acc: 0.8229 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 751/1000\n",
      "7477/7477 [==============================] - 0s 23us/step - loss: 0.4210 - acc: 0.8240 - val_loss: 0.4303 - val_acc: 0.8207\n",
      "Epoch 752/1000\n",
      "7477/7477 [==============================] - 0s 22us/step - loss: 0.4211 - acc: 0.8235 - val_loss: 0.4307 - val_acc: 0.8211\n",
      "Epoch 753/1000\n",
      "7477/7477 [==============================] - 0s 46us/step - loss: 0.4210 - acc: 0.8231 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 754/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4209 - acc: 0.8227 - val_loss: 0.4314 - val_acc: 0.8207\n",
      "Epoch 755/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4210 - acc: 0.8233 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 756/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8237 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 757/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8235 - val_loss: 0.4306 - val_acc: 0.8211\n",
      "Epoch 758/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8239 - val_loss: 0.4301 - val_acc: 0.8219\n",
      "Epoch 759/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4210 - acc: 0.8231 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 760/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8215\n",
      "Epoch 761/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4210 - acc: 0.8221 - val_loss: 0.4314 - val_acc: 0.8219\n",
      "Epoch 762/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4209 - acc: 0.8228 - val_loss: 0.4309 - val_acc: 0.8207\n",
      "Epoch 763/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8233 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 764/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4210 - acc: 0.8240 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 765/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4210 - acc: 0.8233 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 766/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4210 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 767/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4209 - acc: 0.8235 - val_loss: 0.4309 - val_acc: 0.8211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 769/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8233 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 770/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4208 - acc: 0.8239 - val_loss: 0.4317 - val_acc: 0.8211\n",
      "Epoch 771/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4210 - acc: 0.8229 - val_loss: 0.4307 - val_acc: 0.8215\n",
      "Epoch 772/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 773/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4209 - acc: 0.8233 - val_loss: 0.4307 - val_acc: 0.8215\n",
      "Epoch 774/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4208 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8211\n",
      "Epoch 775/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4209 - acc: 0.8231 - val_loss: 0.4306 - val_acc: 0.8211\n",
      "Epoch 776/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4209 - acc: 0.8231 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 777/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4209 - acc: 0.8232 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 778/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4209 - acc: 0.8235 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 779/1000\n",
      "7477/7477 [==============================] - 0s 37us/step - loss: 0.4209 - acc: 0.8225 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 780/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4208 - acc: 0.8231 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 781/1000\n",
      "7477/7477 [==============================] - 0s 39us/step - loss: 0.4209 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 782/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4208 - acc: 0.8235 - val_loss: 0.4304 - val_acc: 0.8211\n",
      "Epoch 783/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4208 - acc: 0.8236 - val_loss: 0.4312 - val_acc: 0.8215\n",
      "Epoch 784/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4209 - acc: 0.8224 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 785/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4208 - acc: 0.8236 - val_loss: 0.4301 - val_acc: 0.8207\n",
      "Epoch 786/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4208 - acc: 0.8228 - val_loss: 0.4311 - val_acc: 0.8207\n",
      "Epoch 787/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4208 - acc: 0.8227 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 788/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4208 - acc: 0.8223 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 789/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4208 - acc: 0.8229 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 790/1000\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4208 - acc: 0.8227 - val_loss: 0.4309 - val_acc: 0.8207\n",
      "Epoch 791/1000\n",
      "7477/7477 [==============================] - 0s 37us/step - loss: 0.4207 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 792/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4208 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 793/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4208 - acc: 0.8232 - val_loss: 0.4313 - val_acc: 0.8203\n",
      "Epoch 794/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4208 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 795/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8232 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 796/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8233 - val_loss: 0.4305 - val_acc: 0.8215\n",
      "Epoch 797/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4208 - acc: 0.8224 - val_loss: 0.4309 - val_acc: 0.8219\n",
      "Epoch 798/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4208 - acc: 0.8225 - val_loss: 0.4307 - val_acc: 0.8215\n",
      "Epoch 799/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8229 - val_loss: 0.4309 - val_acc: 0.8219\n",
      "Epoch 800/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 801/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 802/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 803/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4208 - acc: 0.8229 - val_loss: 0.4307 - val_acc: 0.8207\n",
      "Epoch 804/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8229 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 805/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 806/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8227 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 807/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8223 - val_loss: 0.4313 - val_acc: 0.8203\n",
      "Epoch 808/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4207 - acc: 0.8229 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 809/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8211\n",
      "Epoch 810/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 811/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8236 - val_loss: 0.4311 - val_acc: 0.8199\n",
      "Epoch 812/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8229 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 813/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8228 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 814/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8231 - val_loss: 0.4310 - val_acc: 0.8199\n",
      "Epoch 815/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 816/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8228 - val_loss: 0.4314 - val_acc: 0.8207\n",
      "Epoch 817/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 818/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8228 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 819/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8232 - val_loss: 0.4314 - val_acc: 0.8199\n",
      "Epoch 820/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8223 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 821/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 822/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8223 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 823/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8232 - val_loss: 0.4317 - val_acc: 0.8199\n",
      "Epoch 824/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4207 - acc: 0.8227 - val_loss: 0.4310 - val_acc: 0.8199\n",
      "Epoch 825/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 826/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4205 - acc: 0.8225 - val_loss: 0.4301 - val_acc: 0.8207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8224 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 828/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8225 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 829/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 830/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8233 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 831/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8232 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 832/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 833/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4206 - acc: 0.8224 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 834/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4205 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 835/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8224 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 836/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4206 - acc: 0.8224 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 837/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4205 - acc: 0.8225 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 838/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8236 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 839/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8225 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 840/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4206 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 841/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4205 - acc: 0.8231 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 842/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8224 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 843/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4203 - acc: 0.8224 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 844/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 845/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8227 - val_loss: 0.4312 - val_acc: 0.8199\n",
      "Epoch 846/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8228 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 847/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4205 - acc: 0.8224 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 848/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8227 - val_loss: 0.4310 - val_acc: 0.8199\n",
      "Epoch 849/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 850/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 851/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8227 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 852/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8228 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 853/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 854/1000\n",
      "7477/7477 [==============================] - 0s 23us/step - loss: 0.4205 - acc: 0.8225 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 855/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8232 - val_loss: 0.4324 - val_acc: 0.8195\n",
      "Epoch 856/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4206 - acc: 0.8231 - val_loss: 0.4310 - val_acc: 0.8211\n",
      "Epoch 857/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8224 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 858/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 859/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8228 - val_loss: 0.4309 - val_acc: 0.8207\n",
      "Epoch 860/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8232 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 861/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8231 - val_loss: 0.4309 - val_acc: 0.8207\n",
      "Epoch 862/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8223 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 863/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8227 - val_loss: 0.4299 - val_acc: 0.8211\n",
      "Epoch 864/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8220 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 865/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8227 - val_loss: 0.4315 - val_acc: 0.8203\n",
      "Epoch 866/1000\n",
      "7477/7477 [==============================] - 0s 23us/step - loss: 0.4204 - acc: 0.8229 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 867/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8221 - val_loss: 0.4307 - val_acc: 0.8199\n",
      "Epoch 868/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8232 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 869/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4204 - acc: 0.8223 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 870/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8232 - val_loss: 0.4301 - val_acc: 0.8203\n",
      "Epoch 871/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4205 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 872/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4204 - acc: 0.8229 - val_loss: 0.4306 - val_acc: 0.8199\n",
      "Epoch 873/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8229 - val_loss: 0.4315 - val_acc: 0.8195\n",
      "Epoch 874/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8225 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 875/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8231 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 876/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8233 - val_loss: 0.4312 - val_acc: 0.8203\n",
      "Epoch 877/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4203 - acc: 0.8224 - val_loss: 0.4311 - val_acc: 0.8203\n",
      "Epoch 878/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8231 - val_loss: 0.4300 - val_acc: 0.8199\n",
      "Epoch 879/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8231 - val_loss: 0.4315 - val_acc: 0.8219\n",
      "Epoch 880/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4203 - acc: 0.8221 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 881/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 882/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8217 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 883/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 884/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4202 - acc: 0.8231 - val_loss: 0.4300 - val_acc: 0.8199\n",
      "Epoch 885/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4203 - acc: 0.8216 - val_loss: 0.4310 - val_acc: 0.8207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8225 - val_loss: 0.4312 - val_acc: 0.8215\n",
      "Epoch 887/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8215 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 888/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8217 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 889/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8229 - val_loss: 0.4312 - val_acc: 0.8211\n",
      "Epoch 890/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 891/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8229 - val_loss: 0.4314 - val_acc: 0.8203\n",
      "Epoch 892/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8227 - val_loss: 0.4312 - val_acc: 0.8203\n",
      "Epoch 893/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8195\n",
      "Epoch 894/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8225 - val_loss: 0.4315 - val_acc: 0.8195\n",
      "Epoch 895/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4203 - acc: 0.8227 - val_loss: 0.4307 - val_acc: 0.8207\n",
      "Epoch 896/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8220 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 897/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8224 - val_loss: 0.4302 - val_acc: 0.8203\n",
      "Epoch 898/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8228 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 899/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8225 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 900/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8236 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 901/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8232 - val_loss: 0.4312 - val_acc: 0.8207\n",
      "Epoch 902/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8220 - val_loss: 0.4313 - val_acc: 0.8203\n",
      "Epoch 903/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8227 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 904/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8227 - val_loss: 0.4313 - val_acc: 0.8215\n",
      "Epoch 905/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4202 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 906/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4202 - acc: 0.8231 - val_loss: 0.4312 - val_acc: 0.8203\n",
      "Epoch 907/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8225 - val_loss: 0.4307 - val_acc: 0.8211\n",
      "Epoch 908/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8228 - val_loss: 0.4318 - val_acc: 0.8195\n",
      "Epoch 909/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8219 - val_loss: 0.4311 - val_acc: 0.8215\n",
      "Epoch 910/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8221 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 911/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8232 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 912/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8232 - val_loss: 0.4303 - val_acc: 0.8199\n",
      "Epoch 913/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8227 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 914/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8224 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 915/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 916/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4201 - acc: 0.8227 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 917/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8223 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 918/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4200 - acc: 0.8233 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 919/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8224 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 920/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 921/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4199 - acc: 0.8224 - val_loss: 0.4299 - val_acc: 0.8207\n",
      "Epoch 922/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8232 - val_loss: 0.4314 - val_acc: 0.8203\n",
      "Epoch 923/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8229 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 924/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8231 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 925/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4201 - acc: 0.8231 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 926/1000\n",
      "7477/7477 [==============================] - 0s 24us/step - loss: 0.4200 - acc: 0.8221 - val_loss: 0.4312 - val_acc: 0.8203\n",
      "Epoch 927/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4200 - acc: 0.8224 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 928/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4200 - acc: 0.8228 - val_loss: 0.4311 - val_acc: 0.8215\n",
      "Epoch 929/1000\n",
      "7477/7477 [==============================] - 0s 31us/step - loss: 0.4200 - acc: 0.8224 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 930/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4199 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "Epoch 931/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4199 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 932/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4200 - acc: 0.8233 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 933/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4200 - acc: 0.8223 - val_loss: 0.4300 - val_acc: 0.8203\n",
      "Epoch 934/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4200 - acc: 0.8229 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 935/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4199 - acc: 0.8228 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "Epoch 936/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4200 - acc: 0.8233 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 937/1000\n",
      "7477/7477 [==============================] - 0s 40us/step - loss: 0.4199 - acc: 0.8229 - val_loss: 0.4303 - val_acc: 0.8203\n",
      "Epoch 938/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4200 - acc: 0.8224 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 939/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4200 - acc: 0.8229 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 940/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4199 - acc: 0.8231 - val_loss: 0.4308 - val_acc: 0.8207\n",
      "Epoch 941/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4200 - acc: 0.8225 - val_loss: 0.4307 - val_acc: 0.8199\n",
      "Epoch 942/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4199 - acc: 0.8225 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 943/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4199 - acc: 0.8233 - val_loss: 0.4305 - val_acc: 0.8199\n",
      "Epoch 944/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4198 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4199 - acc: 0.8232 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 946/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4199 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 947/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8228 - val_loss: 0.4309 - val_acc: 0.8199\n",
      "Epoch 948/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4199 - acc: 0.8233 - val_loss: 0.4313 - val_acc: 0.8199\n",
      "Epoch 949/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4198 - acc: 0.8225 - val_loss: 0.4301 - val_acc: 0.8191\n",
      "Epoch 950/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8225 - val_loss: 0.4307 - val_acc: 0.8207\n",
      "Epoch 951/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4198 - acc: 0.8239 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 952/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4199 - acc: 0.8227 - val_loss: 0.4304 - val_acc: 0.8195\n",
      "Epoch 953/1000\n",
      "7477/7477 [==============================] - 0s 47us/step - loss: 0.4199 - acc: 0.8227 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 954/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4199 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8207\n",
      "Epoch 955/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8236 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 956/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4197 - acc: 0.8228 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 957/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4199 - acc: 0.8231 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 958/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4198 - acc: 0.8233 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 959/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4198 - acc: 0.8227 - val_loss: 0.4302 - val_acc: 0.8207\n",
      "Epoch 960/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4197 - acc: 0.8239 - val_loss: 0.4300 - val_acc: 0.8199\n",
      "Epoch 961/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4198 - acc: 0.8231 - val_loss: 0.4309 - val_acc: 0.8203\n",
      "Epoch 962/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8232 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 963/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4198 - acc: 0.8228 - val_loss: 0.4306 - val_acc: 0.8199\n",
      "Epoch 964/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4197 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8199\n",
      "Epoch 965/1000\n",
      "7477/7477 [==============================] - 0s 35us/step - loss: 0.4198 - acc: 0.8233 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 966/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4197 - acc: 0.8228 - val_loss: 0.4309 - val_acc: 0.8199\n",
      "Epoch 967/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4197 - acc: 0.8232 - val_loss: 0.4308 - val_acc: 0.8203\n",
      "Epoch 968/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8232 - val_loss: 0.4301 - val_acc: 0.8199\n",
      "Epoch 969/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4197 - acc: 0.8228 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 970/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4197 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8207\n",
      "Epoch 971/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4197 - acc: 0.8229 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 972/1000\n",
      "7477/7477 [==============================] - 0s 32us/step - loss: 0.4197 - acc: 0.8232 - val_loss: 0.4304 - val_acc: 0.8199\n",
      "Epoch 973/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4196 - acc: 0.8229 - val_loss: 0.4299 - val_acc: 0.8187\n",
      "Epoch 974/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4196 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8207\n",
      "Epoch 975/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8231 - val_loss: 0.4306 - val_acc: 0.8203\n",
      "Epoch 976/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4197 - acc: 0.8227 - val_loss: 0.4301 - val_acc: 0.8191\n",
      "Epoch 977/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4196 - acc: 0.8239 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 978/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4195 - acc: 0.8227 - val_loss: 0.4303 - val_acc: 0.8195\n",
      "Epoch 979/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4197 - acc: 0.8224 - val_loss: 0.4299 - val_acc: 0.8191\n",
      "Epoch 980/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8227 - val_loss: 0.4298 - val_acc: 0.8207\n",
      "Epoch 981/1000\n",
      "7477/7477 [==============================] - 0s 30us/step - loss: 0.4196 - acc: 0.8232 - val_loss: 0.4307 - val_acc: 0.8203\n",
      "Epoch 982/1000\n",
      "7477/7477 [==============================] - 0s 29us/step - loss: 0.4195 - acc: 0.8223 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "Epoch 983/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8229 - val_loss: 0.4299 - val_acc: 0.8191\n",
      "Epoch 984/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4195 - acc: 0.8231 - val_loss: 0.4298 - val_acc: 0.8195\n",
      "Epoch 985/1000\n",
      "7477/7477 [==============================] - 0s 38us/step - loss: 0.4196 - acc: 0.8232 - val_loss: 0.4302 - val_acc: 0.8195\n",
      "Epoch 986/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8199\n",
      "Epoch 987/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4195 - acc: 0.8233 - val_loss: 0.4308 - val_acc: 0.8191\n",
      "Epoch 988/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4196 - acc: 0.8233 - val_loss: 0.4300 - val_acc: 0.8191\n",
      "Epoch 989/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4196 - acc: 0.8228 - val_loss: 0.4303 - val_acc: 0.8195\n",
      "Epoch 990/1000\n",
      "7477/7477 [==============================] - 0s 26us/step - loss: 0.4195 - acc: 0.8229 - val_loss: 0.4297 - val_acc: 0.8183\n",
      "Epoch 991/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4196 - acc: 0.8233 - val_loss: 0.4301 - val_acc: 0.8195\n",
      "Epoch 992/1000\n",
      "7477/7477 [==============================] - 0s 27us/step - loss: 0.4195 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.8199\n",
      "Epoch 993/1000\n",
      "7477/7477 [==============================] - 0s 25us/step - loss: 0.4196 - acc: 0.8232 - val_loss: 0.4300 - val_acc: 0.8199\n",
      "Epoch 994/1000\n",
      "7477/7477 [==============================] - 0s 42us/step - loss: 0.4193 - acc: 0.8232 - val_loss: 0.4294 - val_acc: 0.8191\n",
      "Epoch 995/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4195 - acc: 0.8231 - val_loss: 0.4298 - val_acc: 0.8187\n",
      "Epoch 996/1000\n",
      "7477/7477 [==============================] - 0s 33us/step - loss: 0.4194 - acc: 0.8236 - val_loss: 0.4298 - val_acc: 0.8195\n",
      "Epoch 997/1000\n",
      "7477/7477 [==============================] - 0s 49us/step - loss: 0.4194 - acc: 0.8236 - val_loss: 0.4304 - val_acc: 0.8195\n",
      "Epoch 998/1000\n",
      "7477/7477 [==============================] - 0s 36us/step - loss: 0.4194 - acc: 0.8228 - val_loss: 0.4297 - val_acc: 0.8187\n",
      "Epoch 999/1000\n",
      "7477/7477 [==============================] - 0s 28us/step - loss: 0.4194 - acc: 0.8227 - val_loss: 0.4306 - val_acc: 0.8187\n",
      "Epoch 1000/1000\n",
      "7477/7477 [==============================] - 0s 34us/step - loss: 0.4194 - acc: 0.8225 - val_loss: 0.4304 - val_acc: 0.8199\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4854f669e8>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.820\n",
      "roc-auc is 0.791\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XmczfXix/HXx9i3sStL3CzZKmuq20UIra5SSaLUdfu1SGpQWRJZ25CEFpVCFwmhUsnSYouMfWfsDMMwY7bP749zZprRDIM585lzzvv5eHiY7znfOec93zlz3ufzXY21FhEREck5crkOICIiImmpnEVERHIYlbOIiEgOo3IWERHJYVTOIiIiOYzKWUREJIdROUvQMcYUMMbMMcZEGWP+5zpPsDLGTDLGDPZ+/S9jzOZMft+jxpilvk3nljGmsjHGGmNyZ3D/q8aYydmdS7KPyjnAGWN2GWNijDHRxpiD3jfEwufMc7Mx5kdjzClvYc0xxtQ6Z56ixph3jDF7vI+1zTtdKoPnNcaY7saYcGPMaWNMhDHmf8aYa33582ZSe6AsUNJae//lPpgxppn3jXTsObcvNcY86v36Ue88YefME2GMaXa5GTKRMfXr4JAx5uPk14ExZpEx5olzfpaZ53z/9d7bF51zuzHG7DDGbLicfNbaJdbaay7nMTIjGIpdAoPKOTjcba0tDNQF6gEvJd9hjLkJ+A74GigH/ANYCywzxlztnScv8ANQG2gDFAVuBo4BN2TwnKOA54DuQAmgOjALuPNiw2c0ergMlYAt1tqELMxyGuhsjKl8nm+PBHobY4pe7PNmkeTXQX2gEdA3g/mOADcbY0qmuq0LsCWdeZsAZYCrjTGNsjJsIPPBa1oCjMo5iFhrDwLf4inpZCOAT621o6y1p6y1kdbavsBvwKveeToDVwHtrLUbrLVJ1trD1tpB1tp55z6PMaYa8DTwkLX2R2vtWWvtGWvt59baYd55UkZr3uk0IxrvKO1pY8xWYKsx5n1jzBvnPM/Xxpie3q/LGWNmGGOOGGN2GmO6p7cMjDEDgf7Ag95R5OPGmFzGmL7GmN3GmMPGmE+NMaHe+ZNXLz5ujNkD/JjB4j0BTAIGZHA/wEbgV+D588yTOmuoN8sRb7a+xphc3vse9Y7M3zDGHPf+zLdn5nGttfuA+UCdDGaJw/NBqoP3uUKAB4DP05m3C54PdvO8X5/v56lnjFntXUMzDcif6r5mxpiIVNN9jDHbvfNuMMa0+/vDmTHeNT2bjDEtUt0Raoz50BhzwBizzxgz2BgTYoypCbwP3OT93Z/wzp/Puxz3eNcqvG+MKeC9r5QxZq4x5oQxJtIYsyT5d5DOz2eNZ23RDmPMUWPMyHN+X8uMMW8bYyKBV8/3ukulqzFmv/dneeE8y/ZGY8wv3pxrTaq1Md6/tcHe+6ONZ81YSWPM58aYk8aYFRf4UCkOqJyDiDGmAnA7sM07XRDPCDi97a5fArd5v24JLLDWRmfyqVoAEdba5ZeXmH8DjYFawBd4CtUAGGOKA62Aqd43wDl4Rvzlvc/fwxjT+twHtNYOAIYA06y1ha21HwKPev/dClwNFAbePedbmwI1gb89ZiqvA/cZY863erYf8LwxpsR55kk2Bgj1ZmqK50PSY6nubwxsBkrh+ZD1YfLyOR9jTEXgDuCP88z2qff5wPMzrwf2n/M4BfFsIvjc+6+D8axlSe858+Ip/M/wrEn5H3DfeZ5/O/AvPD//QGCyMebKVPc3Bnbg+dkHADNTLdNPgASgKp41Ra2AJ6y1G4EngV+9v/ti3vmH41mzU9f7PeXxfIADeAGIAErj2RTyMnC+cx63AxriWTvRFuiaTuYyeF4rj3Lh192tQDXvz9DHGNPy3Cc0xpQHvgEG41m2LwIzjDGlU83WAXjE+7NVwfMh8WPv/Bs5/4dKcUDlHBxmGWNOAXuBw/z1h1gCz2vgQDrfcwDPGx9AyQzmycjFzp+Rod6RfAywBM+b4r+897XH8ya7H88q2tLW2testXHW2h3ARLwjv0x4GHjLWrvD+wHkJTxFk3rV46vW2tPeLOnyrpl4H3jtPPOswbMZoff5AnlHqw8CL3nXaOwC3sTzBptst7V2orU2EU8hXYmnQDIyyztaXAr8jOdDSkY5fwFKeD9odMZT1ue6Fzjr/XnmArnJeLPFjUAe4B1rbby1djqw4jzP/z9r7X7vWpppwFbSbkI5nOqxpuH5kHKnMaYsng+gPby/r8PA22TwWvB+mPkP8Lz3tXYKz3JJnj8ez3Kt5H2uJfb8FyQY7n2cPcA7wEOp7ttvrR1jrU3wvo4y87ob6P051uEp09SPl6wTMM9aO8+7vL4HVuL5AJbsY2vtdmttFJ61JtuttQu9m3b+h+dDjOQgKufg8G9rbRGgGVCDv0r3OJCE583nXFcCR71fH8tgnoxc7PwZ2Zv8hfcNcSp/vTl15K/VrJWAct5Veie8BfQy5y+q1MoBu1NN78ZTNKm/fy+ZMxxobYy5/jzz9Af+zxhzxXnmKQXkTSdX+VTTB5O/sNae8X6ZZme/c/zbWlvMWlvJWvvU+T5oeH0GPINn9PZVOvd3Ab70ls1ZYCYZr9ouB+w7p9h2ZzAvxpjOxpg1qX6fdfjrdUsGj1UOz2shD3Ag1feOxzNaTU9poCCwKtX8C7y3A4zEs6bpO+/q6j4ZZfZK/TpJzpTefXDxr7tzHy9ZJeD+c17/t5D2b/BQqq9j0pk+3+tGHFA5BxFr7c94tou+4Z0+jWf1Vnp7LD+AZycwgIV4CqdQJp/qB6CCMabheeY5jedNMVl6RXXuCGUK0N4YUwnPKsIZ3tv3Aju9xZP8r4i19g4yZz+eN7hkV+FZLZr6DSxTl2+z1h7DM2IadJ55NuEpspfP81BH8Yzazs21LzM5sshnwFN4RmVnUt/h3UTSHOhkPEcBHMSzNuMOk/4e/AeA8uesdr8qvSf1/n4n4vlgUNK7+jkcSP296T3WfjyvhbNAqVSvhaLW2tre+c79PR7FU061U80f6t1xDu9aixestVcDdwM9U2/fTkfFdDIlO/e5M/O6O9/jJdsLfHbO679Q8v4d4p9UzsHnHeA2Y0zyTmF9gC7eHVmKGGOKG8+xpzfh2dYHnjfpvXi2Y9Xw7shS0hjzsjHmbwVord0KvAdMMZ4dffIaY/IbYzqkGnmsAe41xhQ0xlQFHr9QcGvtH3j2JP4A+NZae8J713LgpDGmt/EcwxxijKljMr/38BQ824H/YTyHFyVvk77ovbm93sKzLb/meeYZiGf7cbH07vSuqv4SeN37e6kE9ASy7dhWa+1OPNu6X0nn7kfw7L19DZ5ttXXxbLeNIP1Vr7/iKZ7uxpjcxph7yXhP/0J4iuwIgDHmMf6+81oZ72PlMcbcj2dZz7PWHsCzmv1N4zn8L5cxpooxpqn3+w7h+eCY1/szJuH5IPC2MaaM9/nKJ++vYIy5yxhT1ftB4CSQ6P2XkTDv31BFPEcrTDvPvJl53fXz/o3UxvN6Se/xJgN3G2Nae1/7+b1/dxXO89ySw6mcg4y19gie7Yf9vNNL8ezwcy+e0c1uPNufbvGWLN5Vli2BTcD3eN6kluNZzfh7Bk/VHc/OLWPx7Mm8Hc/OMnO897+NZ6/gQ3i2l6a3J3B6pnizfJHqZ0rEM6qpC+zEMxr6AM/ORJnxEZ4PIIu93x8LPJvJ7/0ba+1JPDtoZbjTl7f4PsNTRBl5Fs8ahh14thN/4c2abay1S73b9c/VBXjPWnsw9T8829z/tmrbWhuH5zX2KJ7NKQ/iWXuQ3nNuwLN9/Vc8r49rgWXnzPY7nh2ljuLZuaq9d60FeLaR5wU2eJ9rOn+t4v0Rz85tB40xyZtteuNZdf2bMeYknjVFyTv1VfNOR3vzvGetXZRebq+vgVV4Pnx+A3x4nnkz87r72ZvtB+ANa+135z6ItXYvnp3PXsbzgWYvEIbe3/2aOf++DSIikhnGGAtUs9Zuc51F/J8+WYmIiOQwKmcREZEcRqu1RUREchiNnEVERHIYlbOIiEgOc8EroxhjPgLuAg5ba/92onzv8X+j8Jwq7gzwqLV29YUet1SpUrZy5cop06dPn6ZQocye40Iulpavb2n5+o6WrW9p+frOuct21apVR621pc/zLSkyc9mySXiOV03v3LrgOY9tNe+/xsA47//nVblyZVauXJkyvWjRIpo1a5aJOHIptHx9S8vXd7RsfUvL13fOXbbGmAxPWXuuC67WttYuxnMd2oy0xXPJQWut/Q0ods7VY0REROQiZMUFv8uT9uTsEd7bsuKqRCIiIjlSXFwcgwcPJioqKt37T58+fclrJbKinNO7fmy6x2cZY7oB3QDKli3LokWLUu6Ljo5OMy1ZS8vXt7R8fUfL1re0fC9eQkICu3bt4tlnnyU2NhaAwoX/urCXtZa4uDgqVKhwycs2K8o5grRXTqlA+ldOwVo7AZgA0LBhQ5v6E4W2e/iWlq9vafn6jpatb2n5Zmzfvn2sX78+zW3Hjh2jY8eOKdMNGzZk3rx5lC7t2c8rKSmJjRs3kjdvXvbt2+d05DwbeMYYMxXPjmBR3ivDiIiI+I2EhARGjRrFiROeC94NHjw4w3mbNm3KI488QteuXUm+eqm1lpdeeolHHnmEatWqsW/fpV/hNTOHUk0BmgGljDERwAA8FzPHWvs+MA/PYVTb8BxK9dglpxEREXHg3XffZeDAgRw96rlYWa5cnv2lmzdvzqBBaS/Pnj9/furWrZsyD0B8fDzLli2jT58+FC9e/LLzXLCcrbXpXZs19f0WePqyk4iIiGSRvXv3Zjhy7dmzJ7/++iu5c/9VgQkJnstot2nThg8++IDy5ctf1PMNGjSIzp07Z0kxQ9as1hYREckxjh49ylVXXXXB+Xr16pVm+u677+bGG2+8qOc6e/YsM2bMYMCAAYSEhFzU956PyllERPzWvHnzGD9+fJrbZs+eDXjK9qmnnkr3++rVq0fZsmUv+/nfe+897rvvviwtZlA5i4iInzpz5gx33nknAHXr1k25/frrr6dChQrMmjUrzXbhrHT69GnGjx9Pz549ffL4KmcREfEra9asYfny5fTt2xeA++67j+nTp2drhlmzZqU5pCqrqZxFRMRvrF+/nnr16qW5bfLkydn2/FFRUQwZMoRhw4alHELlCypnERHJNvHx8Rw+fDjNbVOnTuWdd95Js/d0Rnbt2gVAWFgYPXr0oHjx4uTPn98XUf8mLi6O5cuX07t3b58WM6icRUQkiyxbtoyIiIjzzvP4449z+vTpdO/r3LnzBZ+jSZMm1KhRg5deeumSMl6qo0ePMmDAAN5++23y5s3r8+dTOYuIyAX99ttv5119HBMTw0cffZSpx8qTJw9jx45Nc1vt2rW5+eabLyujrxw7dozdu3czdOjQbClmUDmLiEgGYmNjad26NSdOnODPP/8EoGTJkunOm5SUROHChXn99de57bbbzvu4V199Nfny5cvyvL5w4MABBg8ezIgRIyhUqFC2Pa/KWURE0jhx4gS//vorvXv3Zt26dRhjaNu2LS1atODZZ591HS/bREREcPz4cUaOHEnBggWz9blVziIiAsAff/zB9OnTGTJkSJrbo6KiKFKkiKNUbhw4cIARI0YwYsSIbNvhLDWVs4iIADBy5EimTJkCeFY9f/HFF1SqVCnoinn79u2cOnWKkSNHOlv9rnIWEfFzcXFxrFq1iqSkpEx/z+HDh7n33nsB0lzysFatWn+7hnEwOXnyJOPGjWPo0KHkyZPHWQ6Vs4iIn5oxYwbbtm3j7bff5tChQ5f0GLVq1eK+++5Lmf7nP/+ZVfH8zoYNGzh06BAjR470+XHMF6JyFhHJYVasWMHgwYPPOxJOTExk/vz5aW777rvvLup5ChQoQFxcHM2bN7+knIEkISGBGTNm8PLLLzsvZlA5i4g4cebMGXbs2EH79u3Zu3dvmlWoUVFRANSvXz/D77fW0qBBA4YMGcK//vUv8ubNe0lXRlq0aNFFf0+gWb16NTt27KBfv36uo6RQOYuIONCpUye++uqrlOnnnnsuzf01a9bkv//9b3bHCjrWWlasWEG3bt1cR0lD5Swiko2SkpLo1asXS5cupVatWgwaNIhbb72V4sWLu44WdJYtW0Z4eHiO/BCkchYR8bHIyEgOHjzI3XffTUREBHFxcYBntJy8x7Rkr9OnT3P8+PEcN2JOpnIWEfGhVatW0bBhw5TpEiVK0L59e/r160eFChUcJgteCxcuZP369X/blJCTqJxFRHxgyZIlfPHFF7z//vsAdOnShVatWtGuXTsKFCjgOF3w2rlzJyVLlszRxQwqZxGRLHf27FmaNGkCeEbKjRs3ZtKkSW5DCXPnzmXPnj089dRTrqNckMpZRCSLnDhxgmXLljFr1iwAmjZtqkOVcoilS5fSqFEj7rrrLtdRMkXlLCJyGay1jBkzhv379zN8+PA0940fP95RKklt3rx5HD58mFtuucV1lExTOYuIpMNam2Z62rRpjBkz5m/zHT16lC1btqRMV6lShalTp1KiRAmuvvpqn+eU85s5cyatWrWicOHCrqNcFJWziIiXtZZ169YxY8YMXnvttXTnadmyZZrpq666iqpVq/Lmm29So0aN7IgpmbR48WLi4uL8rphB5SwikmLTpk1cf/31KdM9evSgWLFiKdM33XQTrVq1chFNLtKHH35Iu3btUnbM8zcqZxEJel9++SWTJk3ixIkTALz++uvcc8891KlTx3EyuRTh4eGUKlWKEiVKuI5yyXK5DiAi4kpiYiLh4eG8++67LFq0iISEBJo1a0bnzp1VzH5q1KhRFCxYkLZt27qOclk0chaRoHPgwAFmzZrFqFGj2Lx5MwC33HILS5YscZxMLsfevXupVatWQOyIp3IWkaDxyy+/MGbMGKZOnZrm9pkzZ1K3bl1HqeRyWWsZPnw4rVu35rbbbnMdJ0uonEUk4Fhr2bdvHwkJCQwcOJAFCxYQEhLCvn37AKhWrRrVq1fn448/pkiRIuTPn99xYrlU1loiIiK49dZbqVevnus4WUblLCIBZ/DgwfTv3z/NbY8//jgAjRo1ypGXCJSLZ61l4MCB3HnnnTRu3Nh1nCylchaRgLJy5cqUYp4wYQJ58uTh5ptvpnr16o6TSVZKSkpi/fr1dOrUiapVq7qOk+VUziLit3r37s3s2bMxxqTctnHjRgC6du3Kf/7zH1fRxIestfTt25cHH3wwIIsZVM4i4qc2b97MiBEjALj//vtTbq9Tpw433XQTzz//vKto4kMJCQksWrSI3r17Exoa6jqOz6icRcQvbN68mY8++oikpCTAc9gMwNixY/3iEoCSNYYMGcKDDz4Y0MUMKmcRyWESEhKIiIiga9eunDlzhlOnTlG0aFF+++03AAoWLJgyb9myZWnTpo2rqJKN4uLimDZtGn379iVXrsA/f5bKWURyhLi4OLp27crnn3+ectsVV1xBhQoVKFq0KK1ataJevXoMGzbMYUpxZeLEidx5551BUcygchYRh5KSknj//feJjIxk4sSJ7NmzB4BBgwYRGhrKU089xZIlS2jWrJnboOJMTEwM7777LmFhYa6jZCuVs4g4sX//flq2bJmyd3Wybdu2UaVKFUepJCex1jJnzhwefvhh11GyXXCsHxCRHMNay4YNG6hduzYbN26kTJkybNmyhfj4eBITE1XMAsCpU6cICwujffv2lCtXznWcbKeRs4hkm6NHj/L4448ze/bslNv27dtH7tx6K5K/xMbGsmrVKvr06RM025jPFZw/tYg4MWnSpJRinjhxIhERESpmSSMyMpKePXty4403UqpUKddxnNFfhYj4TFRUFO3bt2ft2rWEhIQQHR0NwIkTJwL+OFW5eMeOHWPPnj0MHTo06C9GonIWEZ84deoUxYoVS5nu1q0bAFWrVlUxy98cOnSI1157jWHDhlGkSBHXcZxTOYuIT9xxxx0A1KtXj7lz5wblTj2SOfv37+fo0aOMGDGCQoUKuY6TI2ibs4hkuT///JOlS5cCsHz5chWzZOjIkSMMGzaMatWqqZhT0chZRLLU/v37uf766wH47LPPtMOXZGjXrl0cO3aMkSNHki9fPtdxchSNnEUkyxw+fJjy5csDnlNvBuPJIyRzzpw5w5gxY7j22mtVzOnQR1oRyTJff/01ALVr12bFihVprrMskmzz5s3s2rWLN954Q6+RDKicReSynDlzht9++421a9fSs2dPAL7//nsKFCjgOJnkRImJiUyfPp3evXurmM9D5Swil2TLli1MnTqV4cOHc+bMmZTbe/XqxZVXXukwmeRUa9euJTw8nFdeecV1lBxP5Swil2T06NGMHTsWgMKFCzNv3jxCQ0O57rrrHCeTnCgpKYkVK1bQtWtX11H8gspZRDLl22+/pX379sTHxwMQHx/PFVdcwf79+wG0ilIy9Ntvv7FixQqeffZZ11H8hspZRC5oxYoVjBs3jujoaJ577rmUUys2aNBApSznderUKY4fP84zzzzjOopfUTmLSLqstbz44ovs2rWLmTNnAlCqVCmGDx+uQ18kUxYtWsTKlSt58cUXXUfxOypnEUkRHx/Pzp07OXbsGM2bNyc2NhbwHBr10EMPERYWRt68eR2nFH+wbds2SpQooWK+RCpnkSC3b98+vv32WwBefPFFjh8/nnJfjRo1WLBgAZUqVXIVT/zQggUL2LJlC927d3cdxW+pnEWC0JEjRxgwYAAxMTFMmjTpb/d//vnnFChQgLvuuos8efJkf0DxW4sXL6Z+/fq0adPGdRS/pnIWCRLHjh1L2dP6tttuIzw8HIDy5ctz3XXX8f777wNQtmxZbVOWS/Ldd9+xe/dumjRp4jqK31M5iwSo+Ph4vv32W2JjY5k7dy6ffPLJ3+aJi4vTyFiyxMyZM2nZsiWtWrVyHSUgqJxFAsiPP/7I7NmzAZg3bx5bt25Nc/+wYcMIDQ0FoFmzZipmyRK///47MTExFC1a1HWUgKFyFgkQp06dokWLFgCEhoYSHx9P4cKFmT9/PsWKFaNkyZI6raZkuY8//pg77riDxo0bu44SUFTOIn5u586dbN26lQkTJgDwwAMPMG3aNMepJBhs3bqVokWLUrZsWddRAo7KWcQPffDBB+zZsweAQYMGpblv1KhRLiJJkBk7diwtWrTgvvvucx0lIKmcRfxIdHQ07dq1Y+HChcBf57O+//776dGjB2XKlOGKK65wGVGCwMGDB6latSo1atRwHSVgqZxF/MhNN91EeHg4ISEhrFy5krp167qOJEHEWsubb75JkyZNaN26tes4AU3lLOJHTp48CcCJEycoXLiw4zQSTKy17Nu3j1tuuYUbbrjBdZyAl8t1ABHJnD59+nDkyBE6d+6sYpZsZa1l8ODB7N27lxtvvNF1nKCgkbNIDmatZevWrXTs2JFVq1YBaHWiZCtrLevWraNjx45UqVLFdZygoXIWyYE2btzI0qVLGTduHH/88UfK7Vu3bqVq1aoOk0mwefXVV2nbtq2KOZupnEVymB07dlCrVq00t02dOpUWLVpQqlQpR6kk2CQmJrJw4UJefPFFihQp4jpO0NE2ZxHHjhw5wv79+9m/fz9du3ZNGaF06tSJiIgIoqOjefDBB1XMkq1GjBhBxYoVVcyOaOQsks3i4uKYP38+sbGxfP3110yZMiXN/YUKFaJHjx4MGjQo5ThmkewSHx/P5MmT6d27N7lyafzmispZJBt9/PHHDBw4kN27d6e5/Y033qBIkSKEhITw73//m5IlSzpKKMFu0qRJNG/eXMXsmMpZJJucPn2arl27AlCsWDHmz59PaGgoJUuWpEyZMo7TSbCLjY3lzTff5OWXX9YamxwgUx+NjDFtjDGbjTHbjDF90rn/KmPMT8aYP4wxfxpj7sj6qCL+6+DBg3Tr1g2AF154gePHj3PjjTdSs2ZNFbM4Z61l/vz5dOnSRcWcQ1xw5GyMCQHGArcBEcAKY8xsa+2GVLP1Bb601o4zxtQC5gGVfZBXJMdasmQJCxYsSPe+IUOGpHzdvXv37IokckExMTH07NmTkSNHkju3VqbmFJn5TdwAbLPW7gAwxkwF2gKpy9kCyVfZDgX2Z2VIkZzs+++/JywsjLVr1wJk+AZ300038emnn3LVVVdlZzyRDMXExLBt2zZeeuklFXMOY6y155/BmPZAG2vtE97pR4DG1tpnUs1zJfAdUBwoBLS01q5K57G6Ad0AypYt22Dq1Kkp90VHR+uUhD6k5Zs1rLVs376dLVu2MHLkyDT31a1blxYtWnDXXXc5SheY9Nr1jejoaCZOnEinTp0oXbq06zgB6dzX7q233rrKWtswM9+bmY9K6W2AOLfRHwImWWvfNMbcBHxmjKljrU1K803WTgAmADRs2NA2a9Ys5b5FixaRelqylpZv1hgxYgS9e/dOmW7bti3XXXcdISEhDBgwwGGywKXXbtaLjIxk7969TJo0ibVr12r5+sjlvHYzU84RQMVU0xX4+2rrx4E2ANbaX40x+YFSwOFLSiWSA23YsCGlmCdNmsQ111xD48aNMcawaNEit+FEMuno0aMMGDCAIUOGEBoa6jqOZCAz5bwCqGaM+QewD+gAdDxnnj1AC2CSMaYmkB84kpVBRVxJSkpiy5YttGrVCoCBAwfSpUsXx6lELt7Bgwc5dOgQw4YN05m/crgLHkplrU0AngG+BTbi2St7vTHmNWPMPd7ZXgD+Y4xZC0wBHrUX2pgt4ge++eYbGjZsSM2aNdm3bx8A/fv3d5xK5OIdP36cQYMGUbVqVRWzH8jU7nnW2nl4Do9KfVv/VF9vAP6ZtdFE3Dp9+jR33303yZ8zp0yZQv369R2nErl4e/bsYf/+/bz11lvky5fPdRzJBJ2fTSSVgwcPcu2111KpUiVq1KiBtZaBAwdy+vRpOnToQPXq1V1HFLkoZ8+eZdSoUdSrV0/F7Ed0YJsIsGrVKrZs2cKWLVsIDw/ntttuo3z58uTJk4dOnTpRsGBB1xFFLtrWrVvZvHkzb7zxhs785WdUzhK04uLiGDBgAFFRUYwbNy7NfUOHDqVBgwaOkolcPmst06f1sel6AAAgAElEQVRPJywsTMXsh1TOErSee+453n//fQBCQ0Pp3r07Dz/8MIUKFaJChQqO04lcuvDwcFauXMlLL73kOopcIpWzBLzExEQWL17MmTNnUm4bPXo03333HQCHDx/WGZIkYCQlJbFy5Uo6d+7sOopcBpWzBKwPP/yQbdu2sXDhQlauXJnuPEuXLlUxS8BYuXIlixcvpmfPnq6jyGVSOUtAOnDgAE888USa2+bMmUPZsmVTpitWrMgVV1yR3dFEfCIqKorIyEief/5511EkC6icJSC99dZbALz77rs8/fTTjtOI+NaSJUtYtmwZffr0cR1FsoiOc5aAtGTJEgAee+wxx0lEfGvz5s2UKFEizQVZxP+pnCUgrVq1irJly+r4ZAloCxcu5JtvvqF27do6XCrAqJwloIwbN448efKQkJBAsWLFXMcR8ZnFixdz3XXXaeevAKVyloCwdu1axo4dy1NPPUVCQgI9e/ZkxowZrmOJ+MSiRYvYsGEDZcqUcR1FfEQ7hInfOXbsGL169Upz3PLUqVNTvn788cd58803XUQT8bmvvvqKZs2a0axZM9dRxIdUzuJ3WrZsyZo1awBSLkRRtWpV7r33Xnr16kXJkiVdxhPxmTVr1nDy5EmKFy/uOor4mMpZ/Mq0adNSijk2NlZX2ZGg8dlnn9GsWTO6dOniOopkA5Wz+IUzZ84wYMAAfvnlFwB++eUXFbMEjT179pAvXz4qVqzoOopkE+0QJjleYmIiP//8M2+88QYbN26kUaNGNGzY0HUskWwxfvx4jh8/zgMPPOA6imQjjZwlR4qIiGD16tUAPPLII5w8eRKAWbNm0aRJE5fRRLLNkSNHuOqqq7j++utdR5FspnKWHOnxxx9PuWoUQEhICOPHj+emm25ymEok+7z99ts0atSI22+/3XUUcUDlLDlOYmIip0+fpmHDhowfPx6AmjVrUqBAAcfJRHzPWsu+ffu4+eabady4ses44oi2OUuOsWfPHu6//35y587NsmXLKF68OPXr16d+/foqZgkK1lqGDh3Kzp07VcxBTiNnyRFOnDhBpUqVUqZfe+01Wrdu7TCRSPay1rJmzRoeeugh/vGPf7iOI46pnMU5ay01a9YE4F//+heffvoplStXdhtKJJsNHjyYNm3aqJgFUDlLDnDy5EkOHjwIeK6ykzdvXseJRLJPUlIS8+bNo2fPnhQqVMh1HMkhtM1Zcoy33npLxSxB56233qJSpUoqZklDI2cREQcSEhL4+OOPeeGFF3QtZvkbjZzFqcTExJS9UvUGJcFk8uTJNG3aVK97SZdGzuLU3XffzebNmwFo27at4zQivnf27FmGDx9Ov379VMySIZWzOPPnn38yf/58AI4ePapLPUrAs9aycOFCunTpomKW89JqbXGmffv2gOc0hSpmCXRnzpzh+eef57bbbktzTL9IelTO4szWrVsB6NGjh+MkIr4VExPDunXr6NOnj45IkExROUu2O3bsGK+88goADz74oOM0Ir518uRJXnzxRWrUqMEVV1zhOo74CW1zlmxlraV69epERkYCf63aFglEx48fZ8+ePbz22muEhoa6jiN+ROUsPhceHs7hw4cBz05gycV89uxZreKTgBUZGUm/fv14/fXXKVasmOs44mdUzuJTY8eO5Zlnnvnb7QsWLFAxS8A6cuQI+/btY+jQoRQtWtR1HPFDKmfxmSlTpqQUc//+/WnRogUARYoUoW7dui6jifjMqVOnGDhwIMOGDaNw4cKu44ifUjmLz0ydOhWApUuX8s9//tNxGhHf27dvHzt37tR54uWyaW9tyXJxcXF88MEH7Nixg+uvv17FLEEhISGBUaNG0bBhQxWzXDaNnCXLTZw4MWV19j333OM4jYjv7dixg7Vr1zJixAjXUSRAqJzlkkVGRnLs2DE+++wzxowZkzJaSN4ze/PmzVSpUsVlRBGfs9YyY8YMnUxHspTKWS7a3r17+eabb/i///u/NLc/+eSTKV/XqFGD6tWrZ3c0kWy1ceNGlixZQlhYmOsoEmBUznJRvvrqK+69996U6TvuuIOOHTtSo0YNGjRo4DCZSPZKTExk1apVPP74466jSABSOctFSS7mu+++m/fff59y5co5TiSS/f744w++++47evfu7TqKBCiVs1y0Fi1aMHv2bNcxRJw4fvw4x48f16ps8SkdSiUXTYdGSbD65ZdfGDt2LM2bNydXLr19iu/o1SWZEh4ezo033ug6hogzGzdupHjx4ilXVBPxJZWzXNDatWu59tpr+f3337nuuuu4++67XUcSyVY///wzc+fOpUaNGhhjXMeRIKBtznJBnTp1AuDpp59mzJgxenOSoPLzzz9To0YNmjZt6jqKBBGNnOW8YmJiCA8PB2D06NEqZgkqv/zyC+vWraNs2bKuo0iQUTlLhtauXUvBggUBCAsL0w4wElS+/vprqlWrlu4lT0V8Te+2kq7NmzenXNaxQ4cO2glGgsqGDRs4evQopUuXdh1FgpTKWdI1ePBgAPLmzcsXX3xBaGio40Qi2ePzzz8nX758OvOXOKVylr85fvw4kydPpnLlypw+fVrbmSVoHDx4kFy5cumCLeKcyln+Jvkyjw0aNCB3bu3QL8Hhgw8+YO/evTz00EOuo4ionOXv4uLiyJUrF5999pnrKCLZIjIykiuvvJJGjRq5jiIC6DhnwXM92p49ezJr1ixy5cpFREQEt912GwUKFHAdTcTnRo8ezbXXXsudd97pOopICpWz0LJlS3788UfgrxOOPPjggy4jiWSLiIgIGjduTOPGjV1HEUlD5RzkRowYkVLM69ato06dOo4TiWSPYcOG0bhxY2699VbXUUT+RuUc5JKvRzt79mwVswQFay2rVq2iY8eOXHXVVa7jiKRLO4QFsY8++giAV155RRezkKAxfPhw4uPjVcySo2nkHKSstSknWejatavjNCK+l5SUxJw5c3juuee0s6PkeBo5B6mXX34ZgPz583P11Vc7TiPie2PHjqVSpUoqZvELGjkHmaSkJFavXs2wYcMAWLNmjeNEIr6VmJjIxIkTeeaZZ3S2O/EbGjkHkdjYWFq3bp1yooXHHnuMa665xnEqEd+aNm0azZo1UzGLX9HIOUj8/vvvtGvXjhMnTgAwY8YM7rjjDsepRHwnLi6OIUOG0L9/f13uVPyOyjmA7d69m3vvvZctW7YQHR0NwM0338zMmTN18XgJaElJSfz888906dJFxSx+Sa/aADVmzBgqV67M6tWriY6Opl27dnz55ZcsW7ZMxSwBLSYmhueff55bbrmFf/zjH67jiFwSjZwD0JIlS+jevTsAgwYN4sknnyQ8PJxmzZq5DSbiY2fOnGHjxo306tVLe2WLX9PIOcD8+9//pkmTJoDnEnh9+/alVKlSjlOJ+N6pU6cICwujcuXKlC9f3nUckcuicg4w8+fPp06dOkyYMCHlJCMigS4qKoodO3bw6quvUrJkSddxRC6byjlAWGsZPHgw8fHx3HXXXfznP/9xHUkkW5w4cYKXXnqJihUrUrp0addxRLKEtjkHgLNnz/LTTz/Rr18/AOrXr+84kUj2OHr0KHv27GHo0KGEhoa6jiOSZTRy9nO7d+8mf/783H777YBntfb999/vOJWI78XExPDqq69SrVo1FbMEHJWzH5syZQqVK1cGoGnTpnz88ce0bt3abSiRbHDgwAF+/fVX3n77bYoUKeI6jkiWUzn7qUGDBtGxY0cAqlevzk8//cSjjz6qUxRKwEtKSuKdd97hxhtvJE+ePK7jiPiEtjn7kVOnThEaGoq1NuW2H3/8kVtvvdVhKpHss2vXLn777TeGDx/uOoqIT2Vq5GyMaWOM2WyM2WaM6ZPBPA8YYzYYY9YbY77I2pgyf/58mjZtirWWcuXKMWDAAP78808VswSVmTNncu+997qOIeJzFxw5G2NCgLHAbUAEsMIYM9tauyHVPNWAl4B/WmuPG2PK+CpwsHrsscc4dOgQAKtXr9YpOCWobN68me+//56ePXu6jiKSLTIzcr4B2Gat3WGtjQOmAm3Pmec/wFhr7XEAa+3hrI0pR44c4b///S/x8fEqZgkqiYmJrF69mieffNJ1FJFsk5lyLg/sTTUd4b0ttepAdWPMMmPMb8aYNlkVUODDDz8kKSmJmJgYcufWbgISPP7880+++OILHnroIb32Jahk5tWe3u6/9pzp3EA1oBlQAVhijKljrT2R5oGM6QZ0AyhbtiyLFi1KuS86OjrNtHgcOXKEJ554AoCqVate8jLS8vUtLd+sFxUVxc6dO2nbtq2WrQ/ptes7l7VsrbXn/QfcBHybavol4KVz5nkfeDTV9A9Ao/M9boMGDWxqP/30kxWPyMhIW79+fXvllVdaPB+E7LBhwy7rMbV8fUvLN2v9/vvvtn///tZaLVtf0/L1nXOXLbDSXqBzk/9lZuS8AqhmjPkHsA/oAHQ8Z55ZwEPAJGNMKTyruXdc2seF4BQTE8OcOXM4dOhQyuUeAbp27UrRokXT3CYSyNavX09oaCivvvqq6ygizlywnK21CcaYZ4BvgRDgI2vtemPMa3g+Bcz23tfKGLMBSATCrLXHfBk8kMyfP59OnToRGRmZctsDDzzAuHHjKFGihMNkItlr2bJlLF68mD59+uiEOhLUMrWHhbV2HjDvnNv6p/raAj29/+QCEhMTmTdvHn36eA4Z37DBc1RauXLlWLBgAcWKFaNixYouI4pku8WLF1O9enVuvvlmFbMEPe3+mI22b9/Ohg0b6Ny5MydOePaVu+OOO6hZsybt27enQ4cOjhOKuLFy5UpWr15NkyZNXEcRyRFUztlk27ZtVKtWLWU6V65czJw5k7Ztzz1kXCS4zJkzhwYNGtCjRw/XUURyDF34IpvUqVMHgAcffJCVK1cSHR2tYpagt337dg4cOEC5cuVcRxHJUTRy9rGYmBjuuecezp49S4kSJZg6darrSCI5wrRp07j22mvp1q2b6ygiOY5Gzj42ZMgQFi5cCMAff/zhOI1IznDs2DESEhKoVauW6ygiOZJGzj40bdo0Pv30UwD27dunVXciwKRJk6hatSoPP/yw6ygiOZbK2UeioqJS9r5+9tlnVcwieP4uSpcuzS233OI6ikiOpnL2gbi4OIoVKwZAkyZNGD16tONEIu699957VK1alTvvvNN1FJEcT+Wcxc6ePUv9+vUByJ8/P19//bXjRCLu7d27l0aNGtGoUSPXUUT8gnYIy2IbNmxIOePXnj17UkbQIsHqzTffZNOmTSpmkYugkXMWiouLo2nTpgB88803lC5d2nEiEXestSxfvpwOHTpQvvy5l4AXkfPRyDkL/fDDD5w6dQqAli1bOk4j4tZbb71FQkKCilnkEmjknAUSExOZO3cuTz31FAC//PILefPmdZxKxA1rLV999RVPP/00+fPndx1HxC+pnLNAvXr1WLduHQCdOnVK2SFMJBhNmDCBhg0bqphFLoPK+TItWrQopZi//vpr7rnnHseJRNxITEzkvffe45lnntElH0Uuk7Y5X6YRI0YAnrOBqZglmM2cOZPmzZurmEWygMr5Ms2fP5/rrruOBx54wHUUESfi4+Pp168f7dq1o3bt2q7jiAQErda+RNOnT2fDhg2EhIQQGhrqOo6IE0lJSSxbtowuXbqQO7feTkSyiv6aLsHQoUN5+eWXU6aTz6EtEkxiY2Pp3bs3gwcPpkiRIq7jiAQUlfNFmjRpUkoxf//99zRv3pxcubR1QIJLTEwMmzdv5sUXX1Qxi/iAWuUibNq0iU8++QSANWvW0LJlSxWzBJ3Tp08TFhZGuXLlqFixous4IgFJI+dM2rt3LzVr1gSgdu3aXH/99Y4TiWS/U6dOsXPnTvr160eZMmVcxxEJWBr2ZcKWLVu46qqrAGjbti1//PGH40Qi2e/UqVP06dOHcuXKUbZsWddxRAKaRs6Z0LVrVwBuv/12Zs6cqVXZEnQiIyPZsWMHQ4YM0dEJItlALZMJhQsXBmDu3LkqZgk6cXFx9O/fn2rVqqmYRbKJRs6Z8O2333LDDTeomCXoHDp0iDVr1vDOO+/oOGaRbKS2uYCDBw8CEB0d7TiJSPay1jJ69GhuueUWFbNINtNf3AUcPXoUgCeffNJxEpHss3fvXhYtWsTrr7/uOopIUNLIOZOuvPJK1xFEss2sWbO4//77XccQCVoaOV/AzJkzAc85hEUC3fbt25k9ezbPP/+86ygiQU0j5wt49913AfjnP//pOImIb8XHx7N69WqeeeYZ11FEgp5Gzuexf/9+jhw5QsOGDSlfvrzrOCI+s379er788ksGDhzoOoqIoJHzeTVu3BiAO++803ESEd85fPgwJ06coH///q6jiIiXyjkDW7ZsISIiAoC+ffs6TiPiG6tWrWL06NHcfPPNhISEuI4jIl4q5wysXLkSgIkTJ+oYTwlI4eHhFClShEGDBmGMcR1HRFJROWfg8OHDANxwww2Ok4hkveXLlzNr1iyqVaumYhbJgVTOGUgeOet6tRJolixZQoUKFXjllVdUzCI5lMo5AwsWLACgQIECjpOIZJ0///yT5cuXU65cORWzSA6mcs5Avnz5aN++Pfnz53cdRSRLzJs3j9DQUF544QXXUUTkAlTOGQgJCaFIkSKuY4hkib1797Jr1y4qVarkOoqIZILKWSTATZ8+nWPHjvHUU0+5jiIimaRyTkdcXBx79+7FWus6ishliYqKIiYmhrp167qOIiIXQQfwpiP5MnnaGUz82WeffUb58uV55JFHXEcRkYukkXM6vvnmGwCGDh3qOInIpTl58iQlS5akefPmrqOIyCXQyPkcCQkJrFq1itq1axMaGuo6jshFGz9+PBUqVNA54UX8mEbOqUyePJk8efIA0LFjR8dpRC7e7t27adiwoYpZxM+pnL1OnjyZsm3uySef1HY68TujRo1iw4YNNGjQwHUUEblMWq3t9euvvwLQoUMHxo0b5ziNSOZZa/nll1944IEHuPLKK13HEZEsoJHzObp37+46gshFGT16NAkJCSpmkQCikbOIn7LW8r///Y8nn3ySfPnyuY4jIllII2cRP/Xxxx9TqVIlFbNIANLIWcTPJCUlMXr0aJ577jldWUokQGnk7BUVFeU6gkimzJ07l+bNm6uYRQKYytkr+TJ6JUqUcJxEJH0JCQn069eP1q1bc91117mOIyI+pHL2ioiIAOCaa65xnETk7xITE1m+fDmPPPKItjGLBAGVM56L0AP07NnTcRKRv4uLi+PFF1+kZs2aVK9e3XUcEckG2iEM2LNnDwAPPfSQ4yQiacXGxrJlyxZ69OhB8eLFXccRkWyikTOwdOlSACpUqOA4ichfzpw5Q1hYGKVLl6ZSpUqu44hINgr6kbO1ls8//xyA0qVLO04j4nH69Gm2b9/Oyy+/rDN/iQShoB85f/LJJwBUrlyZkJAQx2lEPMXcq1cvrrjiChWzSJAK+pFzt27dAJg/f77jJCJw4sQJNm/ezJAhQ3Q9cZEgFtQj5zlz5hAfH0++fPmoUaOG6zgS5BISEujfvz/Vq1dXMYsEuaAeOY8cORKAFStWOE4iwe7IkSP8/vvvvP3229q8IiLBPXIODw8nb968XHvtta6jSBCz1vLuu+/SrFkzFbOIAEE+cs6TJ4+OHRWn9u3bx7fffsvAgQNdRxGRHCRoR85Hjhzh8OHD3H333a6jSJCy1jJ79myd/EZE/iZoR84jRowAdGyzuLFz506mTZtGnz59XEcRkRwoKEfO+/fv54033gBg0KBBjtNIsDl79ixr1qzRudxFJENBWc7NmjUD4L777tMOOJKtNm7cyMCBA2nXrh158+Z1HUdEcqigK+ekpCS2bt0KwJQpUxynkWBy8OBBoqKitLZGRC4o6Mr5nXfeAeCBBx4gT548jtNIsFizZg2jRo3ihhtu0NoaEbmgoCrnuLg4XnjhBeCvHcJEfC08PJxChQrx+uuvkytXUP3JicglCqp3ii1btgBw++236xJ8ki1Wr17N9OnTqVq1qopZRDItqN4tkrcxP/nkk46TSDBYtmwZpUqVYsCAARhjXMcRET8SVOU8btw4AO655x7HSSTQbdq0iaVLl1KxYkUVs4hctKAp5507d3L8+HHXMSQIfPfdd+TKlYvevXurmEXkkmSqnI0xbYwxm40x24wxGZ7SyBjT3hhjjTENsy5i1hg2bBgAY8aMcZxEAtmhQ4fYtGkT1atXdx1FRPzYBcvZGBMCjAVuB2oBDxljaqUzXxGgO/B7VofMCvPnzwc8O4OJ+MKsWbPYtWsX3bt3dx1FRPxcZkbONwDbrLU7rLVxwFSgbTrzDQJGALFZmC/LhISE0LlzZ6pUqeI6igSgmJgYTp48SePGjV1HEZEAkJlyLg/sTTUd4b0thTGmHlDRWjs3C7OJ+IUpU6awbt06Onfu7DqKiASIzFyVKr09WmzKncbkAt4GHr3gAxnTDegGULZsWRYtWpRyX3R0dJrprBYbG8vBgwd9+hw5ma+Xb7A6ffo0u3fvpk6dOlq+PqLXrm9p+frO5SzbzJRzBFAx1XQFYH+q6SJAHWCRd8/UK4DZxph7rLUrUz+QtXYCMAGgYcOGNvkCFACLFi0i9XRWO3jwIK1atfLpc+Rkvl6+weijjz6iRIkS9OnTR8vXh7RsfUvL13cuZ9lmppxXANWMMf8A9gEdgI7Jd1pro4BSydPGmEXAi+cWs0vJh1AdPXrUcRIJFDt27KB+/frUrVvXdRQRCUAX3OZsrU0AngG+BTYCX1pr1xtjXjPG+MXZPGJjPfuotWnTxnESCQRjx45l/fr1KmYR8ZnMjJyx1s4D5p1zW/8M5m12+bGyVkxMDICunyuXbcmSJdx///2UKVPGdRQRCWBBcYaw9957D4AiRYo4TiL+bNy4ccTHx6uYRcTnMjVy9ncLFy4EPNdwFrlY1lqmTp3KE088oWuAi0i2CPiRs7WWtWvXApA7d1B8FpEs9sUXX1C5cmUVs4hkm6BpK12JSi5WUlIS77zzDs899xwhISGu44hIEAn4kXN0dDQA9evXd5xE/M13333HrbfeqmIWkWwX8OWcfBGCfPnyOU4i/iIxMZG+ffvSpEkT6tWr5zqOiAShgC7nmJgYJk+eDMDTTz/tOI34g8TERFavXs3DDz9MwYIFXccRkSAV0OU8ZMgQEhISqFu3rg6jkguKj48nLCyMSpUqUbNmTddxRCSIBewOYUlJSQwePBiAH374wXEayenOnj3L1q1beeaZZ3Qcs4g4F7Aj52effRaAunXrUqJECcdpJCeLjY0lLCyMYsWKcfXVV7uOIyISmCPnxMTElLOCadQs53PmzBm2bdtGnz59KFeunOs4IiJAgI6cZ8+eDUD79u01apYMxcbG0qtXL8qUKaNiFpEcJSBHzjt27AAgLCzMcRLJqU6ePMm6desYMmQIRYsWdR1HRCSNgBw5L1myBIBq1ao5TiI5UVJSEv369aNGjRoqZhHJkQJy5Fy8eHHy5s1L8eLFXUeRHObYsWMsXryYt99+m1y5AvKzqYgEgIB8d5o0aZK2NUu63nvvPVq0aKFiFpEcLeBGztu2bQM8x62KJDt48CBff/01/fr1cx1FROSCAmr4cObMmZTtzG+++abjNJJTWGuZM2cOjzzyiOsoIiKZElAj5w0bNgBQrlw5HnvsMcdpJCfYvXs3n376qUbMIuJXAmrk/OmnnwIwceJEx0kkJ4iNjeXPP/+kV69erqOIiFyUgCrnSZMmAdCkSRO3QcS5LVu20L9/f+666y5dLlRE/E5ArdYuXLgwCQkJFC5c2HUUcWj//v1ERUUxZMgQjDGu44iIXLSAGjkfOHCADh06uI4hDq1bt45Ro0ZRv359cucOqM+eIhJEAubd68iRI2n+l+ATHh5O/vz5GTp0qI5jFhG/FjDvYMnHNd95552Ok4gL4eHhfPnll1SpUkXFLCJ+L2DexaKjowG0KjMI/frrrxQqVIiBAweqmEUkIATMO9l//vMfAF3IIMjs2LGDn376icqVK2vnLxEJGAFRzpGRkSxduhTwXMNZgsMPP/zAmTNneOmll1TMIhJQAqKcu3XrBsD//d//abVmkIiMjCQ8PJw6deqomEUk4ATEBtr4+HgA3nrrLcdJJDvMnTuX0NBQnnvuOddRRER8ImCGmXXr1iV//vyuY4iPxcbGEhkZyb/+9S/XUUREfMbvR87WWmbPns21117rOor42Jdffkn+/Pnp3Lmz6ygiIj7l9+U8YcIEAG13DHAnT56kaNGitGnTxnUUERGf8/tyTt5Le8aMGY6TiK988sknFCxYkPvvv991FBGRbOH35Tx37lwKFy5M1apVXUcRH9i6dSv169fXZgsRCSp+vUNYXFwcJ06cSNlbWwLL+PHj2bBhg4pZRIKOX4+ck8+nnXx2MAkcP/30E/fddx+lSpVyHUVEJNv59cg5WeXKlV1HkCz0wQcfEB8fr2IWkaDl1yPnTZs2AZ7V2+L/rLVMnjyZRx99VBcwEZGg5tcj57lz5wJQp04dx0kkK0yfPp3KlSurmEUk6Pn1u+CSJUsAz9nBxH9Za3nrrbfo3r07efLkcR1HRMQ5vx45Hzt2jBtvvJGKFSu6jiKX4aeffqJp06YqZhERL78u5z///JPjx4+7jiGXKCkpib59+9KwYUMaNmzoOo6ISI7h16u18+TJQ6NGjVzHkEuQmJjIunXr6NChA0WLFnUdR0QkR/HrkXN8fDxly5Z1HUMuUnx8PL1796Z06dLamU9EJB1+O3Les2cPANHR0Y6TyMWIi4tj27Zt/Pe//6V8+fKu44iI5Eh+O3KeNWsWADfccIPjJJJZZ8+epVevXhQsWJBq1aq5jiMikmP55cg5Li6O5557DoBbbrnFcRrJjJiYGLZs2UJYWJhGzCIiF+CXI+cTJ04A0Mr2vukAABMbSURBVLRpU6pXr+44jVxIfHw8YWFhlCpVSsUsIpIJfjlyTj586oEHHnCcRC7k1KlTrF69mqFDh1KkSBHXcURE/IJfjpzXr18PQIECBRwnkfOx1vLqq69Sq1YtFbOIyEXwy5HzDz/8AGhnsJzs+PHjfP/994wcOZJcufzyM6CIiDN++a5ZqFAhAGrWrOk4iWRkwoQJtGrVSsUsInIJ/HLkDJ5V2nrjz3kOHz7Ml19+Se/evV1HERHxW37Zbrt27dI1nHMgay3ffPMNjz32mOsoIiJ+zS9Hzv/73/9cR5BzREREMGHCBF577TXXUURE/J5fjpwBHnroIdcRxCsmJobw8HBefvll11FERAKCX5Zzrly5qFKliusYAmzfvp1XXnmF1q1bkz9/ftdxREQCgt+V89KlS0lKSnIdQ/Csyo6KimL48OEYY1zHEREJGH5Xzp06dQKgYsWKjpMEt40bNzJ69Giuu+468uTJ4zqOiEhA8btyjoyMpF27dnTr1s11lKC1fv16cufOzdChQ8md2y/3KRQRydH8qpyPHz/OqVOntG3ToU2bNvHFF19QpUoVQkJCXMcREQlIflXO27dvB6BOnTqOkwSn5cuXExISwuDBg3UCGBERH/Krd9jkazhfc801jpMEn4iICBYsWEDVqlW185eIiI/51QbDmJgYAO655x7HSYLLzz//TJEiRejXr5+KWUQkG/jVyNkYw1133aW9g7PRqVOn+OOPP6hXr56KWUQkm/jNyPnIkSOsXr2aK6+80nWUoDF//nzy5MlDjx49XEcREQkqfjNyXr9+PYDODJZN4uLiOHLkCC1btnQdRUQk6PjNyDlZu3btXEcIeDNnziQpKYnOnTu7jiIiEpT8ppzXrVvnOkJQiIqKonDhwrRq1cp1FBGRoOU35Xzy5EkAqlWr5jhJ4Jo8eTK5cuWiY8eOrqOIiAQ1vynnLVu2AFC6dGnHSQLTpk2bqF+/PrVq1XIdRUQk6PnNDmGffvopgE4Z6QMffvgh69evVzGLiOQQfjNyBs+VqFTOWeuHH36gXbt2lChRwnUUERHx8ouR886dOwH4//buPraqOs/j+PvbUh6s2K3iggErs8AAtVkFi46KDjK4iI3FmIkRbfAB1LiMfzDVovUJReRJxIwxmWHlYbvJyqxj2C2LIjjYsBA7QQWqxUJKZSvRgqxUeezT/e0ft2U6WOih7bnn3Hs/r+Qm9/ae3vvJl5v75XvO6fndeuutASdJLCUlJTQ0NKgxi4iETFxMzhs3bgTg2muvDThJ4igpKeHee+/Vko8iIiEUF5Pz66+/DsCUKVMCTpIYSktLycrKUmMWEQkpT83ZzG4zsz1mVm1mT3Xw/G/NbLeZVZjZn83sip4K2NDQQFVVFQBDhgzpqZdNSs45li5dyuTJk5kwYULQcURE5Cw6bc5mlgq8CUwBsoFpZnbmab07gFzn3D8CfwIW91TAQ4cOAfD4449rDeFu2rZtG+PHj6dPnz5BRxERkXPw0u2uBaqdczXOuUZgDTC1/QbOuY+ccydaH5YDPTbiVlRUAFrDuTsikQgrV65k9OjRXHfddUHHERGRTng56DgY+Lrd4wPAub7hZwDvd/SEmT0CPAIwcOBAysrKTj937Nixv3ncpu2ynSkpKR0+L+fW0tJCbW0t48aN0yVQfXS2z690n2rrL9XXP92prZfm3NEivq7DDc0KgFzglx0975xbDiwHyM3Nde2Pe5aVlXV4HPTEiehAfs011+hs7fPU3NxMcXExs2bN4quvvtJxZh+d7fMr3afa+kv19U93autlt/YB4PJ2j4cA35y5kZlNAp4B8p1zDV1K04GdO3f21EsllaamJqqrq5kxYwZXXNFj5+eJiEgMeGnO24ERZvYzM+sN3AOUtt/AzMYAfyDamA/1ZMC2yVnHnL1rbGykqKiItLQ01U1EJA51ulvbOddsZr8BPgBSgZXOuUozewn4xDlXCiwBLgTeMTOAWudcfk8E/PLLLwHIyMjoiZdLeKdOnaKqqoonnniCwYMHBx1HRES6wNNVKJxz7wHvnfGz59vdn9TDuU6rq6vz66UTTktLC0VFRTz55JNqzCIicSz0l4jq27ev/vzHg+PHj1NeXs6CBQtIT08POo6IiHRD6K/qUVlZqctMevDSSy+Rk5OjxiwikgBC3/UOHjyohnMO9fX1rF+/noULF9J6vF9EROJc6Cfn1NRUpk6d2vmGSWrFihVMmTJFjVlEJIGEenJ2ztHS0kJaWlrQUULn8OHDlJSUUFhYGHQUERHpYaGenPfs2QNEd93KXznn2LBhAw8//HDQUURExAehbs4nT54EYPLkyQEnCY9vvvmG4uJiCgoK6N+/f9BxRETEB6Fuzm1SU1ODjhAKx48fZ/fu3Tz//POdbywiInErLpqzwP79+ykuLmbixIn069cv6DgiIuIjNec4cODAAerr61myZAkpKfonExFJdKH+pt++fTsAkUgk4CTB2bt3L8uWLePKK6+kd+/eQccREZEYCHVzbmpqAuDqq68OOEkwdu/eDcCiRYv052QiIkkk1M159erVAFx44YXBBgnAvn37KCkpYdiwYbp8qYhIkgl1cz548CAAmZmZASeJrU8//ZSGhgZeeeUVnakuIpKEQt2cU1NTmT59elJNjocOHWLdunWMHj1aJ3+JiCSp0H77O+fYv39/0DFiauvWrdTU1DB37lxdK1tEJImFtjlv27YN+OtVwhLdyZMn2b59u9auFhGR8C580Xa8+f777w84if82bdpEY2Mjs2fPDjqKiIiEQGgn5zZZWVlBR/BVU1MTBw8eJC8vL+goIiISEqGdnJNBaWkpx44do6CgIOgoIiISImrOATly5Ajp6enk5+cHHUVEREJGzTkAa9asobGxkenTpwcdRUREQii0zbntutqJprKykjFjxjBy5Migo4iISEiF9oSwtrO1hw0bFnCSnlNSUkJlZaUas4iInFNoJ+etW7cCcMEFFwScpGds3LiRqVOnkpGREXQUEREJudA25wEDBiTMZTvXrFlDenq6GrOIiHgS2u5XXl7OxIkTg47RbatXr+a+++7Tko8iIuJZKI85t7S0ANCvX7+Ak3TPhg0bGDJkiBqziIicl1BOzjt27AAgOzs74CRd45xj6dKlPPbYY6SnpwcdR0RE4kwoJ+e2xS4mTZoUcJLz55xj+/btXH/99WrMIiLSJaFszgsXLgSgT58+ASc5P5FIhBdeeIGsrCxuvPHGoOOIiEicCmVzbmvK8dTgIpEIe/fu5c4772TQoEFBxxERkTgWyubc3NxMTk5O3PwpVUtLC08//TS9evVi7NixQccREZE4F8rmvG7dOhoaGoKO4UlzczPV1dU8+OCDDB8+POg4IiKSAELXnOvq6gBISQldtJ9oamqiqKgIM2PUqFFBxxERkQQRuv3GX3zxBQCFhYUBJzm3hoYGKisrKSwsZPDgwUHHERGRBBK68bSkpAQI94IXkUiEOXPmcMkll6gxi4hIjwvd5FxdXQ3ALbfcEnCSjp04cYItW7awYMGCuL+CmYiIhFPoJuf6+noAzCzgJB2bP38+V111lRqziIj4JnSTc1paGnfccUfQMX7ixx9/ZO3atbz88suh/Y+DiIgkhtBNzmYWyjO1V61aRV5enhqziIj4LnSTc9h8//33vPXWWxQVFQUdRUREkkT4RtQQiUQibNq0iUcffTToKCIikkTUnM+irq6OOXPmcPfdd5ORkRF0HBERSSJqzh04evQoVVVVzJ07V8eYRUQk5kLVnCORCLt27cI5F1iG2tpaiouLGT9+vNZjFhGRQISqOQe92MXXX39NfX09r776atysiCUiIoknVM25zQ033BDz99y3bx/Lli1j1KhRp9eTFhERCYLGQ6CqqgqARYsWkZaWFnAaERFJdqGanI8cORLz96ytrWXVqlWMGDFCjVlEREIhVJPzrFmzAOjfv39M3m/nzp2kpKSwYMGCUF6VTEREklOoOtKpU6fo1asXM2fO9P296uvrWbt2LTk5OWrMIiISKqGanAHGjh1L7969fX2P8vJyGhsbefHFF319HxERka5IupGxsbGRjz/+mJtuuinoKCIiIh0K3eTsp82bN1NfX8/s2bODjiIiInJWSTM5NzU18e2333LXXXcFHUVEROSckmJyXr9+Pd999x0PPPBA0FFEREQ6lfDN+fDhw6Snp5OXlxd0FBEREU8Sujm/8847HD16lIceeijoKCIiIp4lbHOuqKhgzJgxDB8+POgoIiIi5yUhTwh7++23+fzzz9WYRUQkLiXc5Pz++++Tl5fHRRddFHQUERGRLkmo5vzuu++SkpKixiwiInEtYZrz6tWrmTZtmtZiFhGRuJcQx5w3b97MoEGD1JhFRCQhxPXk7JzjtddeY+bMmWRkZAQdR0REpEfE7eTsnKOiooJx48apMYuISEKJy+bsnGPevHlkZmZy8803Bx1HRESkR8Xdbu1IJEJNTQ1TpkwhKysr6DgiIiI9Lq4m50gkwrPPPktTUxPjxo0LOo6IiIgv4mZybmlpYd++fRQUFDB69Oig44iIiPgmLibn5uZm5syZQ0tLC9nZ2UHHERER8VWoJufq6moyMzP/5mdNTU3s2rWLwsJCLrvssoCSiYiIxE6oJufq6mrq6upOP3bO8dRTT3HxxRerMYuISNIIzeR88uRJACZPngzAqVOn+PDDD5k/fz59+/YNMpqIiEhMhWZybpuYBwwYAMDixYsZM2aMGrOIiCQdT83ZzG4zsz1mVm1mT3XwfB8z+2Pr838xs6FdDZSdnc2KFSt47rnnGDx4cFdfRkREJG512pzNLBV4E5gCZAPTzOzMU6ZnAEecc8OBZcCi8wkRiURYvHgxAFu2bCE/Px8zO5+XEBERSRheJudrgWrnXI1zrhFYA0w9Y5upwL+23v8T8Cs7j+5aU1NDVVUVAM888wyXXnqp118VERFJOF6a82Dg63aPD7T+rMNtnHPNwA/AJV5DfPbZZwC88cYbDB061OuviYiIJCQvZ2t3NAG7LmyDmT0CPAIwcOBAysrKAEhLS2PevHmMHDny9M+kZx07dky19ZHq6x/V1l+qr3+6U1svzfkAcHm7x0OAb86yzQEz6wVkAN+f+ULOueXAcoDc3Fw3YcKE089lZmbS/rH0rLKyMtXXR6qvf1Rbf6m+/ulObb3s1t4OjDCzn5lZb+AeoPSMbUqB+1vv/xrY7Jz7yeQsIiIinet0cnbONZvZb4APgFRgpXOu0sxeAj5xzpUCK4B/M7NqohPzPX6GFhERSWQW1IBrZt8B/9vuRwOAw4GESQ6qr79UX/+otv5Sff1zZm2vcM55+nOkwJrzmczsE+dcbtA5EpXq6y/V1z+qrb9UX/90p7ahuXyniIiIRKk5i4iIhEyYmvPyoAMkONXXX6qvf1Rbf6m+/ulybUNzzFlERESiwjQ5i4iICAE051guP5mMPNT3t2a228wqzOzPZnZFEDnjUWe1bbfdr83MmZnOgD0PXuprZne3fn4rzezfY50xXnn4Xsgys4/MbEfrd8PtQeSMR2a20swOmdkXZ3nezOx3rbWvMLOxnl7YORezG9GLmOwD/gHoDewCss/Y5p+B37fevwf4YywzxvPNY31vAS5ovf+Y6ttztW3drj+wBSgHcoPOHS83j5/dEcAOILP18d8HnTsebh5ruxx4rPV+NrA/6NzxcgNuBsYCX5zl+duB94muQfEL4C9eXjfWk7Pvy08muU7r65z7yDl3ovVhOdFrpUvnvHx2AeYBi4FTsQyXALzU92HgTefcEQDn3KEYZ4xXXmrrgIta72fw0/UT5Cycc1voYC2JdqYCJS6qHPg7M7uss9eNdXP2ffnJJOelvu3NIPo/Oulcp7U1szHA5c65/45lsATh5bP7c+DnZrbNzMrN7LaYpYtvXmo7FygwswPAe8DjsYmWFM73exnwtipVT+qx5SelQ55rZ2YFQC7wS18TJY5z1tbMUoBlwAOxCpRgvHx2exHdtT2B6B6f/zGzHOdcvc/Z4p2X2k4DVjvnlprZ9UTXSshxzkX8j5fwutTTYj05n8/yk5xr+UnpkJf6YmaTgGeAfOdcQ4yyxbvOatsfyAHKzGw/0WNLpTopzDOv3w3/5Zxrcs59Bewh2qzl3LzUdgbwHwDOuY+BvkSvCy3d5+l7+Uyxbs5aftJfnda3ddfrH4g2Zh2z8+6ctXXO/eCcG+CcG+qcG0r0eH6+c+6TYOLGHS/fDf9J9IRGzGwA0d3cNTFNGZ+81LYW+BWAmY0m2py/i2nKxFUKTG89a/sXwA/OuW87+6WY7tZ2Wn7SVx7ruwS4EHin9Ty7WudcfmCh44TH2koXeazvB8A/mdluoAV40jn3f8Gljg8ea1sI/IuZzSa6y/UBDUXemNnbRA+1DGg9Zv8CkAbgnPs90WP4twPVwAngQU+vq/qLiIiEi64QJiIiEjJqziIiIiGj5iwiIhIyas4iIiIho+YsIiISMmrOIiIiIaPmLCIiEjJqziIiIiHz/xIW+UzDPCBVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compute_test_validation_accuracy(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels, y_labels = output_labels_given_model_data(model_1, credit_cards_deep_learning_test)\n",
    "#len(y_labels)\n",
    "\n",
    "\n",
    "\n",
    "def number_to_default(number):\n",
    "    if number == 0:\n",
    "        return \"no\"\n",
    "    elif number == 1:\n",
    "        return \"yes\"\n",
    "\n",
    "def output_results_to_file(file_name, y_labels):\n",
    "    sys.stdout = open(file_name, 'w')\n",
    "    #just iterate over the two lists element by element\n",
    "    print(\"index,credit_default\")\n",
    "    for i in range(0, len(y_labels)):\n",
    "        print(str(i) + \",\" + str(number_to_default(y_labels.item(i))))\n",
    "\n",
    "\n",
    "\n",
    "output_results_to_file(\"group_1_submission_3rd_try.txt\", y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 6 hidden nodes, relu activation\n",
    "# 1 hidden layer, 6 hidden nodes, relu activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "\n",
    "model_2 = Sequential([\n",
    "    #hidden layers\n",
    "    Dense(6, input_shape=(27,), activation=\"relu\"),\n",
    "    Dense(6, activation=\"relu\"),\n",
    "    #final layer\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function!!\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n",
    "\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_compute_test_validation_accuracy(model_2)\n",
    "\n",
    "#file\n",
    "#sys.stdout = open(file_name, 'w')\n",
    "\n",
    "\n",
    "y_pred_class_nn_1 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_2.predict(X_test_norm)\n",
    "\n",
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
