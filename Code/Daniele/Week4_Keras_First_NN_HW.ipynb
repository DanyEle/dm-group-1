{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed). Fixed the dataset\n",
    "\n",
    "url = \"http://www.dgadler.it/HMM/pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url, names=names, header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.856</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.324</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.293</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>66</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.196</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>98</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.321</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "690               8                     107              80               0   \n",
       "87                2                     100              68              25   \n",
       "234               3                      74              68              28   \n",
       "397               0                     131              66              40   \n",
       "187               1                     128              98              41   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "690        0  24.6              0.856   34             0  \n",
       "87        71  38.5              0.324   26             0  \n",
       "234       45  29.7              0.293   23             0  \n",
       "397        0  34.3              0.196   22             1  \n",
       "187       58  32.0              1.321   33             1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
      "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "#the output consists of the state with diabetes\n",
    "y = diabetes_df[\"has_diabetes\"].values\n",
    "\n",
    "print(X)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "#y is the state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "#we train both with X input data and Y input data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.829\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test) #HARD\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test) #SOFT\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 264us/step - loss: 0.7678 - acc: 0.4861 - val_loss: 0.7828 - val_acc: 0.4375\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.7546 - acc: 0.4896 - val_loss: 0.7707 - val_acc: 0.4375\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.7423 - acc: 0.5035 - val_loss: 0.7595 - val_acc: 0.4479\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.7310 - acc: 0.5260 - val_loss: 0.7491 - val_acc: 0.4688\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.7203 - acc: 0.5347 - val_loss: 0.7393 - val_acc: 0.4844\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.7105 - acc: 0.5451 - val_loss: 0.7302 - val_acc: 0.5000\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.7012 - acc: 0.5503 - val_loss: 0.7217 - val_acc: 0.5208\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6926 - acc: 0.5712 - val_loss: 0.7137 - val_acc: 0.5417\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.6845 - acc: 0.5851 - val_loss: 0.7062 - val_acc: 0.5625\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6769 - acc: 0.6024 - val_loss: 0.6992 - val_acc: 0.5781\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6697 - acc: 0.6215 - val_loss: 0.6926 - val_acc: 0.5833\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6631 - acc: 0.6372 - val_loss: 0.6864 - val_acc: 0.5990\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6568 - acc: 0.6458 - val_loss: 0.6806 - val_acc: 0.6146\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.6509 - acc: 0.6441 - val_loss: 0.6752 - val_acc: 0.6146\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6453 - acc: 0.6493 - val_loss: 0.6701 - val_acc: 0.6198\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6402 - acc: 0.6528 - val_loss: 0.6652 - val_acc: 0.6250\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6352 - acc: 0.6562 - val_loss: 0.6606 - val_acc: 0.6146\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6305 - acc: 0.6632 - val_loss: 0.6563 - val_acc: 0.6250\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6260 - acc: 0.6684 - val_loss: 0.6522 - val_acc: 0.6354\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.6217 - acc: 0.6736 - val_loss: 0.6483 - val_acc: 0.6250\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6176 - acc: 0.6788 - val_loss: 0.6446 - val_acc: 0.6250\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6137 - acc: 0.6788 - val_loss: 0.6410 - val_acc: 0.6250\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6100 - acc: 0.6840 - val_loss: 0.6376 - val_acc: 0.6250\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6064 - acc: 0.6892 - val_loss: 0.6343 - val_acc: 0.6302\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.6030 - acc: 0.6910 - val_loss: 0.6312 - val_acc: 0.6354\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5997 - acc: 0.6944 - val_loss: 0.6281 - val_acc: 0.6406\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5965 - acc: 0.6944 - val_loss: 0.6252 - val_acc: 0.6458\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5934 - acc: 0.6962 - val_loss: 0.6223 - val_acc: 0.6458\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5904 - acc: 0.7031 - val_loss: 0.6196 - val_acc: 0.6510\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5875 - acc: 0.7014 - val_loss: 0.6169 - val_acc: 0.6562\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5847 - acc: 0.7031 - val_loss: 0.6144 - val_acc: 0.6510\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5821 - acc: 0.7031 - val_loss: 0.6120 - val_acc: 0.6510\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.5795 - acc: 0.6997 - val_loss: 0.6096 - val_acc: 0.6615\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5769 - acc: 0.6997 - val_loss: 0.6073 - val_acc: 0.6615\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5745 - acc: 0.6997 - val_loss: 0.6051 - val_acc: 0.6615\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5722 - acc: 0.7014 - val_loss: 0.6030 - val_acc: 0.6615\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5699 - acc: 0.7014 - val_loss: 0.6010 - val_acc: 0.6562\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5677 - acc: 0.7031 - val_loss: 0.5990 - val_acc: 0.6562\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5656 - acc: 0.7066 - val_loss: 0.5970 - val_acc: 0.6615\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5635 - acc: 0.7066 - val_loss: 0.5952 - val_acc: 0.6615\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5615 - acc: 0.7066 - val_loss: 0.5934 - val_acc: 0.6615\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5596 - acc: 0.7066 - val_loss: 0.5917 - val_acc: 0.6615\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5577 - acc: 0.7066 - val_loss: 0.5900 - val_acc: 0.6667\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5559 - acc: 0.7066 - val_loss: 0.5883 - val_acc: 0.6667\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5541 - acc: 0.7083 - val_loss: 0.5867 - val_acc: 0.6667\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5523 - acc: 0.7083 - val_loss: 0.5852 - val_acc: 0.6719\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5506 - acc: 0.7083 - val_loss: 0.5837 - val_acc: 0.6719\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5490 - acc: 0.7066 - val_loss: 0.5823 - val_acc: 0.6719\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5473 - acc: 0.7066 - val_loss: 0.5809 - val_acc: 0.6719\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.5458 - acc: 0.7083 - val_loss: 0.5795 - val_acc: 0.6771\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5442 - acc: 0.7066 - val_loss: 0.5782 - val_acc: 0.6771\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5427 - acc: 0.7049 - val_loss: 0.5769 - val_acc: 0.6771\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5413 - acc: 0.7049 - val_loss: 0.5756 - val_acc: 0.6771\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5399 - acc: 0.7049 - val_loss: 0.5744 - val_acc: 0.6771\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5385 - acc: 0.7049 - val_loss: 0.5732 - val_acc: 0.6771\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5371 - acc: 0.7066 - val_loss: 0.5721 - val_acc: 0.6771\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5358 - acc: 0.7049 - val_loss: 0.5709 - val_acc: 0.6823\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.5345 - acc: 0.7049 - val_loss: 0.5698 - val_acc: 0.6823\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.5333 - acc: 0.7083 - val_loss: 0.5688 - val_acc: 0.6823\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5320 - acc: 0.7083 - val_loss: 0.5678 - val_acc: 0.6823\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5308 - acc: 0.7083 - val_loss: 0.5668 - val_acc: 0.6823\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5296 - acc: 0.7101 - val_loss: 0.5658 - val_acc: 0.6823\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5285 - acc: 0.7118 - val_loss: 0.5648 - val_acc: 0.6875\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5274 - acc: 0.7118 - val_loss: 0.5638 - val_acc: 0.6875\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5263 - acc: 0.7135 - val_loss: 0.5629 - val_acc: 0.6927\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5252 - acc: 0.7135 - val_loss: 0.5620 - val_acc: 0.6927\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5241 - acc: 0.7135 - val_loss: 0.5611 - val_acc: 0.6979\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5231 - acc: 0.7135 - val_loss: 0.5602 - val_acc: 0.7031\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5220 - acc: 0.7135 - val_loss: 0.5593 - val_acc: 0.7031\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5210 - acc: 0.7135 - val_loss: 0.5585 - val_acc: 0.7031\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5201 - acc: 0.7170 - val_loss: 0.5577 - val_acc: 0.7031\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5191 - acc: 0.7170 - val_loss: 0.5568 - val_acc: 0.7083\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.5181 - acc: 0.7153 - val_loss: 0.5560 - val_acc: 0.7083\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5172 - acc: 0.7170 - val_loss: 0.5553 - val_acc: 0.7083\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5163 - acc: 0.7188 - val_loss: 0.5545 - val_acc: 0.7083\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5154 - acc: 0.7222 - val_loss: 0.5538 - val_acc: 0.7083\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5145 - acc: 0.7240 - val_loss: 0.5531 - val_acc: 0.7083\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5136 - acc: 0.7240 - val_loss: 0.5524 - val_acc: 0.7083\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5128 - acc: 0.7257 - val_loss: 0.5517 - val_acc: 0.7083\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5119 - acc: 0.7240 - val_loss: 0.5510 - val_acc: 0.7083\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5111 - acc: 0.7240 - val_loss: 0.5504 - val_acc: 0.7083\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5104 - acc: 0.7240 - val_loss: 0.5497 - val_acc: 0.7083\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5095 - acc: 0.7222 - val_loss: 0.5491 - val_acc: 0.7083\n",
      "Epoch 84/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5087 - acc: 0.7222 - val_loss: 0.5485 - val_acc: 0.7083\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5080 - acc: 0.7222 - val_loss: 0.5478 - val_acc: 0.7083\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5072 - acc: 0.7205 - val_loss: 0.5472 - val_acc: 0.7031\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5065 - acc: 0.7222 - val_loss: 0.5467 - val_acc: 0.7031\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5057 - acc: 0.7240 - val_loss: 0.5461 - val_acc: 0.7031\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5050 - acc: 0.7222 - val_loss: 0.5455 - val_acc: 0.7031\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5043 - acc: 0.7274 - val_loss: 0.5450 - val_acc: 0.7083\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5036 - acc: 0.7292 - val_loss: 0.5444 - val_acc: 0.7083\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5029 - acc: 0.7309 - val_loss: 0.5439 - val_acc: 0.7083\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5022 - acc: 0.7292 - val_loss: 0.5433 - val_acc: 0.7083\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.5015 - acc: 0.7309 - val_loss: 0.5428 - val_acc: 0.7083\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5009 - acc: 0.7326 - val_loss: 0.5423 - val_acc: 0.7135\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5002 - acc: 0.7309 - val_loss: 0.5418 - val_acc: 0.7135\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4996 - acc: 0.7344 - val_loss: 0.5413 - val_acc: 0.7135\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4990 - acc: 0.7344 - val_loss: 0.5408 - val_acc: 0.7135\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4984 - acc: 0.7344 - val_loss: 0.5403 - val_acc: 0.7135\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4978 - acc: 0.7344 - val_loss: 0.5398 - val_acc: 0.7135\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4972 - acc: 0.7344 - val_loss: 0.5394 - val_acc: 0.7135\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4966 - acc: 0.7361 - val_loss: 0.5389 - val_acc: 0.7135\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4960 - acc: 0.7361 - val_loss: 0.5384 - val_acc: 0.7135\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4954 - acc: 0.7361 - val_loss: 0.5380 - val_acc: 0.7135\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4949 - acc: 0.7361 - val_loss: 0.5375 - val_acc: 0.7083\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4943 - acc: 0.7378 - val_loss: 0.5371 - val_acc: 0.7083\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4938 - acc: 0.7361 - val_loss: 0.5367 - val_acc: 0.7083\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4932 - acc: 0.7396 - val_loss: 0.5362 - val_acc: 0.7083\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4927 - acc: 0.7413 - val_loss: 0.5358 - val_acc: 0.7083\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4921 - acc: 0.7431 - val_loss: 0.5354 - val_acc: 0.7135\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4916 - acc: 0.7431 - val_loss: 0.5350 - val_acc: 0.7135\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4911 - acc: 0.7448 - val_loss: 0.5346 - val_acc: 0.7135\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4906 - acc: 0.7431 - val_loss: 0.5342 - val_acc: 0.7188\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4901 - acc: 0.7431 - val_loss: 0.5338 - val_acc: 0.7188\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4896 - acc: 0.7431 - val_loss: 0.5334 - val_acc: 0.7188\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4891 - acc: 0.7448 - val_loss: 0.5330 - val_acc: 0.7240\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4887 - acc: 0.7465 - val_loss: 0.5326 - val_acc: 0.7240\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4882 - acc: 0.7448 - val_loss: 0.5323 - val_acc: 0.7240\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4877 - acc: 0.7465 - val_loss: 0.5319 - val_acc: 0.7292\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4872 - acc: 0.7483 - val_loss: 0.5316 - val_acc: 0.7344\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 41us/step - loss: 0.4867 - acc: 0.7483 - val_loss: 0.5312 - val_acc: 0.7344\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4863 - acc: 0.7465 - val_loss: 0.5309 - val_acc: 0.7344\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4858 - acc: 0.7483 - val_loss: 0.5305 - val_acc: 0.7344\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4854 - acc: 0.7483 - val_loss: 0.5302 - val_acc: 0.7396\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4850 - acc: 0.7483 - val_loss: 0.5298 - val_acc: 0.7396\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4845 - acc: 0.7500 - val_loss: 0.5295 - val_acc: 0.7396\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4841 - acc: 0.7500 - val_loss: 0.5292 - val_acc: 0.7396\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4837 - acc: 0.7500 - val_loss: 0.5289 - val_acc: 0.7396\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4832 - acc: 0.7500 - val_loss: 0.5285 - val_acc: 0.7396\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4828 - acc: 0.7483 - val_loss: 0.5282 - val_acc: 0.7396\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4824 - acc: 0.7500 - val_loss: 0.5279 - val_acc: 0.7396\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4820 - acc: 0.7500 - val_loss: 0.5276 - val_acc: 0.7396\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4816 - acc: 0.7517 - val_loss: 0.5274 - val_acc: 0.7344\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4812 - acc: 0.7500 - val_loss: 0.5271 - val_acc: 0.7344\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4809 - acc: 0.7517 - val_loss: 0.5268 - val_acc: 0.7292\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4805 - acc: 0.7517 - val_loss: 0.5265 - val_acc: 0.7292\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4801 - acc: 0.7517 - val_loss: 0.5262 - val_acc: 0.7344\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4798 - acc: 0.7535 - val_loss: 0.5260 - val_acc: 0.7344\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4794 - acc: 0.7517 - val_loss: 0.5257 - val_acc: 0.7344\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4790 - acc: 0.7535 - val_loss: 0.5254 - val_acc: 0.7396\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4787 - acc: 0.7535 - val_loss: 0.5252 - val_acc: 0.7396\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4784 - acc: 0.7535 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4780 - acc: 0.7552 - val_loss: 0.5247 - val_acc: 0.7448\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4777 - acc: 0.7587 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4773 - acc: 0.7569 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4770 - acc: 0.7587 - val_loss: 0.5239 - val_acc: 0.7448\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4767 - acc: 0.7604 - val_loss: 0.5237 - val_acc: 0.7448\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4764 - acc: 0.7604 - val_loss: 0.5234 - val_acc: 0.7448\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4760 - acc: 0.7622 - val_loss: 0.5232 - val_acc: 0.7448\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4757 - acc: 0.7622 - val_loss: 0.5230 - val_acc: 0.7448\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4754 - acc: 0.7639 - val_loss: 0.5228 - val_acc: 0.7448\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4751 - acc: 0.7622 - val_loss: 0.5225 - val_acc: 0.7448\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4748 - acc: 0.7622 - val_loss: 0.5223 - val_acc: 0.7448\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4745 - acc: 0.7604 - val_loss: 0.5221 - val_acc: 0.7448\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4742 - acc: 0.7622 - val_loss: 0.5219 - val_acc: 0.7448\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4739 - acc: 0.7639 - val_loss: 0.5216 - val_acc: 0.7448\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4736 - acc: 0.7622 - val_loss: 0.5214 - val_acc: 0.7448\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4733 - acc: 0.7639 - val_loss: 0.5212 - val_acc: 0.7448\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4730 - acc: 0.7639 - val_loss: 0.5210 - val_acc: 0.7448\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4727 - acc: 0.7622 - val_loss: 0.5208 - val_acc: 0.7448\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4725 - acc: 0.7622 - val_loss: 0.5206 - val_acc: 0.7448\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4722 - acc: 0.7622 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4719 - acc: 0.7639 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4716 - acc: 0.7639 - val_loss: 0.5200 - val_acc: 0.7396\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4714 - acc: 0.7639 - val_loss: 0.5198 - val_acc: 0.7396\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4711 - acc: 0.7622 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 167/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4708 - acc: 0.7622 - val_loss: 0.5195 - val_acc: 0.7396\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4706 - acc: 0.7622 - val_loss: 0.5193 - val_acc: 0.7396\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4703 - acc: 0.7622 - val_loss: 0.5191 - val_acc: 0.7396\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4701 - acc: 0.7622 - val_loss: 0.5189 - val_acc: 0.7396\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4698 - acc: 0.7639 - val_loss: 0.5187 - val_acc: 0.7396\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4695 - acc: 0.7639 - val_loss: 0.5186 - val_acc: 0.7396\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4693 - acc: 0.7656 - val_loss: 0.5184 - val_acc: 0.7448\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4690 - acc: 0.7656 - val_loss: 0.5182 - val_acc: 0.7448\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4688 - acc: 0.7656 - val_loss: 0.5180 - val_acc: 0.7448\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4685 - acc: 0.7656 - val_loss: 0.5179 - val_acc: 0.7448\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4683 - acc: 0.7656 - val_loss: 0.5177 - val_acc: 0.7448\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4681 - acc: 0.7691 - val_loss: 0.5175 - val_acc: 0.7448\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4678 - acc: 0.7674 - val_loss: 0.5174 - val_acc: 0.7448\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4676 - acc: 0.7674 - val_loss: 0.5172 - val_acc: 0.7448\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4674 - acc: 0.7708 - val_loss: 0.5170 - val_acc: 0.7448\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4672 - acc: 0.7708 - val_loss: 0.5169 - val_acc: 0.7448\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4669 - acc: 0.7708 - val_loss: 0.5167 - val_acc: 0.7448\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4667 - acc: 0.7691 - val_loss: 0.5166 - val_acc: 0.7448\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4665 - acc: 0.7691 - val_loss: 0.5164 - val_acc: 0.7396\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4663 - acc: 0.7691 - val_loss: 0.5163 - val_acc: 0.7396\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4660 - acc: 0.7691 - val_loss: 0.5161 - val_acc: 0.7396\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4658 - acc: 0.7691 - val_loss: 0.5160 - val_acc: 0.7396\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4656 - acc: 0.7691 - val_loss: 0.5158 - val_acc: 0.7396\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4654 - acc: 0.7674 - val_loss: 0.5156 - val_acc: 0.7396\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4652 - acc: 0.7691 - val_loss: 0.5155 - val_acc: 0.7396\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4649 - acc: 0.7674 - val_loss: 0.5153 - val_acc: 0.7396\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4647 - acc: 0.7674 - val_loss: 0.5152 - val_acc: 0.7448\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4645 - acc: 0.7691 - val_loss: 0.5150 - val_acc: 0.7448\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4643 - acc: 0.7691 - val_loss: 0.5149 - val_acc: 0.7448\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4641 - acc: 0.7674 - val_loss: 0.5147 - val_acc: 0.7448\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4639 - acc: 0.7691 - val_loss: 0.5146 - val_acc: 0.7448\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4637 - acc: 0.7691 - val_loss: 0.5144 - val_acc: 0.7448\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4635 - acc: 0.7691 - val_loss: 0.5143 - val_acc: 0.7448\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4633 - acc: 0.7674 - val_loss: 0.5142 - val_acc: 0.7448\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]\n",
    "y_pred_class_nn_1 #Resulting prediction for every single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47158974],\n",
       "       [0.7717504 ],\n",
       "       [0.2936714 ],\n",
       "       [0.4548161 ],\n",
       "       [0.20817392],\n",
       "       [0.52120703],\n",
       "       [0.04707582],\n",
       "       [0.4031567 ],\n",
       "       [0.7208713 ],\n",
       "       [0.20087609]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions' results from the test casa\n",
    "y_pred_prob_nn_1[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.745\n",
      "roc-auc is 0.807\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa244236b00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4631 - acc: 0.7674 - val_loss: 0.5140 - val_acc: 0.7448\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4630 - acc: 0.7674 - val_loss: 0.5139 - val_acc: 0.7448\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4628 - acc: 0.7674 - val_loss: 0.5138 - val_acc: 0.7448\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4626 - acc: 0.7674 - val_loss: 0.5137 - val_acc: 0.7448\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4624 - acc: 0.7674 - val_loss: 0.5135 - val_acc: 0.7448\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4622 - acc: 0.7691 - val_loss: 0.5134 - val_acc: 0.7448\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4620 - acc: 0.7674 - val_loss: 0.5133 - val_acc: 0.7448\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4619 - acc: 0.7674 - val_loss: 0.5132 - val_acc: 0.7448\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4617 - acc: 0.7708 - val_loss: 0.5130 - val_acc: 0.7448\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4615 - acc: 0.7691 - val_loss: 0.5129 - val_acc: 0.7448\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4613 - acc: 0.7674 - val_loss: 0.5128 - val_acc: 0.7448\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4612 - acc: 0.7691 - val_loss: 0.5127 - val_acc: 0.7448\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4610 - acc: 0.7674 - val_loss: 0.5126 - val_acc: 0.7500\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4608 - acc: 0.7674 - val_loss: 0.5125 - val_acc: 0.7500\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4606 - acc: 0.7708 - val_loss: 0.5123 - val_acc: 0.7500\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4605 - acc: 0.7726 - val_loss: 0.5122 - val_acc: 0.7500\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4603 - acc: 0.7708 - val_loss: 0.5121 - val_acc: 0.7500\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4601 - acc: 0.7708 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4600 - acc: 0.7726 - val_loss: 0.5119 - val_acc: 0.7500\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4598 - acc: 0.7708 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4597 - acc: 0.7726 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4595 - acc: 0.7726 - val_loss: 0.5116 - val_acc: 0.7500\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4593 - acc: 0.7726 - val_loss: 0.5115 - val_acc: 0.7500\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4591 - acc: 0.7726 - val_loss: 0.5114 - val_acc: 0.7500\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4590 - acc: 0.7726 - val_loss: 0.5113 - val_acc: 0.7500\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4588 - acc: 0.7708 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4587 - acc: 0.7708 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4585 - acc: 0.7708 - val_loss: 0.5110 - val_acc: 0.7500\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4584 - acc: 0.7708 - val_loss: 0.5109 - val_acc: 0.7500\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4582 - acc: 0.7708 - val_loss: 0.5108 - val_acc: 0.7500\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4580 - acc: 0.7708 - val_loss: 0.5107 - val_acc: 0.7500\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4579 - acc: 0.7708 - val_loss: 0.5106 - val_acc: 0.7500\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4578 - acc: 0.7708 - val_loss: 0.5105 - val_acc: 0.7500\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4576 - acc: 0.7708 - val_loss: 0.5104 - val_acc: 0.7500\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4575 - acc: 0.7708 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4573 - acc: 0.7708 - val_loss: 0.5102 - val_acc: 0.7500\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4572 - acc: 0.7708 - val_loss: 0.5101 - val_acc: 0.7500\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4570 - acc: 0.7726 - val_loss: 0.5101 - val_acc: 0.7500\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4569 - acc: 0.7726 - val_loss: 0.5100 - val_acc: 0.7500\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4567 - acc: 0.7708 - val_loss: 0.5099 - val_acc: 0.7552\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4566 - acc: 0.7708 - val_loss: 0.5098 - val_acc: 0.7552\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4565 - acc: 0.7708 - val_loss: 0.5097 - val_acc: 0.7552\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4564 - acc: 0.7708 - val_loss: 0.5096 - val_acc: 0.7552\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4562 - acc: 0.7726 - val_loss: 0.5096 - val_acc: 0.7552\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4561 - acc: 0.7760 - val_loss: 0.5095 - val_acc: 0.7552\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4559 - acc: 0.7743 - val_loss: 0.5094 - val_acc: 0.7552\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4558 - acc: 0.7743 - val_loss: 0.5093 - val_acc: 0.7552\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4557 - acc: 0.7760 - val_loss: 0.5093 - val_acc: 0.7552\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4555 - acc: 0.7743 - val_loss: 0.5092 - val_acc: 0.7552\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4554 - acc: 0.7778 - val_loss: 0.5091 - val_acc: 0.7552\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4553 - acc: 0.7760 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4552 - acc: 0.7760 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4551 - acc: 0.7778 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4549 - acc: 0.7760 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4548 - acc: 0.7778 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4547 - acc: 0.7760 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4546 - acc: 0.7778 - val_loss: 0.5086 - val_acc: 0.7552\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4545 - acc: 0.7778 - val_loss: 0.5085 - val_acc: 0.7552\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4543 - acc: 0.7778 - val_loss: 0.5085 - val_acc: 0.7552\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4542 - acc: 0.7778 - val_loss: 0.5084 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4541 - acc: 0.7778 - val_loss: 0.5083 - val_acc: 0.7552\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4540 - acc: 0.7778 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4539 - acc: 0.7760 - val_loss: 0.5082 - val_acc: 0.7500\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4538 - acc: 0.7778 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4536 - acc: 0.7778 - val_loss: 0.5081 - val_acc: 0.7500\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4535 - acc: 0.7778 - val_loss: 0.5080 - val_acc: 0.7500\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4534 - acc: 0.7778 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4533 - acc: 0.7795 - val_loss: 0.5079 - val_acc: 0.7500\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4532 - acc: 0.7795 - val_loss: 0.5078 - val_acc: 0.7500\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4531 - acc: 0.7778 - val_loss: 0.5077 - val_acc: 0.7552\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4529 - acc: 0.7795 - val_loss: 0.5077 - val_acc: 0.7552\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4528 - acc: 0.7778 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4527 - acc: 0.7795 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4526 - acc: 0.7795 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4525 - acc: 0.7812 - val_loss: 0.5074 - val_acc: 0.7604\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4523 - acc: 0.7812 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4522 - acc: 0.7830 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4521 - acc: 0.7812 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4520 - acc: 0.7812 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4519 - acc: 0.7830 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4518 - acc: 0.7830 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4517 - acc: 0.7847 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4515 - acc: 0.7847 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4514 - acc: 0.7830 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4513 - acc: 0.7830 - val_loss: 0.5068 - val_acc: 0.7552\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4512 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4511 - acc: 0.7830 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4510 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4509 - acc: 0.7830 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4508 - acc: 0.7865 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4507 - acc: 0.7865 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4505 - acc: 0.7882 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4504 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4503 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4502 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4501 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4500 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4499 - acc: 0.7882 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4498 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4497 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4496 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4495 - acc: 0.7899 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4494 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4492 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4492 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7604\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4490 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7604\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4489 - acc: 0.7882 - val_loss: 0.5056 - val_acc: 0.7604\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4489 - acc: 0.7865 - val_loss: 0.5056 - val_acc: 0.7604\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4487 - acc: 0.7882 - val_loss: 0.5056 - val_acc: 0.7604\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4486 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7604\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4485 - acc: 0.7865 - val_loss: 0.5055 - val_acc: 0.7604\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4484 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7604\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4483 - acc: 0.7865 - val_loss: 0.5054 - val_acc: 0.7604\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4482 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7604\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4481 - acc: 0.7865 - val_loss: 0.5053 - val_acc: 0.7604\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4480 - acc: 0.7882 - val_loss: 0.5053 - val_acc: 0.7604\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4479 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7604\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4478 - acc: 0.7865 - val_loss: 0.5052 - val_acc: 0.7604\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4477 - acc: 0.7865 - val_loss: 0.5052 - val_acc: 0.7604\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4476 - acc: 0.7865 - val_loss: 0.5051 - val_acc: 0.7604\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4476 - acc: 0.7865 - val_loss: 0.5051 - val_acc: 0.7604\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4474 - acc: 0.7882 - val_loss: 0.5051 - val_acc: 0.7604\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4474 - acc: 0.7865 - val_loss: 0.5050 - val_acc: 0.7604\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4473 - acc: 0.7865 - val_loss: 0.5050 - val_acc: 0.7604\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4472 - acc: 0.7882 - val_loss: 0.5050 - val_acc: 0.7604\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4470 - acc: 0.7865 - val_loss: 0.5049 - val_acc: 0.7604\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4470 - acc: 0.7882 - val_loss: 0.5049 - val_acc: 0.7604\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4469 - acc: 0.7865 - val_loss: 0.5049 - val_acc: 0.7604\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4468 - acc: 0.7865 - val_loss: 0.5048 - val_acc: 0.7604\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4467 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7604\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4466 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7604\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4465 - acc: 0.7882 - val_loss: 0.5048 - val_acc: 0.7604\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4464 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7604\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4463 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7604\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4462 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7604\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4461 - acc: 0.7882 - val_loss: 0.5047 - val_acc: 0.7604\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4461 - acc: 0.7865 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4460 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4459 - acc: 0.7865 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4458 - acc: 0.7882 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4457 - acc: 0.7865 - val_loss: 0.5046 - val_acc: 0.7604\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4456 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4455 - acc: 0.7882 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4455 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4454 - acc: 0.7865 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4453 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4452 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4452 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4450 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4450 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4449 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4448 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4447 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4447 - acc: 0.7847 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4445 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4445 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4444 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7604\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4443 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4442 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4440 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4439 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4438 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4437 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4437 - acc: 0.7847 - val_loss: 0.5042 - val_acc: 0.7604\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4436 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4435 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4434 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4433 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4433 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4432 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4431 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.4430 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7604\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4429 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4429 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4428 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4427 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4426 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4426 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4425 - acc: 0.7847 - val_loss: 0.5041 - val_acc: 0.7552\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4424 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4423 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4423 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4422 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4421 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4421 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4420 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7552\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4419 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4418 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4417 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4417 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4416 - acc: 0.7847 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4415 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4414 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4414 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4413 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4412 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4411 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4410 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4409 - acc: 0.7882 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4409 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4408 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4407 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4406 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4406 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4405 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4404 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4404 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4403 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4402 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4401 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4401 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4400 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4399 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4399 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4398 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4397 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4396 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4395 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4394 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4394 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4393 - acc: 0.7882 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4392 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4391 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4390 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4389 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4388 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7604\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4387 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4386 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4384 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7604\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4382 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4380 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4380 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4379 - acc: 0.7865 - val_loss: 0.5040 - val_acc: 0.7656\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4378 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4378 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4375 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4375 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4375 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4374 - acc: 0.7865 - val_loss: 0.5041 - val_acc: 0.7656\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4373 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4372 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4370 - acc: 0.7865 - val_loss: 0.5042 - val_acc: 0.7656\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4368 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4368 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4367 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4366 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4366 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4365 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4365 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4364 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4364 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4363 - acc: 0.7847 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4363 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4362 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4362 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4361 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4361 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4360 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4360 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4359 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4359 - acc: 0.7865 - val_loss: 0.5043 - val_acc: 0.7656\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4358 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4358 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4357 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4357 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4356 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7604\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4355 - acc: 0.7865 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4355 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4354 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4354 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4354 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4353 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4352 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4351 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4351 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4350 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4350 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4349 - acc: 0.7830 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4349 - acc: 0.7847 - val_loss: 0.5044 - val_acc: 0.7656\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4348 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4348 - acc: 0.7830 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4347 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4347 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4346 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4346 - acc: 0.7830 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4345 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4345 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4344 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4344 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4343 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4343 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4342 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4342 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4342 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7656\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4341 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7708\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4340 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7708\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4340 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7708\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4339 - acc: 0.7847 - val_loss: 0.5045 - val_acc: 0.7708\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4339 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4338 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4338 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4337 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4337 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4336 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4335 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4335 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4335 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4334 - acc: 0.7847 - val_loss: 0.5046 - val_acc: 0.7708\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4334 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7708\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4333 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7708\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4333 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4332 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4332 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4331 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4331 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4331 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4330 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4330 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4329 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4329 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4328 - acc: 0.7847 - val_loss: 0.5047 - val_acc: 0.7656\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4328 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4327 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4327 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4326 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4326 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4326 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4325 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4325 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4324 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4324 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4323 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4323 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.5048 - val_acc: 0.7656\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4321 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4321 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4320 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4320 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4319 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4319 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4319 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4318 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4317 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4317 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4317 - acc: 0.7847 - val_loss: 0.5049 - val_acc: 0.7656\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4316 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4316 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4316 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4315 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4315 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4315 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4314 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4314 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4313 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4313 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4312 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4312 - acc: 0.7847 - val_loss: 0.5050 - val_acc: 0.7656\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4311 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4311 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4311 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4310 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4310 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4310 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4309 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4309 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4308 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4308 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4307 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4307 - acc: 0.7847 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4307 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4305 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4305 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4304 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4304 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4304 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4303 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4303 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4303 - acc: 0.7847 - val_loss: 0.5052 - val_acc: 0.7656\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4302 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4302 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4301 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4301 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4301 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4300 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4300 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4299 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4299 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4299 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4298 - acc: 0.7847 - val_loss: 0.5053 - val_acc: 0.7656\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4298 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4298 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4297 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4296 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4296 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4296 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4295 - acc: 0.7847 - val_loss: 0.5054 - val_acc: 0.7656\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4295 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4295 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4294 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4293 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5055 - val_acc: 0.7656\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4292 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4291 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4290 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4289 - acc: 0.7847 - val_loss: 0.5056 - val_acc: 0.7656\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4289 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4288 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4288 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4288 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4287 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4287 - acc: 0.7865 - val_loss: 0.5057 - val_acc: 0.7656\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4287 - acc: 0.7882 - val_loss: 0.5057 - val_acc: 0.7604\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4287 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4286 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4286 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4285 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4285 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4285 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4285 - acc: 0.7882 - val_loss: 0.5058 - val_acc: 0.7604\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4284 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4284 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4283 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4282 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4282 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4282 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4281 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4281 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4280 - acc: 0.7882 - val_loss: 0.5059 - val_acc: 0.7604\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4280 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4280 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4280 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4279 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4279 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4278 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - acc: 0.7882 - val_loss: 0.5060 - val_acc: 0.7604\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4277 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4277 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4276 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4276 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4276 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5061 - val_acc: 0.7604\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - acc: 0.7865 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4274 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4274 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4274 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4273 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4272 - acc: 0.7882 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4272 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7604\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4272 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4271 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4271 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4271 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4270 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4270 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4270 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4269 - acc: 0.7899 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4269 - acc: 0.7882 - val_loss: 0.5063 - val_acc: 0.7604\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4268 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4268 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4268 - acc: 0.7917 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4267 - acc: 0.7882 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4267 - acc: 0.7917 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4267 - acc: 0.7917 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4267 - acc: 0.7882 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4266 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4266 - acc: 0.7899 - val_loss: 0.5064 - val_acc: 0.7604\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4265 - acc: 0.7917 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4265 - acc: 0.7934 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4265 - acc: 0.7917 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4265 - acc: 0.7934 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4264 - acc: 0.7917 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4264 - acc: 0.7899 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4264 - acc: 0.7917 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4263 - acc: 0.7917 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4263 - acc: 0.7899 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4263 - acc: 0.7899 - val_loss: 0.5065 - val_acc: 0.7604\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4263 - acc: 0.7917 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - acc: 0.7899 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4262 - acc: 0.7899 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4262 - acc: 0.7899 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4261 - acc: 0.7917 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4261 - acc: 0.7917 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4261 - acc: 0.7899 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4260 - acc: 0.7899 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4260 - acc: 0.7917 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4260 - acc: 0.7917 - val_loss: 0.5066 - val_acc: 0.7604\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4260 - acc: 0.7899 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - acc: 0.7899 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4259 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4259 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4258 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4258 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4258 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4258 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4257 - acc: 0.7917 - val_loss: 0.5067 - val_acc: 0.7604\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4257 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4256 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4256 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4256 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4256 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4255 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4255 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4255 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - acc: 0.7917 - val_loss: 0.5068 - val_acc: 0.7604\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4254 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4254 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4254 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4254 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4254 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4253 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4253 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4252 - acc: 0.7917 - val_loss: 0.5069 - val_acc: 0.7604\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4252 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4252 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4252 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4251 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4251 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4251 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.5070 - val_acc: 0.7604\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4249 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4249 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4249 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4249 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4248 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4248 - acc: 0.7917 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4248 - acc: 0.7934 - val_loss: 0.5071 - val_acc: 0.7604\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4248 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4247 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4247 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4247 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4246 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4246 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4246 - acc: 0.7917 - val_loss: 0.5072 - val_acc: 0.7604\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4246 - acc: 0.7917 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4245 - acc: 0.7934 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4245 - acc: 0.7917 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4245 - acc: 0.7934 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4245 - acc: 0.7934 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4244 - acc: 0.7917 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4244 - acc: 0.7934 - val_loss: 0.5073 - val_acc: 0.7604\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4244 - acc: 0.7951 - val_loss: 0.5073 - val_acc: 0.7552\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4244 - acc: 0.7951 - val_loss: 0.5074 - val_acc: 0.7604\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4243 - acc: 0.7934 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4243 - acc: 0.7934 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4243 - acc: 0.7951 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4242 - acc: 0.7951 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4242 - acc: 0.7951 - val_loss: 0.5074 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4242 - acc: 0.7934 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4242 - acc: 0.7934 - val_loss: 0.5074 - val_acc: 0.7552\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - acc: 0.7934 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4241 - acc: 0.7951 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4241 - acc: 0.7951 - val_loss: 0.5075 - val_acc: 0.7552\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4240 - acc: 0.7934 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4241 - acc: 0.7934 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4240 - acc: 0.7934 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4240 - acc: 0.7934 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4239 - acc: 0.7951 - val_loss: 0.5075 - val_acc: 0.7604\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4240 - acc: 0.7951 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - acc: 0.7951 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4239 - acc: 0.7934 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4239 - acc: 0.7934 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4238 - acc: 0.7951 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4238 - acc: 0.7951 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4238 - acc: 0.7934 - val_loss: 0.5076 - val_acc: 0.7604\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4238 - acc: 0.7951 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4237 - acc: 0.7934 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4237 - acc: 0.7951 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4237 - acc: 0.7951 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4237 - acc: 0.7951 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4236 - acc: 0.7934 - val_loss: 0.5077 - val_acc: 0.7604\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4235 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4234 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4234 - acc: 0.7934 - val_loss: 0.5078 - val_acc: 0.7604\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4234 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4233 - acc: 0.7917 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4232 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4233 - acc: 0.7934 - val_loss: 0.5079 - val_acc: 0.7604\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4232 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4232 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4232 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4231 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4231 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5080 - val_acc: 0.7604\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4231 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4230 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4229 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4228 - acc: 0.7934 - val_loss: 0.5081 - val_acc: 0.7604\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4228 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4228 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4228 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5082 - val_acc: 0.7604\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4226 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4227 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4226 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4226 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4225 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4226 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4225 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4225 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4225 - acc: 0.7934 - val_loss: 0.5083 - val_acc: 0.7604\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4224 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4224 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4224 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4224 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4223 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4222 - acc: 0.7934 - val_loss: 0.5084 - val_acc: 0.7604\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4222 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4222 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4222 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4222 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - acc: 0.7917 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4220 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4220 - acc: 0.7934 - val_loss: 0.5085 - val_acc: 0.7604\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4220 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4220 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4219 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4219 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4219 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4219 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4219 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4218 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4218 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4218 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4217 - acc: 0.7934 - val_loss: 0.5086 - val_acc: 0.7604\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4217 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4216 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4216 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4216 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7604\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - acc: 0.7934 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4215 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5087 - val_acc: 0.7552\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4213 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5088 - val_acc: 0.7552\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4211 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5089 - val_acc: 0.7552\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4210 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4208 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4208 - acc: 0.7934 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4208 - acc: 0.7934 - val_loss: 0.5090 - val_acc: 0.7552\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4207 - acc: 0.7917 - val_loss: 0.5090 - val_acc: 0.7604\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4207 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4207 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4207 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4207 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4206 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4206 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4205 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4205 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4205 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4205 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4204 - acc: 0.7917 - val_loss: 0.5091 - val_acc: 0.7604\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4204 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4203 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4203 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4202 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4202 - acc: 0.7899 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4202 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4202 - acc: 0.7934 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - acc: 0.7917 - val_loss: 0.5092 - val_acc: 0.7604\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4201 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4201 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4201 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7552\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4201 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7552\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4200 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4200 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7552\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4200 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7552\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4200 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4199 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4199 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4199 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4199 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4198 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4198 - acc: 0.7934 - val_loss: 0.5093 - val_acc: 0.7604\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4198 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4198 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4197 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4197 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4196 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4195 - acc: 0.7934 - val_loss: 0.5094 - val_acc: 0.7604\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4195 - acc: 0.7917 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4194 - acc: 0.7917 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4194 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4193 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4193 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4193 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4193 - acc: 0.7934 - val_loss: 0.5095 - val_acc: 0.7604\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4193 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4192 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4192 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4192 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4191 - acc: 0.7917 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4191 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4192 - acc: 0.7917 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4191 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4191 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4191 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - acc: 0.7934 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4190 - acc: 0.7917 - val_loss: 0.5096 - val_acc: 0.7604\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4190 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7604\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7604\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4190 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7604\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4189 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7604\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4189 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7656\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4189 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7656\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4189 - acc: 0.7917 - val_loss: 0.5097 - val_acc: 0.7656\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4188 - acc: 0.7917 - val_loss: 0.5097 - val_acc: 0.7656\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4188 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7656\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4188 - acc: 0.7934 - val_loss: 0.5097 - val_acc: 0.7656\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4188 - acc: 0.7917 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4187 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4187 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4187 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4187 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4186 - acc: 0.7917 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4186 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4186 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - acc: 0.7917 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4186 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4185 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4185 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4185 - acc: 0.7917 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4185 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4184 - acc: 0.7934 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4184 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4184 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4184 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4184 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4183 - acc: 0.7917 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4183 - acc: 0.7917 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4183 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4183 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4182 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4182 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - acc: 0.7917 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4182 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4182 - acc: 0.7934 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4181 - acc: 0.7917 - val_loss: 0.5099 - val_acc: 0.7656\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4181 - acc: 0.7934 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4181 - acc: 0.7934 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - acc: 0.7934 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4180 - acc: 0.7934 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4180 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4180 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4180 - acc: 0.7934 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4179 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4179 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4179 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4179 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4179 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4179 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4178 - acc: 0.7917 - val_loss: 0.5100 - val_acc: 0.7656\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4178 - acc: 0.7934 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4178 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4178 - acc: 0.7934 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4177 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4177 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4177 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4176 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4176 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4176 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4176 - acc: 0.7917 - val_loss: 0.5101 - val_acc: 0.7656\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4176 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4175 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4175 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4175 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4174 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4174 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4174 - acc: 0.7917 - val_loss: 0.5102 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4172 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4172 - acc: 0.7951 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4172 - acc: 0.7917 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4171 - acc: 0.7951 - val_loss: 0.5103 - val_acc: 0.7656\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4171 - acc: 0.7934 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4171 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4171 - acc: 0.7917 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4171 - acc: 0.7917 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - acc: 0.7934 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4170 - acc: 0.7934 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4170 - acc: 0.7934 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4170 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - acc: 0.7934 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4169 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4169 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4169 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4169 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4168 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4168 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4168 - acc: 0.7969 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4168 - acc: 0.7951 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4167 - acc: 0.7969 - val_loss: 0.5104 - val_acc: 0.7656\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4167 - acc: 0.7951 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4167 - acc: 0.7951 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4167 - acc: 0.7934 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4166 - acc: 0.7969 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4166 - acc: 0.7951 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4166 - acc: 0.7951 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4166 - acc: 0.7969 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4166 - acc: 0.7986 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - acc: 0.7951 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4165 - acc: 0.7969 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - acc: 0.7969 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4164 - acc: 0.7986 - val_loss: 0.5105 - val_acc: 0.7656\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4164 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4164 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4164 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4163 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4163 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4163 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4162 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4162 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - acc: 0.7969 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4162 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4161 - acc: 0.7986 - val_loss: 0.5106 - val_acc: 0.7656\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - acc: 0.7986 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4161 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4161 - acc: 0.7986 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4161 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4160 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4160 - acc: 0.7986 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4160 - acc: 0.7969 - val_loss: 0.5107 - val_acc: 0.7656\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4159 - acc: 0.7969 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4159 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4159 - acc: 0.7969 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4159 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4159 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4158 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4158 - acc: 0.8003 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4157 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4158 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.7656\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4157 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4157 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4157 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - acc: 0.8003 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.7656\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4155 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4155 - acc: 0.7986 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4154 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4154 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4154 - acc: 0.7986 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4154 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5110 - val_acc: 0.7656\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4153 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4152 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4152 - acc: 0.8003 - val_loss: 0.5111 - val_acc: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa244155940>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 6 hidden nodes, relu activation\n",
    "# 1 hidden layer, 6 hidden nodes, relu activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "\n",
    "model_2 = Sequential([\n",
    "    #hidden layers\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, activation=\"relu\"),\n",
    "    #final layer\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 394us/step - loss: 0.7057 - acc: 0.5122 - val_loss: 0.7086 - val_acc: 0.5208\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.7005 - acc: 0.5260 - val_loss: 0.7038 - val_acc: 0.5365\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6955 - acc: 0.5330 - val_loss: 0.6993 - val_acc: 0.5417\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6909 - acc: 0.5417 - val_loss: 0.6950 - val_acc: 0.5521\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.6865 - acc: 0.5556 - val_loss: 0.6910 - val_acc: 0.5573\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6824 - acc: 0.5660 - val_loss: 0.6872 - val_acc: 0.5781\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6785 - acc: 0.5677 - val_loss: 0.6836 - val_acc: 0.5885\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.6747 - acc: 0.5868 - val_loss: 0.6802 - val_acc: 0.5833\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6711 - acc: 0.6042 - val_loss: 0.6769 - val_acc: 0.5833\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6678 - acc: 0.6146 - val_loss: 0.6738 - val_acc: 0.6042\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.6645 - acc: 0.6285 - val_loss: 0.6708 - val_acc: 0.6094\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6614 - acc: 0.6424 - val_loss: 0.6679 - val_acc: 0.6146\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6585 - acc: 0.6562 - val_loss: 0.6652 - val_acc: 0.6354\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.6557 - acc: 0.6632 - val_loss: 0.6626 - val_acc: 0.6458\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6530 - acc: 0.6649 - val_loss: 0.6601 - val_acc: 0.6510\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6504 - acc: 0.6632 - val_loss: 0.6577 - val_acc: 0.6562\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6479 - acc: 0.6667 - val_loss: 0.6555 - val_acc: 0.6615\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6455 - acc: 0.6667 - val_loss: 0.6533 - val_acc: 0.6562\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6433 - acc: 0.6736 - val_loss: 0.6512 - val_acc: 0.6667\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.6411 - acc: 0.6771 - val_loss: 0.6492 - val_acc: 0.6719\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.6391 - acc: 0.6753 - val_loss: 0.6472 - val_acc: 0.6875\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6371 - acc: 0.6701 - val_loss: 0.6454 - val_acc: 0.6927\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.6352 - acc: 0.6736 - val_loss: 0.6436 - val_acc: 0.6927\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6333 - acc: 0.6719 - val_loss: 0.6419 - val_acc: 0.6875\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6315 - acc: 0.6701 - val_loss: 0.6402 - val_acc: 0.6927\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6298 - acc: 0.6753 - val_loss: 0.6386 - val_acc: 0.6875\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6281 - acc: 0.6823 - val_loss: 0.6371 - val_acc: 0.6823\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.6265 - acc: 0.6823 - val_loss: 0.6356 - val_acc: 0.6719\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.6249 - acc: 0.6858 - val_loss: 0.6341 - val_acc: 0.6719\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6234 - acc: 0.6910 - val_loss: 0.6327 - val_acc: 0.6771\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6219 - acc: 0.6875 - val_loss: 0.6314 - val_acc: 0.6823\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.6204 - acc: 0.6892 - val_loss: 0.6300 - val_acc: 0.6771\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6190 - acc: 0.6858 - val_loss: 0.6287 - val_acc: 0.6771\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6175 - acc: 0.6840 - val_loss: 0.6275 - val_acc: 0.6771\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.6162 - acc: 0.6875 - val_loss: 0.6262 - val_acc: 0.6771\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6148 - acc: 0.6892 - val_loss: 0.6250 - val_acc: 0.6719\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.6135 - acc: 0.6840 - val_loss: 0.6238 - val_acc: 0.6771\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6122 - acc: 0.6840 - val_loss: 0.6227 - val_acc: 0.6771\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6110 - acc: 0.6840 - val_loss: 0.6216 - val_acc: 0.6771\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6097 - acc: 0.6858 - val_loss: 0.6205 - val_acc: 0.6771\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6085 - acc: 0.6927 - val_loss: 0.6194 - val_acc: 0.6771\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6073 - acc: 0.6962 - val_loss: 0.6183 - val_acc: 0.6771\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.6061 - acc: 0.6910 - val_loss: 0.6173 - val_acc: 0.6719\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.6050 - acc: 0.6875 - val_loss: 0.6163 - val_acc: 0.6823\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.6039 - acc: 0.6910 - val_loss: 0.6153 - val_acc: 0.6823\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.6028 - acc: 0.6927 - val_loss: 0.6144 - val_acc: 0.6823\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.6017 - acc: 0.6910 - val_loss: 0.6134 - val_acc: 0.6875\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.6006 - acc: 0.6927 - val_loss: 0.6125 - val_acc: 0.6823\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.5996 - acc: 0.6927 - val_loss: 0.6116 - val_acc: 0.6823\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.5986 - acc: 0.6927 - val_loss: 0.6107 - val_acc: 0.6823\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5976 - acc: 0.6944 - val_loss: 0.6099 - val_acc: 0.6823\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5966 - acc: 0.6944 - val_loss: 0.6090 - val_acc: 0.6823\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5956 - acc: 0.6944 - val_loss: 0.6082 - val_acc: 0.6771\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5946 - acc: 0.6962 - val_loss: 0.6073 - val_acc: 0.6771\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5936 - acc: 0.6962 - val_loss: 0.6065 - val_acc: 0.6771\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5927 - acc: 0.6979 - val_loss: 0.6057 - val_acc: 0.6771\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5917 - acc: 0.6997 - val_loss: 0.6049 - val_acc: 0.6771\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5908 - acc: 0.6997 - val_loss: 0.6041 - val_acc: 0.6771\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5898 - acc: 0.7014 - val_loss: 0.6033 - val_acc: 0.6771\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5889 - acc: 0.7031 - val_loss: 0.6026 - val_acc: 0.6771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5879 - acc: 0.7031 - val_loss: 0.6018 - val_acc: 0.6771\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.5870 - acc: 0.7031 - val_loss: 0.6011 - val_acc: 0.6771\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5862 - acc: 0.7049 - val_loss: 0.6003 - val_acc: 0.6771\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.5853 - acc: 0.7066 - val_loss: 0.5996 - val_acc: 0.6771\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5844 - acc: 0.7066 - val_loss: 0.5989 - val_acc: 0.6719\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5835 - acc: 0.7066 - val_loss: 0.5982 - val_acc: 0.6719\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5826 - acc: 0.7049 - val_loss: 0.5975 - val_acc: 0.6719\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5818 - acc: 0.7049 - val_loss: 0.5968 - val_acc: 0.6771\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5809 - acc: 0.7049 - val_loss: 0.5962 - val_acc: 0.6771\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5801 - acc: 0.7049 - val_loss: 0.5955 - val_acc: 0.6771\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5792 - acc: 0.7083 - val_loss: 0.5948 - val_acc: 0.6771\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5784 - acc: 0.7083 - val_loss: 0.5942 - val_acc: 0.6771\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5775 - acc: 0.7101 - val_loss: 0.5935 - val_acc: 0.6771\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5767 - acc: 0.7101 - val_loss: 0.5929 - val_acc: 0.6771\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5759 - acc: 0.7135 - val_loss: 0.5923 - val_acc: 0.6771\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5751 - acc: 0.7153 - val_loss: 0.5916 - val_acc: 0.6771\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5742 - acc: 0.7118 - val_loss: 0.5910 - val_acc: 0.6823\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5734 - acc: 0.7135 - val_loss: 0.5904 - val_acc: 0.6875\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5726 - acc: 0.7153 - val_loss: 0.5897 - val_acc: 0.6875\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5718 - acc: 0.7153 - val_loss: 0.5891 - val_acc: 0.6927\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5710 - acc: 0.7153 - val_loss: 0.5885 - val_acc: 0.6927\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5702 - acc: 0.7153 - val_loss: 0.5879 - val_acc: 0.6927\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5694 - acc: 0.7170 - val_loss: 0.5873 - val_acc: 0.6927\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5686 - acc: 0.7170 - val_loss: 0.5867 - val_acc: 0.6927\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5678 - acc: 0.7153 - val_loss: 0.5861 - val_acc: 0.6927\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5670 - acc: 0.7188 - val_loss: 0.5855 - val_acc: 0.6979\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5662 - acc: 0.7205 - val_loss: 0.5849 - val_acc: 0.6979\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5655 - acc: 0.7222 - val_loss: 0.5843 - val_acc: 0.6979\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5647 - acc: 0.7222 - val_loss: 0.5837 - val_acc: 0.7031\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5639 - acc: 0.7240 - val_loss: 0.5831 - val_acc: 0.7031\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5632 - acc: 0.7240 - val_loss: 0.5825 - val_acc: 0.7031\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.5624 - acc: 0.7257 - val_loss: 0.5820 - val_acc: 0.7031\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5616 - acc: 0.7274 - val_loss: 0.5814 - val_acc: 0.7031\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5609 - acc: 0.7257 - val_loss: 0.5808 - val_acc: 0.7083\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.5601 - acc: 0.7257 - val_loss: 0.5803 - val_acc: 0.7083\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5594 - acc: 0.7257 - val_loss: 0.5797 - val_acc: 0.7083\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5586 - acc: 0.7292 - val_loss: 0.5791 - val_acc: 0.7083\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5579 - acc: 0.7292 - val_loss: 0.5786 - val_acc: 0.7083\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5571 - acc: 0.7292 - val_loss: 0.5780 - val_acc: 0.7083\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5564 - acc: 0.7344 - val_loss: 0.5775 - val_acc: 0.7083\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5556 - acc: 0.7326 - val_loss: 0.5769 - val_acc: 0.7083\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5548 - acc: 0.7309 - val_loss: 0.5764 - val_acc: 0.7083\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5541 - acc: 0.7326 - val_loss: 0.5758 - val_acc: 0.7083\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5533 - acc: 0.7309 - val_loss: 0.5753 - val_acc: 0.7135\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5525 - acc: 0.7326 - val_loss: 0.5747 - val_acc: 0.7188\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5517 - acc: 0.7309 - val_loss: 0.5742 - val_acc: 0.7188\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5510 - acc: 0.7326 - val_loss: 0.5737 - val_acc: 0.7188\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5502 - acc: 0.7309 - val_loss: 0.5731 - val_acc: 0.7188\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5495 - acc: 0.7309 - val_loss: 0.5726 - val_acc: 0.7188\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.5487 - acc: 0.7344 - val_loss: 0.5720 - val_acc: 0.7188\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5479 - acc: 0.7344 - val_loss: 0.5715 - val_acc: 0.7188\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5472 - acc: 0.7344 - val_loss: 0.5710 - val_acc: 0.7188\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5464 - acc: 0.7326 - val_loss: 0.5704 - val_acc: 0.7135\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5457 - acc: 0.7344 - val_loss: 0.5699 - val_acc: 0.7135\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5450 - acc: 0.7344 - val_loss: 0.5694 - val_acc: 0.7135\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5442 - acc: 0.7378 - val_loss: 0.5689 - val_acc: 0.7135\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5435 - acc: 0.7361 - val_loss: 0.5684 - val_acc: 0.7135\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5427 - acc: 0.7378 - val_loss: 0.5679 - val_acc: 0.7135\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5420 - acc: 0.7378 - val_loss: 0.5674 - val_acc: 0.7135\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5413 - acc: 0.7378 - val_loss: 0.5669 - val_acc: 0.7135\n",
      "Epoch 121/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 30us/step - loss: 0.5407 - acc: 0.7396 - val_loss: 0.5664 - val_acc: 0.7135\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5400 - acc: 0.7431 - val_loss: 0.5659 - val_acc: 0.7083\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5393 - acc: 0.7431 - val_loss: 0.5654 - val_acc: 0.7083\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5386 - acc: 0.7431 - val_loss: 0.5650 - val_acc: 0.7083\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5380 - acc: 0.7431 - val_loss: 0.5645 - val_acc: 0.7083\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5373 - acc: 0.7431 - val_loss: 0.5640 - val_acc: 0.7031\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5367 - acc: 0.7448 - val_loss: 0.5636 - val_acc: 0.7083\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5360 - acc: 0.7448 - val_loss: 0.5631 - val_acc: 0.7083\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5354 - acc: 0.7448 - val_loss: 0.5627 - val_acc: 0.7083\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5347 - acc: 0.7448 - val_loss: 0.5622 - val_acc: 0.7135\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5341 - acc: 0.7448 - val_loss: 0.5618 - val_acc: 0.7188\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5335 - acc: 0.7448 - val_loss: 0.5613 - val_acc: 0.7188\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5329 - acc: 0.7448 - val_loss: 0.5609 - val_acc: 0.7188\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5323 - acc: 0.7448 - val_loss: 0.5605 - val_acc: 0.7135\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5316 - acc: 0.7431 - val_loss: 0.5600 - val_acc: 0.7135\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5311 - acc: 0.7431 - val_loss: 0.5596 - val_acc: 0.7135\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5304 - acc: 0.7431 - val_loss: 0.5592 - val_acc: 0.7135\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5298 - acc: 0.7431 - val_loss: 0.5587 - val_acc: 0.7135\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5292 - acc: 0.7431 - val_loss: 0.5583 - val_acc: 0.7135\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5287 - acc: 0.7448 - val_loss: 0.5579 - val_acc: 0.7135\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5280 - acc: 0.7448 - val_loss: 0.5574 - val_acc: 0.7083\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5275 - acc: 0.7448 - val_loss: 0.5570 - val_acc: 0.7083\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5269 - acc: 0.7448 - val_loss: 0.5566 - val_acc: 0.7083\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5263 - acc: 0.7465 - val_loss: 0.5562 - val_acc: 0.7135\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5257 - acc: 0.7465 - val_loss: 0.5558 - val_acc: 0.7135\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5251 - acc: 0.7465 - val_loss: 0.5554 - val_acc: 0.7135\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5246 - acc: 0.7483 - val_loss: 0.5550 - val_acc: 0.7135\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5240 - acc: 0.7483 - val_loss: 0.5545 - val_acc: 0.7135\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5234 - acc: 0.7500 - val_loss: 0.5541 - val_acc: 0.7135\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5229 - acc: 0.7500 - val_loss: 0.5537 - val_acc: 0.7135\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5223 - acc: 0.7500 - val_loss: 0.5533 - val_acc: 0.7135\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5217 - acc: 0.7517 - val_loss: 0.5529 - val_acc: 0.7135\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5212 - acc: 0.7500 - val_loss: 0.5526 - val_acc: 0.7135\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5206 - acc: 0.7535 - val_loss: 0.5522 - val_acc: 0.7135\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5201 - acc: 0.7535 - val_loss: 0.5518 - val_acc: 0.7135\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.5195 - acc: 0.7552 - val_loss: 0.5514 - val_acc: 0.7188\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5190 - acc: 0.7552 - val_loss: 0.5510 - val_acc: 0.7188\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5184 - acc: 0.7552 - val_loss: 0.5506 - val_acc: 0.7188\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5178 - acc: 0.7552 - val_loss: 0.5503 - val_acc: 0.7240\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5172 - acc: 0.7569 - val_loss: 0.5499 - val_acc: 0.7240\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5167 - acc: 0.7569 - val_loss: 0.5495 - val_acc: 0.7240\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5161 - acc: 0.7569 - val_loss: 0.5492 - val_acc: 0.7240\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5155 - acc: 0.7569 - val_loss: 0.5488 - val_acc: 0.7240\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.5150 - acc: 0.7569 - val_loss: 0.5484 - val_acc: 0.7240\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5144 - acc: 0.7569 - val_loss: 0.5481 - val_acc: 0.7240\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5139 - acc: 0.7569 - val_loss: 0.5477 - val_acc: 0.7344\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.5133 - acc: 0.7569 - val_loss: 0.5474 - val_acc: 0.7344\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5128 - acc: 0.7569 - val_loss: 0.5470 - val_acc: 0.7396\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5122 - acc: 0.7569 - val_loss: 0.5467 - val_acc: 0.7396\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5117 - acc: 0.7569 - val_loss: 0.5463 - val_acc: 0.7396\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5111 - acc: 0.7569 - val_loss: 0.5459 - val_acc: 0.7396\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.5106 - acc: 0.7552 - val_loss: 0.5456 - val_acc: 0.7396\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5101 - acc: 0.7552 - val_loss: 0.5453 - val_acc: 0.7396\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5096 - acc: 0.7552 - val_loss: 0.5449 - val_acc: 0.7396\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5091 - acc: 0.7552 - val_loss: 0.5446 - val_acc: 0.7396\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5085 - acc: 0.7569 - val_loss: 0.5442 - val_acc: 0.7396\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.5081 - acc: 0.7569 - val_loss: 0.5439 - val_acc: 0.7396\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5075 - acc: 0.7569 - val_loss: 0.5436 - val_acc: 0.7396\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5070 - acc: 0.7587 - val_loss: 0.5432 - val_acc: 0.7396\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5066 - acc: 0.7587 - val_loss: 0.5429 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.5061 - acc: 0.7587 - val_loss: 0.5425 - val_acc: 0.7396\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5056 - acc: 0.7569 - val_loss: 0.5422 - val_acc: 0.7344\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.5051 - acc: 0.7569 - val_loss: 0.5419 - val_acc: 0.7344\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5046 - acc: 0.7569 - val_loss: 0.5415 - val_acc: 0.7344\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5041 - acc: 0.7569 - val_loss: 0.5412 - val_acc: 0.7344\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5036 - acc: 0.7552 - val_loss: 0.5409 - val_acc: 0.7344\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5031 - acc: 0.7569 - val_loss: 0.5406 - val_acc: 0.7344\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.5027 - acc: 0.7587 - val_loss: 0.5403 - val_acc: 0.7344\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.5022 - acc: 0.7604 - val_loss: 0.5400 - val_acc: 0.7344\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.5017 - acc: 0.7604 - val_loss: 0.5397 - val_acc: 0.7344\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.5013 - acc: 0.7604 - val_loss: 0.5394 - val_acc: 0.7344\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5008 - acc: 0.7587 - val_loss: 0.5391 - val_acc: 0.7344\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.5003 - acc: 0.7622 - val_loss: 0.5388 - val_acc: 0.7344\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4999 - acc: 0.7639 - val_loss: 0.5385 - val_acc: 0.7344\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4995 - acc: 0.7639 - val_loss: 0.5383 - val_acc: 0.7344\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4990 - acc: 0.7639 - val_loss: 0.5380 - val_acc: 0.7344\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4985 - acc: 0.7639 - val_loss: 0.5377 - val_acc: 0.7344\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4981 - acc: 0.7639 - val_loss: 0.5374 - val_acc: 0.7344\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4977 - acc: 0.7622 - val_loss: 0.5372 - val_acc: 0.7344\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4973 - acc: 0.7604 - val_loss: 0.5369 - val_acc: 0.7344\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4969 - acc: 0.7604 - val_loss: 0.5366 - val_acc: 0.7344\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4964 - acc: 0.7587 - val_loss: 0.5364 - val_acc: 0.7396\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4961 - acc: 0.7587 - val_loss: 0.5361 - val_acc: 0.7396\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4957 - acc: 0.7587 - val_loss: 0.5359 - val_acc: 0.7396\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4952 - acc: 0.7604 - val_loss: 0.5356 - val_acc: 0.7396\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4949 - acc: 0.7587 - val_loss: 0.5354 - val_acc: 0.7396\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4945 - acc: 0.7604 - val_loss: 0.5351 - val_acc: 0.7396\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4941 - acc: 0.7622 - val_loss: 0.5349 - val_acc: 0.7396\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4937 - acc: 0.7622 - val_loss: 0.5347 - val_acc: 0.7448\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4933 - acc: 0.7622 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4930 - acc: 0.7639 - val_loss: 0.5342 - val_acc: 0.7500\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4926 - acc: 0.7622 - val_loss: 0.5340 - val_acc: 0.7500\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4922 - acc: 0.7656 - val_loss: 0.5338 - val_acc: 0.7500\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4918 - acc: 0.7656 - val_loss: 0.5335 - val_acc: 0.7500\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4914 - acc: 0.7656 - val_loss: 0.5333 - val_acc: 0.7500\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4911 - acc: 0.7674 - val_loss: 0.5331 - val_acc: 0.7500\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4907 - acc: 0.7674 - val_loss: 0.5329 - val_acc: 0.7500\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4903 - acc: 0.7674 - val_loss: 0.5327 - val_acc: 0.7500\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4900 - acc: 0.7691 - val_loss: 0.5325 - val_acc: 0.7500\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4897 - acc: 0.7691 - val_loss: 0.5324 - val_acc: 0.7500\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4893 - acc: 0.7691 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4890 - acc: 0.7691 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4887 - acc: 0.7691 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4883 - acc: 0.7691 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4880 - acc: 0.7691 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4876 - acc: 0.7691 - val_loss: 0.5312 - val_acc: 0.7500\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4872 - acc: 0.7726 - val_loss: 0.5311 - val_acc: 0.7552\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4869 - acc: 0.7726 - val_loss: 0.5309 - val_acc: 0.7552\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4866 - acc: 0.7726 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4862 - acc: 0.7726 - val_loss: 0.5305 - val_acc: 0.7552\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4859 - acc: 0.7726 - val_loss: 0.5303 - val_acc: 0.7552\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4856 - acc: 0.7726 - val_loss: 0.5301 - val_acc: 0.7552\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4852 - acc: 0.7726 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4849 - acc: 0.7726 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4846 - acc: 0.7726 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4843 - acc: 0.7691 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4840 - acc: 0.7691 - val_loss: 0.5292 - val_acc: 0.7552\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4837 - acc: 0.7691 - val_loss: 0.5290 - val_acc: 0.7552\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4834 - acc: 0.7708 - val_loss: 0.5289 - val_acc: 0.7552\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4831 - acc: 0.7708 - val_loss: 0.5287 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4828 - acc: 0.7708 - val_loss: 0.5285 - val_acc: 0.7552\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4826 - acc: 0.7691 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4823 - acc: 0.7708 - val_loss: 0.5282 - val_acc: 0.7500\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4819 - acc: 0.7708 - val_loss: 0.5280 - val_acc: 0.7500\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4816 - acc: 0.7708 - val_loss: 0.5278 - val_acc: 0.7448\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4814 - acc: 0.7708 - val_loss: 0.5276 - val_acc: 0.7448\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4811 - acc: 0.7708 - val_loss: 0.5274 - val_acc: 0.7448\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4808 - acc: 0.7708 - val_loss: 0.5273 - val_acc: 0.7396\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4806 - acc: 0.7708 - val_loss: 0.5271 - val_acc: 0.7396\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4803 - acc: 0.7708 - val_loss: 0.5269 - val_acc: 0.7396\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4800 - acc: 0.7708 - val_loss: 0.5268 - val_acc: 0.7344\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4797 - acc: 0.7708 - val_loss: 0.5266 - val_acc: 0.7344\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4795 - acc: 0.7726 - val_loss: 0.5265 - val_acc: 0.7292\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4792 - acc: 0.7708 - val_loss: 0.5263 - val_acc: 0.7292\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4789 - acc: 0.7708 - val_loss: 0.5262 - val_acc: 0.7292\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4787 - acc: 0.7726 - val_loss: 0.5260 - val_acc: 0.7292\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4785 - acc: 0.7726 - val_loss: 0.5259 - val_acc: 0.7292\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4782 - acc: 0.7726 - val_loss: 0.5257 - val_acc: 0.7292\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4780 - acc: 0.7743 - val_loss: 0.5256 - val_acc: 0.7292\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4778 - acc: 0.7726 - val_loss: 0.5254 - val_acc: 0.7292\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4775 - acc: 0.7743 - val_loss: 0.5253 - val_acc: 0.7292\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4773 - acc: 0.7726 - val_loss: 0.5251 - val_acc: 0.7292\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4770 - acc: 0.7760 - val_loss: 0.5250 - val_acc: 0.7292\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4768 - acc: 0.7726 - val_loss: 0.5249 - val_acc: 0.7292\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4765 - acc: 0.7760 - val_loss: 0.5247 - val_acc: 0.7292\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4763 - acc: 0.7760 - val_loss: 0.5246 - val_acc: 0.7292\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4761 - acc: 0.7760 - val_loss: 0.5245 - val_acc: 0.7292\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4759 - acc: 0.7743 - val_loss: 0.5244 - val_acc: 0.7292\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4756 - acc: 0.7760 - val_loss: 0.5242 - val_acc: 0.7292\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4754 - acc: 0.7760 - val_loss: 0.5241 - val_acc: 0.7292\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4752 - acc: 0.7760 - val_loss: 0.5240 - val_acc: 0.7292\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4750 - acc: 0.7760 - val_loss: 0.5238 - val_acc: 0.7292\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4747 - acc: 0.7760 - val_loss: 0.5237 - val_acc: 0.7292\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4745 - acc: 0.7760 - val_loss: 0.5236 - val_acc: 0.7292\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4743 - acc: 0.7760 - val_loss: 0.5235 - val_acc: 0.7292\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4741 - acc: 0.7760 - val_loss: 0.5233 - val_acc: 0.7292\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4739 - acc: 0.7743 - val_loss: 0.5232 - val_acc: 0.7292\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4737 - acc: 0.7760 - val_loss: 0.5231 - val_acc: 0.7292\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4734 - acc: 0.7760 - val_loss: 0.5230 - val_acc: 0.7292\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4732 - acc: 0.7760 - val_loss: 0.5228 - val_acc: 0.7292\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4730 - acc: 0.7743 - val_loss: 0.5227 - val_acc: 0.7292\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4728 - acc: 0.7743 - val_loss: 0.5226 - val_acc: 0.7292\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4725 - acc: 0.7743 - val_loss: 0.5225 - val_acc: 0.7344\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4724 - acc: 0.7743 - val_loss: 0.5224 - val_acc: 0.7396\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4721 - acc: 0.7743 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4719 - acc: 0.7743 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4717 - acc: 0.7743 - val_loss: 0.5220 - val_acc: 0.7396\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4715 - acc: 0.7743 - val_loss: 0.5219 - val_acc: 0.7396\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4713 - acc: 0.7743 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4711 - acc: 0.7743 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4709 - acc: 0.7743 - val_loss: 0.5216 - val_acc: 0.7396\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4707 - acc: 0.7743 - val_loss: 0.5215 - val_acc: 0.7396\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4705 - acc: 0.7743 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4704 - acc: 0.7743 - val_loss: 0.5212 - val_acc: 0.7396\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4701 - acc: 0.7743 - val_loss: 0.5211 - val_acc: 0.7396\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 123us/step - loss: 0.4700 - acc: 0.7743 - val_loss: 0.5210 - val_acc: 0.7396\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4698 - acc: 0.7743 - val_loss: 0.5209 - val_acc: 0.7396\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4696 - acc: 0.7743 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4694 - acc: 0.7743 - val_loss: 0.5207 - val_acc: 0.7448\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4692 - acc: 0.7726 - val_loss: 0.5206 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4690 - acc: 0.7760 - val_loss: 0.5205 - val_acc: 0.7448\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4688 - acc: 0.7760 - val_loss: 0.5204 - val_acc: 0.7448\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4686 - acc: 0.7743 - val_loss: 0.5203 - val_acc: 0.7448\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4685 - acc: 0.7743 - val_loss: 0.5202 - val_acc: 0.7448\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4683 - acc: 0.7760 - val_loss: 0.5201 - val_acc: 0.7448\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4681 - acc: 0.7760 - val_loss: 0.5200 - val_acc: 0.7448\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4680 - acc: 0.7760 - val_loss: 0.5199 - val_acc: 0.7448\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4678 - acc: 0.7743 - val_loss: 0.5198 - val_acc: 0.7448\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4676 - acc: 0.7743 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4674 - acc: 0.7726 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4673 - acc: 0.7726 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4671 - acc: 0.7726 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4669 - acc: 0.7726 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4668 - acc: 0.7726 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4666 - acc: 0.7726 - val_loss: 0.5192 - val_acc: 0.7448\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4664 - acc: 0.7743 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4663 - acc: 0.7760 - val_loss: 0.5191 - val_acc: 0.7448\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4661 - acc: 0.7743 - val_loss: 0.5190 - val_acc: 0.7448\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4660 - acc: 0.7760 - val_loss: 0.5189 - val_acc: 0.7448\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4658 - acc: 0.7760 - val_loss: 0.5188 - val_acc: 0.7448\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4657 - acc: 0.7760 - val_loss: 0.5187 - val_acc: 0.7396\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4655 - acc: 0.7760 - val_loss: 0.5186 - val_acc: 0.7396\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4654 - acc: 0.7760 - val_loss: 0.5185 - val_acc: 0.7396\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4652 - acc: 0.7760 - val_loss: 0.5185 - val_acc: 0.7396\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4651 - acc: 0.7760 - val_loss: 0.5184 - val_acc: 0.7396\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4649 - acc: 0.7760 - val_loss: 0.5183 - val_acc: 0.7396\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4648 - acc: 0.7760 - val_loss: 0.5182 - val_acc: 0.7448\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4647 - acc: 0.7760 - val_loss: 0.5181 - val_acc: 0.7448\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4645 - acc: 0.7760 - val_loss: 0.5180 - val_acc: 0.7448\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4644 - acc: 0.7760 - val_loss: 0.5180 - val_acc: 0.7448\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4642 - acc: 0.7760 - val_loss: 0.5179 - val_acc: 0.7448\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4641 - acc: 0.7760 - val_loss: 0.5178 - val_acc: 0.7448\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4640 - acc: 0.7760 - val_loss: 0.5177 - val_acc: 0.7448\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4638 - acc: 0.7743 - val_loss: 0.5176 - val_acc: 0.7448\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4637 - acc: 0.7760 - val_loss: 0.5175 - val_acc: 0.7448\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4635 - acc: 0.7760 - val_loss: 0.5175 - val_acc: 0.7448\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4634 - acc: 0.7743 - val_loss: 0.5174 - val_acc: 0.7448\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4633 - acc: 0.7743 - val_loss: 0.5173 - val_acc: 0.7448\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4632 - acc: 0.7760 - val_loss: 0.5172 - val_acc: 0.7448\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4630 - acc: 0.7778 - val_loss: 0.5171 - val_acc: 0.7448\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4629 - acc: 0.7778 - val_loss: 0.5171 - val_acc: 0.7448\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4628 - acc: 0.7778 - val_loss: 0.5170 - val_acc: 0.7448\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4627 - acc: 0.7778 - val_loss: 0.5169 - val_acc: 0.7448\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4625 - acc: 0.7778 - val_loss: 0.5168 - val_acc: 0.7448\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4624 - acc: 0.7778 - val_loss: 0.5168 - val_acc: 0.7448\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4623 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7448\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4622 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7448\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4620 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7448\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4619 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7448\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4618 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7448\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4617 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7448\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4616 - acc: 0.7795 - val_loss: 0.5164 - val_acc: 0.7448\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4614 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7448\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4614 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7448\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4612 - acc: 0.7795 - val_loss: 0.5162 - val_acc: 0.7448\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4611 - acc: 0.7795 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4610 - acc: 0.7795 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4609 - acc: 0.7795 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4608 - acc: 0.7795 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4606 - acc: 0.7795 - val_loss: 0.5159 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4605 - acc: 0.7795 - val_loss: 0.5159 - val_acc: 0.7500\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4604 - acc: 0.7795 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4603 - acc: 0.7795 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4602 - acc: 0.7795 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4601 - acc: 0.7812 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4599 - acc: 0.7795 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4598 - acc: 0.7795 - val_loss: 0.5155 - val_acc: 0.7500\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4597 - acc: 0.7812 - val_loss: 0.5155 - val_acc: 0.7500\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4596 - acc: 0.7812 - val_loss: 0.5154 - val_acc: 0.7500\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4595 - acc: 0.7812 - val_loss: 0.5154 - val_acc: 0.7500\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4594 - acc: 0.7830 - val_loss: 0.5154 - val_acc: 0.7500\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4592 - acc: 0.7830 - val_loss: 0.5153 - val_acc: 0.7500\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4592 - acc: 0.7830 - val_loss: 0.5153 - val_acc: 0.7500\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4590 - acc: 0.7830 - val_loss: 0.5152 - val_acc: 0.7500\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4590 - acc: 0.7830 - val_loss: 0.5152 - val_acc: 0.7500\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4588 - acc: 0.7830 - val_loss: 0.5151 - val_acc: 0.7500\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4587 - acc: 0.7847 - val_loss: 0.5151 - val_acc: 0.7500\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4586 - acc: 0.7847 - val_loss: 0.5151 - val_acc: 0.7500\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4585 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4584 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4583 - acc: 0.7847 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4582 - acc: 0.7847 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4581 - acc: 0.7847 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4580 - acc: 0.7847 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4578 - acc: 0.7847 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4577 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4576 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4575 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7552\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4574 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7552\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4573 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4571 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4570 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4569 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4568 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4567 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4566 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4565 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4563 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4563 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4561 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4560 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4559 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4559 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4558 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4557 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4556 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4555 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4554 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4553 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4552 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4551 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4550 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4549 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4548 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4547 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4546 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4545 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4545 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4543 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4542 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4541 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4540 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4540 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4538 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4538 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4536 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4535 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4535 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4533 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4533 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4532 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4531 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4530 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4529 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4528 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4527 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4526 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7552\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4525 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4524 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4523 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4523 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4522 - acc: 0.7865 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4521 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4520 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4519 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4518 - acc: 0.7847 - val_loss: 0.5146 - val_acc: 0.7500\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4517 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4517 - acc: 0.7847 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4516 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4515 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4515 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4514 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4513 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4512 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4512 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4511 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4510 - acc: 0.7865 - val_loss: 0.5147 - val_acc: 0.7500\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4510 - acc: 0.7865 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4509 - acc: 0.7865 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4508 - acc: 0.7865 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4508 - acc: 0.7865 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4507 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7500\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4506 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7552\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4505 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7552\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4505 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7552\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4504 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7552\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4503 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7552\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4502 - acc: 0.7882 - val_loss: 0.5148 - val_acc: 0.7552\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4502 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7552\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4501 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4500 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4500 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4500 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4498 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4498 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4497 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4496 - acc: 0.7899 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4495 - acc: 0.7899 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4495 - acc: 0.7899 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4494 - acc: 0.7899 - val_loss: 0.5150 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4493 - acc: 0.7899 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4493 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4492 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4491 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4490 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4489 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4488 - acc: 0.7882 - val_loss: 0.5150 - val_acc: 0.7500\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4488 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7500\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4487 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7448\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4486 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7448\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4485 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7448\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4484 - acc: 0.7899 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4483 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4483 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4482 - acc: 0.7899 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4481 - acc: 0.7899 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4480 - acc: 0.7899 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4479 - acc: 0.7899 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4478 - acc: 0.7865 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4478 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4477 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4477 - acc: 0.7882 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4475 - acc: 0.7865 - val_loss: 0.5151 - val_acc: 0.7344\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4474 - acc: 0.7865 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4473 - acc: 0.7865 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4472 - acc: 0.7865 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4472 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4471 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4470 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4469 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4469 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4468 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4467 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4466 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4465 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4465 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4464 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4463 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7344\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4462 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7396\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4461 - acc: 0.7830 - val_loss: 0.5150 - val_acc: 0.7396\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4461 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7396\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4460 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7396\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4459 - acc: 0.7847 - val_loss: 0.5150 - val_acc: 0.7396\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4458 - acc: 0.7847 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4458 - acc: 0.7865 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4457 - acc: 0.7847 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4457 - acc: 0.7847 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4456 - acc: 0.7847 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4455 - acc: 0.7865 - val_loss: 0.5151 - val_acc: 0.7396\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4455 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4454 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4453 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4452 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4452 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4451 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4451 - acc: 0.7847 - val_loss: 0.5152 - val_acc: 0.7396\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4451 - acc: 0.7847 - val_loss: 0.5153 - val_acc: 0.7396\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4449 - acc: 0.7847 - val_loss: 0.5153 - val_acc: 0.7396\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4449 - acc: 0.7847 - val_loss: 0.5153 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4448 - acc: 0.7847 - val_loss: 0.5153 - val_acc: 0.7396\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4447 - acc: 0.7847 - val_loss: 0.5153 - val_acc: 0.7396\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4447 - acc: 0.7847 - val_loss: 0.5153 - val_acc: 0.7396\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4446 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7396\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4445 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7396\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4445 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7396\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4444 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7396\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4443 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7448\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4443 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7448\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4442 - acc: 0.7847 - val_loss: 0.5154 - val_acc: 0.7448\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4441 - acc: 0.7847 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4441 - acc: 0.7830 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4440 - acc: 0.7830 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4440 - acc: 0.7830 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4439 - acc: 0.7830 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4438 - acc: 0.7830 - val_loss: 0.5155 - val_acc: 0.7448\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4438 - acc: 0.7830 - val_loss: 0.5156 - val_acc: 0.7448\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4437 - acc: 0.7830 - val_loss: 0.5156 - val_acc: 0.7448\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4436 - acc: 0.7812 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4435 - acc: 0.7830 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4435 - acc: 0.7830 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4435 - acc: 0.7812 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4434 - acc: 0.7830 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4433 - acc: 0.7812 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4432 - acc: 0.7830 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4432 - acc: 0.7830 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4431 - acc: 0.7847 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4430 - acc: 0.7830 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4430 - acc: 0.7812 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4429 - acc: 0.7847 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4429 - acc: 0.7865 - val_loss: 0.5157 - val_acc: 0.7500\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4428 - acc: 0.7847 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4427 - acc: 0.7847 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4427 - acc: 0.7847 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4426 - acc: 0.7865 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4426 - acc: 0.7847 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4425 - acc: 0.7847 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4424 - acc: 0.7847 - val_loss: 0.5159 - val_acc: 0.7500\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4423 - acc: 0.7830 - val_loss: 0.5159 - val_acc: 0.7500\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4423 - acc: 0.7847 - val_loss: 0.5159 - val_acc: 0.7500\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4422 - acc: 0.7847 - val_loss: 0.5159 - val_acc: 0.7500\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4422 - acc: 0.7847 - val_loss: 0.5159 - val_acc: 0.7500\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4421 - acc: 0.7812 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4420 - acc: 0.7812 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4419 - acc: 0.7795 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4419 - acc: 0.7812 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4418 - acc: 0.7795 - val_loss: 0.5160 - val_acc: 0.7500\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4418 - acc: 0.7795 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4417 - acc: 0.7795 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4416 - acc: 0.7795 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4416 - acc: 0.7812 - val_loss: 0.5161 - val_acc: 0.7500\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4415 - acc: 0.7795 - val_loss: 0.5162 - val_acc: 0.7500\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4414 - acc: 0.7795 - val_loss: 0.5162 - val_acc: 0.7500\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4414 - acc: 0.7795 - val_loss: 0.5162 - val_acc: 0.7500\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4413 - acc: 0.7795 - val_loss: 0.5162 - val_acc: 0.7500\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4413 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4412 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4412 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4411 - acc: 0.7795 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - acc: 0.7778 - val_loss: 0.5163 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4410 - acc: 0.7778 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4409 - acc: 0.7778 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4409 - acc: 0.7778 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4408 - acc: 0.7778 - val_loss: 0.5164 - val_acc: 0.7500\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4408 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4407 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4406 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4406 - acc: 0.7778 - val_loss: 0.5165 - val_acc: 0.7500\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4405 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4405 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4404 - acc: 0.7778 - val_loss: 0.5166 - val_acc: 0.7500\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4404 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4403 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4402 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4401 - acc: 0.7778 - val_loss: 0.5167 - val_acc: 0.7500\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4401 - acc: 0.7778 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4400 - acc: 0.7778 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4400 - acc: 0.7778 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4399 - acc: 0.7778 - val_loss: 0.5169 - val_acc: 0.7500\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4399 - acc: 0.7778 - val_loss: 0.5169 - val_acc: 0.7500\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4399 - acc: 0.7778 - val_loss: 0.5169 - val_acc: 0.7500\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4398 - acc: 0.7778 - val_loss: 0.5170 - val_acc: 0.7500\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4397 - acc: 0.7778 - val_loss: 0.5170 - val_acc: 0.7500\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4397 - acc: 0.7778 - val_loss: 0.5170 - val_acc: 0.7500\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4396 - acc: 0.7778 - val_loss: 0.5171 - val_acc: 0.7500\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4395 - acc: 0.7778 - val_loss: 0.5171 - val_acc: 0.7500\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4395 - acc: 0.7778 - val_loss: 0.5171 - val_acc: 0.7500\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4394 - acc: 0.7778 - val_loss: 0.5172 - val_acc: 0.7500\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4394 - acc: 0.7778 - val_loss: 0.5172 - val_acc: 0.7500\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4393 - acc: 0.7795 - val_loss: 0.5172 - val_acc: 0.7500\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4393 - acc: 0.7778 - val_loss: 0.5173 - val_acc: 0.7500\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4392 - acc: 0.7778 - val_loss: 0.5173 - val_acc: 0.7500\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4392 - acc: 0.7778 - val_loss: 0.5173 - val_acc: 0.7500\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4391 - acc: 0.7795 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4390 - acc: 0.7778 - val_loss: 0.5174 - val_acc: 0.7500\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4390 - acc: 0.7795 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4389 - acc: 0.7795 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4389 - acc: 0.7795 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4389 - acc: 0.7812 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4388 - acc: 0.7812 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4388 - acc: 0.7812 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4387 - acc: 0.7812 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4387 - acc: 0.7795 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4386 - acc: 0.7812 - val_loss: 0.5177 - val_acc: 0.7500\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4385 - acc: 0.7812 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4385 - acc: 0.7812 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4384 - acc: 0.7812 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4384 - acc: 0.7812 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4383 - acc: 0.7812 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4383 - acc: 0.7812 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4382 - acc: 0.7812 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4382 - acc: 0.7812 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4381 - acc: 0.7812 - val_loss: 0.5180 - val_acc: 0.7500\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4381 - acc: 0.7812 - val_loss: 0.5180 - val_acc: 0.7552\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4380 - acc: 0.7795 - val_loss: 0.5181 - val_acc: 0.7552\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4380 - acc: 0.7812 - val_loss: 0.5181 - val_acc: 0.7552\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4379 - acc: 0.7812 - val_loss: 0.5181 - val_acc: 0.7552\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4379 - acc: 0.7812 - val_loss: 0.5182 - val_acc: 0.7552\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4379 - acc: 0.7812 - val_loss: 0.5182 - val_acc: 0.7552\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4378 - acc: 0.7812 - val_loss: 0.5182 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4377 - acc: 0.7812 - val_loss: 0.5183 - val_acc: 0.7552\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4377 - acc: 0.7812 - val_loss: 0.5183 - val_acc: 0.7552\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4377 - acc: 0.7812 - val_loss: 0.5183 - val_acc: 0.7552\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4376 - acc: 0.7812 - val_loss: 0.5183 - val_acc: 0.7552\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4376 - acc: 0.7812 - val_loss: 0.5184 - val_acc: 0.7552\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4376 - acc: 0.7812 - val_loss: 0.5184 - val_acc: 0.7552\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4375 - acc: 0.7812 - val_loss: 0.5184 - val_acc: 0.7552\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4375 - acc: 0.7812 - val_loss: 0.5185 - val_acc: 0.7552\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4374 - acc: 0.7812 - val_loss: 0.5185 - val_acc: 0.7552\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4373 - acc: 0.7812 - val_loss: 0.5185 - val_acc: 0.7552\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4373 - acc: 0.7812 - val_loss: 0.5185 - val_acc: 0.7500\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4373 - acc: 0.7812 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4372 - acc: 0.7812 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4372 - acc: 0.7812 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4371 - acc: 0.7812 - val_loss: 0.5186 - val_acc: 0.7500\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4371 - acc: 0.7812 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4370 - acc: 0.7812 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4370 - acc: 0.7812 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4370 - acc: 0.7812 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4369 - acc: 0.7812 - val_loss: 0.5187 - val_acc: 0.7500\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4369 - acc: 0.7812 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4368 - acc: 0.7812 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4368 - acc: 0.7812 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4367 - acc: 0.7812 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4367 - acc: 0.7812 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4367 - acc: 0.7830 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4366 - acc: 0.7830 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4366 - acc: 0.7830 - val_loss: 0.5189 - val_acc: 0.7500\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4365 - acc: 0.7830 - val_loss: 0.5190 - val_acc: 0.7500\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4364 - acc: 0.7812 - val_loss: 0.5190 - val_acc: 0.7500\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4364 - acc: 0.7830 - val_loss: 0.5190 - val_acc: 0.7500\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4363 - acc: 0.7812 - val_loss: 0.5190 - val_acc: 0.7500\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4363 - acc: 0.7830 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4362 - acc: 0.7847 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4362 - acc: 0.7830 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4361 - acc: 0.7847 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4361 - acc: 0.7830 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4361 - acc: 0.7847 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4360 - acc: 0.7830 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4360 - acc: 0.7847 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4359 - acc: 0.7847 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4359 - acc: 0.7847 - val_loss: 0.5193 - val_acc: 0.7500\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4358 - acc: 0.7847 - val_loss: 0.5193 - val_acc: 0.7500\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4358 - acc: 0.7847 - val_loss: 0.5193 - val_acc: 0.7500\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4357 - acc: 0.7847 - val_loss: 0.5193 - val_acc: 0.7448\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4357 - acc: 0.7847 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4356 - acc: 0.7847 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4356 - acc: 0.7847 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4355 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4355 - acc: 0.7865 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4355 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4354 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - acc: 0.7865 - val_loss: 0.5195 - val_acc: 0.7448\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4353 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4353 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5196 - val_acc: 0.7448\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4352 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4351 - acc: 0.7865 - val_loss: 0.5197 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4350 - acc: 0.7951 - val_loss: 0.5197 - val_acc: 0.7448\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4350 - acc: 0.7951 - val_loss: 0.5198 - val_acc: 0.7396\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4350 - acc: 0.7969 - val_loss: 0.5198 - val_acc: 0.7396\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4349 - acc: 0.7969 - val_loss: 0.5198 - val_acc: 0.7396\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4348 - acc: 0.7969 - val_loss: 0.5198 - val_acc: 0.7396\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4348 - acc: 0.7986 - val_loss: 0.5199 - val_acc: 0.7396\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4348 - acc: 0.8003 - val_loss: 0.5199 - val_acc: 0.7396\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4347 - acc: 0.7986 - val_loss: 0.5199 - val_acc: 0.7396\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4347 - acc: 0.7986 - val_loss: 0.5199 - val_acc: 0.7396\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4347 - acc: 0.7986 - val_loss: 0.5200 - val_acc: 0.7396\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4346 - acc: 0.7986 - val_loss: 0.5200 - val_acc: 0.7396\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4345 - acc: 0.8003 - val_loss: 0.5200 - val_acc: 0.7396\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4345 - acc: 0.8003 - val_loss: 0.5200 - val_acc: 0.7396\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4345 - acc: 0.8003 - val_loss: 0.5201 - val_acc: 0.7396\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4344 - acc: 0.7969 - val_loss: 0.5201 - val_acc: 0.7396\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4344 - acc: 0.7986 - val_loss: 0.5201 - val_acc: 0.7396\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4343 - acc: 0.7986 - val_loss: 0.5201 - val_acc: 0.7396\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4343 - acc: 0.7986 - val_loss: 0.5202 - val_acc: 0.7396\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4343 - acc: 0.7986 - val_loss: 0.5202 - val_acc: 0.7396\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4342 - acc: 0.7986 - val_loss: 0.5202 - val_acc: 0.7396\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4342 - acc: 0.7986 - val_loss: 0.5202 - val_acc: 0.7396\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4341 - acc: 0.7986 - val_loss: 0.5203 - val_acc: 0.7396\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4341 - acc: 0.7986 - val_loss: 0.5203 - val_acc: 0.7396\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4341 - acc: 0.7986 - val_loss: 0.5203 - val_acc: 0.7396\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4340 - acc: 0.7986 - val_loss: 0.5203 - val_acc: 0.7396\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4340 - acc: 0.7986 - val_loss: 0.5204 - val_acc: 0.7396\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4339 - acc: 0.7986 - val_loss: 0.5204 - val_acc: 0.7396\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4339 - acc: 0.7986 - val_loss: 0.5204 - val_acc: 0.7396\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4339 - acc: 0.7986 - val_loss: 0.5204 - val_acc: 0.7396\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4338 - acc: 0.7986 - val_loss: 0.5205 - val_acc: 0.7396\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4338 - acc: 0.7986 - val_loss: 0.5205 - val_acc: 0.7396\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4337 - acc: 0.7986 - val_loss: 0.5205 - val_acc: 0.7396\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4336 - acc: 0.7986 - val_loss: 0.5206 - val_acc: 0.7396\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4336 - acc: 0.7986 - val_loss: 0.5206 - val_acc: 0.7396\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4336 - acc: 0.7986 - val_loss: 0.5206 - val_acc: 0.7396\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7986 - val_loss: 0.5206 - val_acc: 0.7396\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4335 - acc: 0.7986 - val_loss: 0.5207 - val_acc: 0.7396\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4334 - acc: 0.7986 - val_loss: 0.5207 - val_acc: 0.7396\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4334 - acc: 0.8003 - val_loss: 0.5207 - val_acc: 0.7396\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4334 - acc: 0.7986 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4334 - acc: 0.8003 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4333 - acc: 0.8003 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4333 - acc: 0.8003 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4332 - acc: 0.8003 - val_loss: 0.5208 - val_acc: 0.7396\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4332 - acc: 0.8003 - val_loss: 0.5209 - val_acc: 0.7396\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4331 - acc: 0.8003 - val_loss: 0.5209 - val_acc: 0.7396\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4331 - acc: 0.8003 - val_loss: 0.5209 - val_acc: 0.7396\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4331 - acc: 0.8003 - val_loss: 0.5209 - val_acc: 0.7396\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4330 - acc: 0.8003 - val_loss: 0.5210 - val_acc: 0.7396\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4330 - acc: 0.8003 - val_loss: 0.5210 - val_acc: 0.7396\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4329 - acc: 0.8003 - val_loss: 0.5210 - val_acc: 0.7396\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4329 - acc: 0.8003 - val_loss: 0.5210 - val_acc: 0.7396\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5211 - val_acc: 0.7396\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5211 - val_acc: 0.7396\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4328 - acc: 0.8021 - val_loss: 0.5211 - val_acc: 0.7396\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4327 - acc: 0.8021 - val_loss: 0.5211 - val_acc: 0.7396\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4327 - acc: 0.8021 - val_loss: 0.5212 - val_acc: 0.7396\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4326 - acc: 0.8021 - val_loss: 0.5212 - val_acc: 0.7396\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4326 - acc: 0.8021 - val_loss: 0.5212 - val_acc: 0.7396\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4326 - acc: 0.8021 - val_loss: 0.5212 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4325 - acc: 0.8021 - val_loss: 0.5213 - val_acc: 0.7396\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4325 - acc: 0.8021 - val_loss: 0.5213 - val_acc: 0.7396\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4325 - acc: 0.8021 - val_loss: 0.5213 - val_acc: 0.7396\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4324 - acc: 0.8021 - val_loss: 0.5213 - val_acc: 0.7396\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4324 - acc: 0.8021 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4324 - acc: 0.8021 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4323 - acc: 0.8021 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4322 - acc: 0.8021 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - acc: 0.8021 - val_loss: 0.5214 - val_acc: 0.7396\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4321 - acc: 0.8021 - val_loss: 0.5215 - val_acc: 0.7396\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4321 - acc: 0.8021 - val_loss: 0.5215 - val_acc: 0.7396\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4321 - acc: 0.8021 - val_loss: 0.5215 - val_acc: 0.7396\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4320 - acc: 0.8021 - val_loss: 0.5215 - val_acc: 0.7396\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4320 - acc: 0.8038 - val_loss: 0.5216 - val_acc: 0.7396\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4320 - acc: 0.8056 - val_loss: 0.5216 - val_acc: 0.7396\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4320 - acc: 0.8021 - val_loss: 0.5216 - val_acc: 0.7396\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4319 - acc: 0.8021 - val_loss: 0.5216 - val_acc: 0.7396\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4319 - acc: 0.8038 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4318 - acc: 0.8038 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4318 - acc: 0.8038 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4317 - acc: 0.8038 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4318 - acc: 0.8038 - val_loss: 0.5217 - val_acc: 0.7396\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4317 - acc: 0.8056 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4316 - acc: 0.8038 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4316 - acc: 0.8038 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4316 - acc: 0.8056 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - acc: 0.8056 - val_loss: 0.5218 - val_acc: 0.7396\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4315 - acc: 0.8056 - val_loss: 0.5219 - val_acc: 0.7396\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4315 - acc: 0.8056 - val_loss: 0.5219 - val_acc: 0.7396\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4314 - acc: 0.8056 - val_loss: 0.5219 - val_acc: 0.7396\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4314 - acc: 0.8056 - val_loss: 0.5219 - val_acc: 0.7396\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4314 - acc: 0.8038 - val_loss: 0.5219 - val_acc: 0.7396\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4313 - acc: 0.8073 - val_loss: 0.5220 - val_acc: 0.7396\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4313 - acc: 0.8038 - val_loss: 0.5220 - val_acc: 0.7396\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5220 - val_acc: 0.7396\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5220 - val_acc: 0.7396\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4312 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4311 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5221 - val_acc: 0.7396\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7396\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7396\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4309 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7396\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4309 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7396\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4308 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7396\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2919 - acc: 0.937 - 0s 46us/step - loss: 0.4308 - acc: 0.8038 - val_loss: 0.5222 - val_acc: 0.7396\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4308 - acc: 0.8038 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4308 - acc: 0.8073 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4307 - acc: 0.8073 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4307 - acc: 0.8038 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4306 - acc: 0.8073 - val_loss: 0.5223 - val_acc: 0.7396\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4306 - acc: 0.8056 - val_loss: 0.5224 - val_acc: 0.7396\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4306 - acc: 0.8056 - val_loss: 0.5224 - val_acc: 0.7396\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4306 - acc: 0.8056 - val_loss: 0.5224 - val_acc: 0.7396\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4305 - acc: 0.8056 - val_loss: 0.5225 - val_acc: 0.7396\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4305 - acc: 0.8073 - val_loss: 0.5225 - val_acc: 0.7396\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4305 - acc: 0.8073 - val_loss: 0.5225 - val_acc: 0.7396\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4304 - acc: 0.8073 - val_loss: 0.5225 - val_acc: 0.7396\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4304 - acc: 0.8056 - val_loss: 0.5225 - val_acc: 0.7396\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4304 - acc: 0.8056 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4304 - acc: 0.8056 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4303 - acc: 0.8056 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4303 - acc: 0.8056 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4302 - acc: 0.8073 - val_loss: 0.5226 - val_acc: 0.7396\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4302 - acc: 0.8073 - val_loss: 0.5227 - val_acc: 0.7396\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4302 - acc: 0.8073 - val_loss: 0.5227 - val_acc: 0.7396\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4302 - acc: 0.8073 - val_loss: 0.5227 - val_acc: 0.7396\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4301 - acc: 0.8073 - val_loss: 0.5227 - val_acc: 0.7396\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4301 - acc: 0.8056 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4301 - acc: 0.8073 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4300 - acc: 0.8073 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4300 - acc: 0.8073 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4299 - acc: 0.8073 - val_loss: 0.5228 - val_acc: 0.7396\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4299 - acc: 0.8073 - val_loss: 0.5229 - val_acc: 0.7396\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4299 - acc: 0.8073 - val_loss: 0.5229 - val_acc: 0.7396\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4299 - acc: 0.8073 - val_loss: 0.5229 - val_acc: 0.7396\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - acc: 0.8056 - val_loss: 0.5229 - val_acc: 0.7396\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4298 - acc: 0.8073 - val_loss: 0.5230 - val_acc: 0.7396\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4298 - acc: 0.8056 - val_loss: 0.5230 - val_acc: 0.7396\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4297 - acc: 0.8073 - val_loss: 0.5230 - val_acc: 0.7396\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4298 - acc: 0.8056 - val_loss: 0.5230 - val_acc: 0.7396\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4297 - acc: 0.8073 - val_loss: 0.5230 - val_acc: 0.7396\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4296 - acc: 0.8073 - val_loss: 0.5230 - val_acc: 0.7396\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4296 - acc: 0.8073 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4296 - acc: 0.8056 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - acc: 0.8073 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4296 - acc: 0.8073 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4295 - acc: 0.8056 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4295 - acc: 0.8056 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4295 - acc: 0.8073 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4294 - acc: 0.8056 - val_loss: 0.5231 - val_acc: 0.7396\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4294 - acc: 0.8056 - val_loss: 0.5232 - val_acc: 0.7396\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4294 - acc: 0.8056 - val_loss: 0.5232 - val_acc: 0.7396\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4293 - acc: 0.8056 - val_loss: 0.5232 - val_acc: 0.7396\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4293 - acc: 0.8056 - val_loss: 0.5232 - val_acc: 0.7396\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4293 - acc: 0.8038 - val_loss: 0.5232 - val_acc: 0.7396\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4293 - acc: 0.8056 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - acc: 0.8056 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4292 - acc: 0.8056 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4292 - acc: 0.8056 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4292 - acc: 0.8056 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - acc: 0.8056 - val_loss: 0.5233 - val_acc: 0.7396\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4291 - acc: 0.8056 - val_loss: 0.5234 - val_acc: 0.7396\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4291 - acc: 0.8056 - val_loss: 0.5234 - val_acc: 0.7396\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4291 - acc: 0.8056 - val_loss: 0.5234 - val_acc: 0.7396\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4290 - acc: 0.8056 - val_loss: 0.5234 - val_acc: 0.7396\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4290 - acc: 0.8056 - val_loss: 0.5234 - val_acc: 0.7396\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4290 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4290 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4289 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4288 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4288 - acc: 0.8056 - val_loss: 0.5235 - val_acc: 0.7396\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4288 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7396\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4287 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7396\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4287 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4287 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7448\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4287 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7448\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4286 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7448\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4286 - acc: 0.8056 - val_loss: 0.5236 - val_acc: 0.7500\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4286 - acc: 0.8038 - val_loss: 0.5236 - val_acc: 0.7448\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4286 - acc: 0.8056 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4285 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4285 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4285 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4285 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4284 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4284 - acc: 0.8038 - val_loss: 0.5237 - val_acc: 0.7500\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4283 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4283 - acc: 0.8021 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4283 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4283 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4282 - acc: 0.8021 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4282 - acc: 0.8038 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4282 - acc: 0.8021 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4281 - acc: 0.8021 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4281 - acc: 0.8021 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - acc: 0.8038 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4280 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4279 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5240 - val_acc: 0.7448\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7448\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7448\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7448\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7448\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4278 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7448\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5241 - val_acc: 0.7448\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4276 - acc: 0.8003 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5242 - val_acc: 0.7448\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7448\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7448\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4275 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7448\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7448\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7448\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4274 - acc: 0.8021 - val_loss: 0.5243 - val_acc: 0.7448\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4273 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5244 - val_acc: 0.7448\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4272 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4271 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5245 - val_acc: 0.7448\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4269 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4268 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4268 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4268 - acc: 0.8021 - val_loss: 0.5246 - val_acc: 0.7448\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4268 - acc: 0.8021 - val_loss: 0.5247 - val_acc: 0.7448\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4267 - acc: 0.8021 - val_loss: 0.5247 - val_acc: 0.7448\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4267 - acc: 0.8021 - val_loss: 0.5247 - val_acc: 0.7448\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4267 - acc: 0.8021 - val_loss: 0.5247 - val_acc: 0.7448\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4267 - acc: 0.8003 - val_loss: 0.5247 - val_acc: 0.7448\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4266 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4266 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4266 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4266 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4265 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4265 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - acc: 0.8021 - val_loss: 0.5248 - val_acc: 0.7448\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4265 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4265 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4264 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4264 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4264 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4264 - acc: 0.8021 - val_loss: 0.5249 - val_acc: 0.7448\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4263 - acc: 0.8021 - val_loss: 0.5250 - val_acc: 0.7448\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4263 - acc: 0.8021 - val_loss: 0.5250 - val_acc: 0.7448\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.5250 - val_acc: 0.7448\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.5250 - val_acc: 0.7448\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.5250 - val_acc: 0.7448\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7448\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7448\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4261 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7448\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4261 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7448\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4261 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7448\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4261 - acc: 0.8021 - val_loss: 0.5251 - val_acc: 0.7448\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4260 - acc: 0.8021 - val_loss: 0.5252 - val_acc: 0.7448\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4260 - acc: 0.8021 - val_loss: 0.5252 - val_acc: 0.7448\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4260 - acc: 0.8021 - val_loss: 0.5252 - val_acc: 0.7448\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4260 - acc: 0.8021 - val_loss: 0.5252 - val_acc: 0.7448\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4259 - acc: 0.8021 - val_loss: 0.5252 - val_acc: 0.7448\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4259 - acc: 0.8021 - val_loss: 0.5252 - val_acc: 0.7448\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4259 - acc: 0.8021 - val_loss: 0.5253 - val_acc: 0.7448\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4258 - acc: 0.8021 - val_loss: 0.5253 - val_acc: 0.7448\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4259 - acc: 0.8021 - val_loss: 0.5253 - val_acc: 0.7448\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4258 - acc: 0.8021 - val_loss: 0.5253 - val_acc: 0.7448\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4258 - acc: 0.8021 - val_loss: 0.5253 - val_acc: 0.7448\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4258 - acc: 0.8021 - val_loss: 0.5254 - val_acc: 0.7448\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4258 - acc: 0.8021 - val_loss: 0.5254 - val_acc: 0.7448\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4257 - acc: 0.8021 - val_loss: 0.5254 - val_acc: 0.7448\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - acc: 0.8021 - val_loss: 0.5254 - val_acc: 0.7448\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4257 - acc: 0.8021 - val_loss: 0.5254 - val_acc: 0.7448\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4257 - acc: 0.8021 - val_loss: 0.5254 - val_acc: 0.7448\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - acc: 0.8021 - val_loss: 0.5255 - val_acc: 0.7448\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - acc: 0.8021 - val_loss: 0.5255 - val_acc: 0.7448\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4256 - acc: 0.8021 - val_loss: 0.5255 - val_acc: 0.7448\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - acc: 0.8021 - val_loss: 0.5255 - val_acc: 0.7448\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4255 - acc: 0.8021 - val_loss: 0.5255 - val_acc: 0.7448\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4255 - acc: 0.8021 - val_loss: 0.5255 - val_acc: 0.7448\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4254 - acc: 0.8021 - val_loss: 0.5256 - val_acc: 0.7448\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4254 - acc: 0.8021 - val_loss: 0.5256 - val_acc: 0.7448\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4254 - acc: 0.8021 - val_loss: 0.5256 - val_acc: 0.7448\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4254 - acc: 0.8021 - val_loss: 0.5256 - val_acc: 0.7448\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - acc: 0.8021 - val_loss: 0.5256 - val_acc: 0.7448\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4253 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7448\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4253 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7448\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4253 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7448\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4253 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7500\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4252 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7500\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4252 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7500\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4252 - acc: 0.8021 - val_loss: 0.5257 - val_acc: 0.7500\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4252 - acc: 0.8021 - val_loss: 0.5258 - val_acc: 0.7500\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4251 - acc: 0.8021 - val_loss: 0.5258 - val_acc: 0.7500\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4251 - acc: 0.8021 - val_loss: 0.5258 - val_acc: 0.7500\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4251 - acc: 0.8021 - val_loss: 0.5258 - val_acc: 0.7500\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4250 - acc: 0.8021 - val_loss: 0.5258 - val_acc: 0.7500\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - acc: 0.8021 - val_loss: 0.5258 - val_acc: 0.7500\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4250 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4250 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4249 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4249 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4249 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4249 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4248 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4248 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4247 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4247 - acc: 0.8021 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4247 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4247 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4246 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4246 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4246 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4245 - acc: 0.8021 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.5260 - val_acc: 0.7500\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4244 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4243 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4242 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4242 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4242 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1078/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 32us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7500\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4241 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7500\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4240 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7500\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4240 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4240 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4239 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4238 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4238 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4238 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4238 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4236 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4237 - acc: 0.8003 - val_loss: 0.5262 - val_acc: 0.7552\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4236 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4236 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4234 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4234 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4234 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4234 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4233 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4232 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4232 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4231 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4231 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4231 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7552\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4229 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4227 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4227 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4227 - acc: 0.8003 - val_loss: 0.5263 - val_acc: 0.7604\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4227 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4225 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5264 - val_acc: 0.7604\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4224 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4223 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.5265 - val_acc: 0.7604\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4221 - acc: 0.8021 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4221 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4221 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4221 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4220 - acc: 0.8021 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4220 - acc: 0.8003 - val_loss: 0.5266 - val_acc: 0.7604\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4220 - acc: 0.8021 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4220 - acc: 0.8003 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4220 - acc: 0.8021 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - acc: 0.8003 - val_loss: 0.5267 - val_acc: 0.7604\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4219 - acc: 0.8021 - val_loss: 0.5268 - val_acc: 0.7604\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4219 - acc: 0.8021 - val_loss: 0.5268 - val_acc: 0.7604\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4218 - acc: 0.8003 - val_loss: 0.5268 - val_acc: 0.7604\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4218 - acc: 0.8003 - val_loss: 0.5268 - val_acc: 0.7604\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4218 - acc: 0.8003 - val_loss: 0.5268 - val_acc: 0.7604\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - acc: 0.8003 - val_loss: 0.5268 - val_acc: 0.7604\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4217 - acc: 0.8003 - val_loss: 0.5269 - val_acc: 0.7604\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4217 - acc: 0.8003 - val_loss: 0.5269 - val_acc: 0.7604\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4217 - acc: 0.8003 - val_loss: 0.5269 - val_acc: 0.7604\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4217 - acc: 0.8003 - val_loss: 0.5269 - val_acc: 0.7604\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.5269 - val_acc: 0.7604\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4216 - acc: 0.8021 - val_loss: 0.5269 - val_acc: 0.7552\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4216 - acc: 0.8003 - val_loss: 0.5269 - val_acc: 0.7552\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4216 - acc: 0.8021 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4216 - acc: 0.7986 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8021 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4215 - acc: 0.8038 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 1196/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8021 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4215 - acc: 0.8038 - val_loss: 0.5270 - val_acc: 0.7552\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4215 - acc: 0.8038 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4215 - acc: 0.8038 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4214 - acc: 0.8038 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4214 - acc: 0.8038 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4214 - acc: 0.8038 - val_loss: 0.5271 - val_acc: 0.7552\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4214 - acc: 0.8038 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4213 - acc: 0.8038 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4213 - acc: 0.8038 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4213 - acc: 0.8038 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4212 - acc: 0.8038 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4212 - acc: 0.8038 - val_loss: 0.5272 - val_acc: 0.7552\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4212 - acc: 0.8038 - val_loss: 0.5273 - val_acc: 0.7552\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4212 - acc: 0.8038 - val_loss: 0.5273 - val_acc: 0.7552\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4212 - acc: 0.8056 - val_loss: 0.5273 - val_acc: 0.7552\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4211 - acc: 0.8038 - val_loss: 0.5273 - val_acc: 0.7552\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4211 - acc: 0.8038 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4211 - acc: 0.8038 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4211 - acc: 0.8056 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4211 - acc: 0.8038 - val_loss: 0.5274 - val_acc: 0.7552\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4210 - acc: 0.8073 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4210 - acc: 0.8056 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4210 - acc: 0.8090 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4209 - acc: 0.8090 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4209 - acc: 0.8073 - val_loss: 0.5275 - val_acc: 0.7552\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4209 - acc: 0.8090 - val_loss: 0.5276 - val_acc: 0.7552\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4209 - acc: 0.8090 - val_loss: 0.5276 - val_acc: 0.7552\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4209 - acc: 0.8090 - val_loss: 0.5276 - val_acc: 0.7552\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4208 - acc: 0.8090 - val_loss: 0.5276 - val_acc: 0.7552\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - acc: 0.8090 - val_loss: 0.5277 - val_acc: 0.7552\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4208 - acc: 0.8090 - val_loss: 0.5277 - val_acc: 0.7552\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4208 - acc: 0.8090 - val_loss: 0.5277 - val_acc: 0.7552\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4207 - acc: 0.8090 - val_loss: 0.5277 - val_acc: 0.7552\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4207 - acc: 0.8090 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4207 - acc: 0.8090 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4207 - acc: 0.8090 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4207 - acc: 0.8090 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4206 - acc: 0.8090 - val_loss: 0.5278 - val_acc: 0.7552\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4206 - acc: 0.8090 - val_loss: 0.5279 - val_acc: 0.7552\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4205 - acc: 0.8108 - val_loss: 0.5279 - val_acc: 0.7552\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4206 - acc: 0.8090 - val_loss: 0.5279 - val_acc: 0.7552\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4206 - acc: 0.8090 - val_loss: 0.5279 - val_acc: 0.7552\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - acc: 0.8090 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4205 - acc: 0.8090 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4205 - acc: 0.8090 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4204 - acc: 0.8108 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4204 - acc: 0.8108 - val_loss: 0.5280 - val_acc: 0.7552\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4204 - acc: 0.8108 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4203 - acc: 0.8108 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4203 - acc: 0.8108 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4203 - acc: 0.8108 - val_loss: 0.5281 - val_acc: 0.7552\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4203 - acc: 0.8108 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4203 - acc: 0.8108 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4202 - acc: 0.8125 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4202 - acc: 0.8125 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4202 - acc: 0.8125 - val_loss: 0.5282 - val_acc: 0.7552\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4202 - acc: 0.8125 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4201 - acc: 0.8108 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4201 - acc: 0.8142 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4201 - acc: 0.8108 - val_loss: 0.5283 - val_acc: 0.7552\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4200 - acc: 0.8108 - val_loss: 0.5284 - val_acc: 0.7604\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4201 - acc: 0.8108 - val_loss: 0.5284 - val_acc: 0.7604\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4200 - acc: 0.8108 - val_loss: 0.5284 - val_acc: 0.7604\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4200 - acc: 0.8108 - val_loss: 0.5284 - val_acc: 0.7604\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4199 - acc: 0.8108 - val_loss: 0.5285 - val_acc: 0.7604\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4199 - acc: 0.8108 - val_loss: 0.5285 - val_acc: 0.7604\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4199 - acc: 0.8125 - val_loss: 0.5285 - val_acc: 0.7604\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4198 - acc: 0.8108 - val_loss: 0.5285 - val_acc: 0.7604\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4199 - acc: 0.8108 - val_loss: 0.5286 - val_acc: 0.7604\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4199 - acc: 0.8108 - val_loss: 0.5286 - val_acc: 0.7604\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4198 - acc: 0.8108 - val_loss: 0.5286 - val_acc: 0.7604\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4198 - acc: 0.8125 - val_loss: 0.5286 - val_acc: 0.7604\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4198 - acc: 0.8108 - val_loss: 0.5287 - val_acc: 0.7604\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4198 - acc: 0.8125 - val_loss: 0.5287 - val_acc: 0.7604\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4198 - acc: 0.8125 - val_loss: 0.5287 - val_acc: 0.7604\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - acc: 0.8125 - val_loss: 0.5287 - val_acc: 0.7604\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - acc: 0.8108 - val_loss: 0.5287 - val_acc: 0.7604\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4196 - acc: 0.8125 - val_loss: 0.5288 - val_acc: 0.7604\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4196 - acc: 0.8108 - val_loss: 0.5288 - val_acc: 0.7604\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4196 - acc: 0.8108 - val_loss: 0.5288 - val_acc: 0.7604\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4196 - acc: 0.8125 - val_loss: 0.5288 - val_acc: 0.7604\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4196 - acc: 0.8108 - val_loss: 0.5288 - val_acc: 0.7604\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4195 - acc: 0.8125 - val_loss: 0.5289 - val_acc: 0.7604\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4195 - acc: 0.8125 - val_loss: 0.5289 - val_acc: 0.7604\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4195 - acc: 0.8108 - val_loss: 0.5289 - val_acc: 0.7604\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4195 - acc: 0.8125 - val_loss: 0.5289 - val_acc: 0.7604\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4194 - acc: 0.8125 - val_loss: 0.5290 - val_acc: 0.7604\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4194 - acc: 0.8142 - val_loss: 0.5290 - val_acc: 0.7604\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4194 - acc: 0.8125 - val_loss: 0.5290 - val_acc: 0.7604\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4193 - acc: 0.8125 - val_loss: 0.5290 - val_acc: 0.7604\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4193 - acc: 0.8125 - val_loss: 0.5291 - val_acc: 0.7604\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4193 - acc: 0.8125 - val_loss: 0.5291 - val_acc: 0.7604\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4193 - acc: 0.8125 - val_loss: 0.5291 - val_acc: 0.7604\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4192 - acc: 0.8142 - val_loss: 0.5291 - val_acc: 0.7604\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4192 - acc: 0.8125 - val_loss: 0.5291 - val_acc: 0.7604\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4192 - acc: 0.8125 - val_loss: 0.5292 - val_acc: 0.7604\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4192 - acc: 0.8125 - val_loss: 0.5292 - val_acc: 0.7604\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4191 - acc: 0.8125 - val_loss: 0.5292 - val_acc: 0.7604\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4191 - acc: 0.8125 - val_loss: 0.5292 - val_acc: 0.7552\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4191 - acc: 0.8142 - val_loss: 0.5293 - val_acc: 0.7552\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4191 - acc: 0.8142 - val_loss: 0.5293 - val_acc: 0.7552\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4191 - acc: 0.8142 - val_loss: 0.5293 - val_acc: 0.7552\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4190 - acc: 0.8142 - val_loss: 0.5293 - val_acc: 0.7552\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4190 - acc: 0.8125 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4190 - acc: 0.8142 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4190 - acc: 0.8142 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4189 - acc: 0.8125 - val_loss: 0.5294 - val_acc: 0.7552\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4189 - acc: 0.8125 - val_loss: 0.5295 - val_acc: 0.7552\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4189 - acc: 0.8125 - val_loss: 0.5295 - val_acc: 0.7552\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4189 - acc: 0.8142 - val_loss: 0.5295 - val_acc: 0.7552\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4189 - acc: 0.8125 - val_loss: 0.5295 - val_acc: 0.7552\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4188 - acc: 0.8142 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4188 - acc: 0.8125 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4187 - acc: 0.8125 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4187 - acc: 0.8142 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4187 - acc: 0.8125 - val_loss: 0.5296 - val_acc: 0.7552\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - acc: 0.8142 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 1314/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 39us/step - loss: 0.4186 - acc: 0.8125 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4186 - acc: 0.8125 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - acc: 0.8125 - val_loss: 0.5297 - val_acc: 0.7552\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4185 - acc: 0.8142 - val_loss: 0.5298 - val_acc: 0.7552\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4185 - acc: 0.8142 - val_loss: 0.5298 - val_acc: 0.7552\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - acc: 0.8142 - val_loss: 0.5298 - val_acc: 0.7552\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - acc: 0.8125 - val_loss: 0.5298 - val_acc: 0.7552\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4184 - acc: 0.8125 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4183 - acc: 0.8142 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - acc: 0.8142 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4183 - acc: 0.8142 - val_loss: 0.5299 - val_acc: 0.7552\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - acc: 0.8142 - val_loss: 0.5300 - val_acc: 0.7552\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4183 - acc: 0.8142 - val_loss: 0.5300 - val_acc: 0.7552\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4182 - acc: 0.8142 - val_loss: 0.5300 - val_acc: 0.7552\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4182 - acc: 0.8142 - val_loss: 0.5300 - val_acc: 0.7552\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4182 - acc: 0.8142 - val_loss: 0.5301 - val_acc: 0.7552\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4181 - acc: 0.8125 - val_loss: 0.5301 - val_acc: 0.7552\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4181 - acc: 0.8142 - val_loss: 0.5301 - val_acc: 0.7552\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4181 - acc: 0.8142 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4181 - acc: 0.8142 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4180 - acc: 0.8142 - val_loss: 0.5302 - val_acc: 0.7552\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - acc: 0.8142 - val_loss: 0.5303 - val_acc: 0.7552\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4180 - acc: 0.8142 - val_loss: 0.5303 - val_acc: 0.7552\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4179 - acc: 0.8142 - val_loss: 0.5303 - val_acc: 0.7552\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4179 - acc: 0.8142 - val_loss: 0.5304 - val_acc: 0.7552\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4179 - acc: 0.8142 - val_loss: 0.5304 - val_acc: 0.7552\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4178 - acc: 0.8142 - val_loss: 0.5304 - val_acc: 0.7552\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4178 - acc: 0.8142 - val_loss: 0.5304 - val_acc: 0.7552\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4177 - acc: 0.8142 - val_loss: 0.5305 - val_acc: 0.7552\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4177 - acc: 0.8142 - val_loss: 0.5305 - val_acc: 0.7552\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - acc: 0.8142 - val_loss: 0.5305 - val_acc: 0.7552\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4177 - acc: 0.8142 - val_loss: 0.5305 - val_acc: 0.7552\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4176 - acc: 0.8142 - val_loss: 0.5305 - val_acc: 0.7552\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4176 - acc: 0.8142 - val_loss: 0.5306 - val_acc: 0.7552\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - acc: 0.8142 - val_loss: 0.5306 - val_acc: 0.7552\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4175 - acc: 0.8142 - val_loss: 0.5306 - val_acc: 0.7552\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4175 - acc: 0.8142 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4175 - acc: 0.8142 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - acc: 0.8142 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4174 - acc: 0.8142 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4173 - acc: 0.8160 - val_loss: 0.5307 - val_acc: 0.7552\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4173 - acc: 0.8160 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4173 - acc: 0.8160 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4173 - acc: 0.8142 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4172 - acc: 0.8160 - val_loss: 0.5308 - val_acc: 0.7552\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4172 - acc: 0.8160 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4172 - acc: 0.8160 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4171 - acc: 0.8160 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4171 - acc: 0.8160 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4171 - acc: 0.8177 - val_loss: 0.5309 - val_acc: 0.7500\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4171 - acc: 0.8177 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4170 - acc: 0.8177 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4170 - acc: 0.8177 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4170 - acc: 0.8160 - val_loss: 0.5311 - val_acc: 0.7500\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4170 - acc: 0.8177 - val_loss: 0.5311 - val_acc: 0.7500\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4169 - acc: 0.8160 - val_loss: 0.5311 - val_acc: 0.7500\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - acc: 0.8160 - val_loss: 0.5311 - val_acc: 0.7500\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4168 - acc: 0.8160 - val_loss: 0.5311 - val_acc: 0.7500\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - acc: 0.8160 - val_loss: 0.5312 - val_acc: 0.7500\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4168 - acc: 0.8160 - val_loss: 0.5312 - val_acc: 0.7500\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4168 - acc: 0.8160 - val_loss: 0.5312 - val_acc: 0.7500\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - acc: 0.8160 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4167 - acc: 0.8160 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4167 - acc: 0.8160 - val_loss: 0.5313 - val_acc: 0.7500\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4166 - acc: 0.8160 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4166 - acc: 0.8160 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4165 - acc: 0.8160 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4165 - acc: 0.8160 - val_loss: 0.5314 - val_acc: 0.7500\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4166 - acc: 0.8177 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4165 - acc: 0.8177 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4164 - acc: 0.8160 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4164 - acc: 0.8177 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4164 - acc: 0.8177 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - acc: 0.8177 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - acc: 0.8177 - val_loss: 0.5316 - val_acc: 0.7500\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4163 - acc: 0.8177 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4163 - acc: 0.8177 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4163 - acc: 0.8177 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4163 - acc: 0.8177 - val_loss: 0.5317 - val_acc: 0.7500\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4162 - acc: 0.8177 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - acc: 0.8177 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4162 - acc: 0.8177 - val_loss: 0.5318 - val_acc: 0.7500\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - acc: 0.8177 - val_loss: 0.5319 - val_acc: 0.7500\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - acc: 0.8177 - val_loss: 0.5319 - val_acc: 0.7500\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4161 - acc: 0.8177 - val_loss: 0.5319 - val_acc: 0.7500\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.4161 - acc: 0.8177 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4161 - acc: 0.8177 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - acc: 0.8177 - val_loss: 0.5320 - val_acc: 0.7500\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4160 - acc: 0.8177 - val_loss: 0.5321 - val_acc: 0.7500\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4160 - acc: 0.8177 - val_loss: 0.5321 - val_acc: 0.7500\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4160 - acc: 0.8177 - val_loss: 0.5321 - val_acc: 0.7500\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4159 - acc: 0.8177 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - acc: 0.8177 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - acc: 0.8177 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4159 - acc: 0.8177 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - acc: 0.8177 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4159 - acc: 0.8177 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.4158 - acc: 0.8177 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4158 - acc: 0.8177 - val_loss: 0.5323 - val_acc: 0.7500\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4158 - acc: 0.8177 - val_loss: 0.5324 - val_acc: 0.7500\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4158 - acc: 0.8177 - val_loss: 0.5324 - val_acc: 0.7500\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4157 - acc: 0.8177 - val_loss: 0.5324 - val_acc: 0.7500\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4157 - acc: 0.8177 - val_loss: 0.5324 - val_acc: 0.7500\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4157 - acc: 0.8177 - val_loss: 0.5325 - val_acc: 0.7500\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4157 - acc: 0.8177 - val_loss: 0.5325 - val_acc: 0.7500\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4157 - acc: 0.8177 - val_loss: 0.5325 - val_acc: 0.7448\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4156 - acc: 0.8177 - val_loss: 0.5325 - val_acc: 0.7448\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4156 - acc: 0.8177 - val_loss: 0.5326 - val_acc: 0.7448\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4156 - acc: 0.8177 - val_loss: 0.5326 - val_acc: 0.7448\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4156 - acc: 0.8177 - val_loss: 0.5326 - val_acc: 0.7448\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4156 - acc: 0.8177 - val_loss: 0.5327 - val_acc: 0.7448\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4155 - acc: 0.8177 - val_loss: 0.5327 - val_acc: 0.7448\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4155 - acc: 0.8177 - val_loss: 0.5327 - val_acc: 0.7448\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4155 - acc: 0.8194 - val_loss: 0.5328 - val_acc: 0.7448\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4154 - acc: 0.8177 - val_loss: 0.5328 - val_acc: 0.7448\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - acc: 0.8194 - val_loss: 0.5328 - val_acc: 0.7448\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4154 - acc: 0.8177 - val_loss: 0.5328 - val_acc: 0.7448\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4154 - acc: 0.8177 - val_loss: 0.5329 - val_acc: 0.7448\n",
      "Epoch 1432/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 48us/step - loss: 0.4154 - acc: 0.8177 - val_loss: 0.5329 - val_acc: 0.7448\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4154 - acc: 0.8194 - val_loss: 0.5329 - val_acc: 0.7448\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4153 - acc: 0.8177 - val_loss: 0.5330 - val_acc: 0.7448\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4153 - acc: 0.8194 - val_loss: 0.5330 - val_acc: 0.7448\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4153 - acc: 0.8177 - val_loss: 0.5330 - val_acc: 0.7448\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4153 - acc: 0.8194 - val_loss: 0.5330 - val_acc: 0.7448\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4152 - acc: 0.8194 - val_loss: 0.5331 - val_acc: 0.7448\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4152 - acc: 0.8194 - val_loss: 0.5331 - val_acc: 0.7448\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 24us/step - loss: 0.4153 - acc: 0.8194 - val_loss: 0.5331 - val_acc: 0.7448\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4152 - acc: 0.8194 - val_loss: 0.5332 - val_acc: 0.7448\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4152 - acc: 0.8194 - val_loss: 0.5332 - val_acc: 0.7448\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.4151 - acc: 0.8194 - val_loss: 0.5332 - val_acc: 0.7448\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4151 - acc: 0.8194 - val_loss: 0.5333 - val_acc: 0.7448\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4151 - acc: 0.8194 - val_loss: 0.5333 - val_acc: 0.7448\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4151 - acc: 0.8194 - val_loss: 0.5333 - val_acc: 0.7448\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.4150 - acc: 0.8194 - val_loss: 0.5333 - val_acc: 0.7448\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4150 - acc: 0.8212 - val_loss: 0.5334 - val_acc: 0.7448\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4150 - acc: 0.8194 - val_loss: 0.5334 - val_acc: 0.7448\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4150 - acc: 0.8212 - val_loss: 0.5334 - val_acc: 0.7448\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - acc: 0.8194 - val_loss: 0.5334 - val_acc: 0.7448\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4149 - acc: 0.8212 - val_loss: 0.5335 - val_acc: 0.7448\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4149 - acc: 0.8194 - val_loss: 0.5335 - val_acc: 0.7448\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4149 - acc: 0.8212 - val_loss: 0.5335 - val_acc: 0.7448\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4149 - acc: 0.8194 - val_loss: 0.5336 - val_acc: 0.7448\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4149 - acc: 0.8212 - val_loss: 0.5336 - val_acc: 0.7448\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4148 - acc: 0.8212 - val_loss: 0.5336 - val_acc: 0.7448\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4148 - acc: 0.8212 - val_loss: 0.5337 - val_acc: 0.7448\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4148 - acc: 0.8212 - val_loss: 0.5337 - val_acc: 0.7448\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4147 - acc: 0.8194 - val_loss: 0.5337 - val_acc: 0.7448\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4147 - acc: 0.8194 - val_loss: 0.5338 - val_acc: 0.7448\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4147 - acc: 0.8194 - val_loss: 0.5338 - val_acc: 0.7448\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4147 - acc: 0.8194 - val_loss: 0.5338 - val_acc: 0.7448\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4147 - acc: 0.8212 - val_loss: 0.5339 - val_acc: 0.7448\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4146 - acc: 0.8194 - val_loss: 0.5339 - val_acc: 0.7448\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4146 - acc: 0.8194 - val_loss: 0.5339 - val_acc: 0.7448\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4146 - acc: 0.8194 - val_loss: 0.5339 - val_acc: 0.7448\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4146 - acc: 0.8194 - val_loss: 0.5340 - val_acc: 0.7448\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4146 - acc: 0.8194 - val_loss: 0.5340 - val_acc: 0.7448\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4146 - acc: 0.8194 - val_loss: 0.5340 - val_acc: 0.7448\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4145 - acc: 0.8194 - val_loss: 0.5341 - val_acc: 0.7448\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4145 - acc: 0.8194 - val_loss: 0.5341 - val_acc: 0.7448\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4144 - acc: 0.8194 - val_loss: 0.5341 - val_acc: 0.7448\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4144 - acc: 0.8194 - val_loss: 0.5342 - val_acc: 0.7448\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4144 - acc: 0.8194 - val_loss: 0.5342 - val_acc: 0.7448\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4144 - acc: 0.8194 - val_loss: 0.5342 - val_acc: 0.7448\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4144 - acc: 0.8194 - val_loss: 0.5342 - val_acc: 0.7448\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4143 - acc: 0.8194 - val_loss: 0.5343 - val_acc: 0.7448\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4143 - acc: 0.8194 - val_loss: 0.5343 - val_acc: 0.7448\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4143 - acc: 0.8194 - val_loss: 0.5343 - val_acc: 0.7448\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4143 - acc: 0.8177 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4143 - acc: 0.8194 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4142 - acc: 0.8212 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4142 - acc: 0.8177 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4142 - acc: 0.8177 - val_loss: 0.5345 - val_acc: 0.7448\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4142 - acc: 0.8194 - val_loss: 0.5345 - val_acc: 0.7448\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4142 - acc: 0.8194 - val_loss: 0.5345 - val_acc: 0.7448\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4141 - acc: 0.8194 - val_loss: 0.5346 - val_acc: 0.7448\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4142 - acc: 0.8212 - val_loss: 0.5346 - val_acc: 0.7448\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4141 - acc: 0.8212 - val_loss: 0.5346 - val_acc: 0.7448\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4141 - acc: 0.8194 - val_loss: 0.5347 - val_acc: 0.7448\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4141 - acc: 0.8194 - val_loss: 0.5347 - val_acc: 0.7448\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4141 - acc: 0.8194 - val_loss: 0.5347 - val_acc: 0.7448\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4140 - acc: 0.8194 - val_loss: 0.5347 - val_acc: 0.7448\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4140 - acc: 0.8194 - val_loss: 0.5348 - val_acc: 0.7448\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4140 - acc: 0.8194 - val_loss: 0.5348 - val_acc: 0.7448\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4139 - acc: 0.8194 - val_loss: 0.5348 - val_acc: 0.7448\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4139 - acc: 0.8194 - val_loss: 0.5348 - val_acc: 0.7448\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4139 - acc: 0.8212 - val_loss: 0.5349 - val_acc: 0.7448\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4138 - acc: 0.8194 - val_loss: 0.5349 - val_acc: 0.7448\n"
     ]
    }
   ],
   "source": [
    "#Train function!!\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n",
    "\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4139 - acc: 0.8194 - val_loss: 0.5349 - val_acc: 0.7448\n",
      "Epoch 2/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4139 - acc: 0.8194 - val_loss: 0.5349 - val_acc: 0.7448\n",
      "Epoch 3/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4138 - acc: 0.8194 - val_loss: 0.5350 - val_acc: 0.7448\n",
      "Epoch 4/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4138 - acc: 0.8194 - val_loss: 0.5350 - val_acc: 0.7448\n",
      "Epoch 5/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4138 - acc: 0.8194 - val_loss: 0.5350 - val_acc: 0.7448\n",
      "Epoch 6/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4138 - acc: 0.8212 - val_loss: 0.5351 - val_acc: 0.7448\n",
      "Epoch 7/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4137 - acc: 0.8212 - val_loss: 0.5351 - val_acc: 0.7448\n",
      "Epoch 8/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4137 - acc: 0.8194 - val_loss: 0.5351 - val_acc: 0.7448\n",
      "Epoch 9/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4137 - acc: 0.8212 - val_loss: 0.5351 - val_acc: 0.7448\n",
      "Epoch 10/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4137 - acc: 0.8212 - val_loss: 0.5352 - val_acc: 0.7448\n",
      "Epoch 11/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4137 - acc: 0.8212 - val_loss: 0.5352 - val_acc: 0.7448\n",
      "Epoch 12/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4137 - acc: 0.8194 - val_loss: 0.5352 - val_acc: 0.7448\n",
      "Epoch 13/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4136 - acc: 0.8212 - val_loss: 0.5352 - val_acc: 0.7448\n",
      "Epoch 14/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4136 - acc: 0.8212 - val_loss: 0.5353 - val_acc: 0.7448\n",
      "Epoch 15/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4136 - acc: 0.8194 - val_loss: 0.5353 - val_acc: 0.7448\n",
      "Epoch 16/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.5353 - val_acc: 0.7448\n",
      "Epoch 17/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4136 - acc: 0.8229 - val_loss: 0.5353 - val_acc: 0.7448\n",
      "Epoch 18/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.5354 - val_acc: 0.7448\n",
      "Epoch 19/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.5354 - val_acc: 0.7448\n",
      "Epoch 20/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.5354 - val_acc: 0.7448\n",
      "Epoch 21/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.5355 - val_acc: 0.7448\n",
      "Epoch 22/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4134 - acc: 0.8212 - val_loss: 0.5355 - val_acc: 0.7448\n",
      "Epoch 23/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4135 - acc: 0.8212 - val_loss: 0.5355 - val_acc: 0.7448\n",
      "Epoch 24/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4134 - acc: 0.8229 - val_loss: 0.5355 - val_acc: 0.7448\n",
      "Epoch 25/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4134 - acc: 0.8212 - val_loss: 0.5356 - val_acc: 0.7448\n",
      "Epoch 26/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4134 - acc: 0.8229 - val_loss: 0.5356 - val_acc: 0.7448\n",
      "Epoch 27/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4134 - acc: 0.8212 - val_loss: 0.5356 - val_acc: 0.7448\n",
      "Epoch 28/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4134 - acc: 0.8247 - val_loss: 0.5357 - val_acc: 0.7448\n",
      "Epoch 29/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4133 - acc: 0.8212 - val_loss: 0.5357 - val_acc: 0.7448\n",
      "Epoch 30/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4133 - acc: 0.8229 - val_loss: 0.5357 - val_acc: 0.7448\n",
      "Epoch 31/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4133 - acc: 0.8247 - val_loss: 0.5357 - val_acc: 0.7448\n",
      "Epoch 32/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4133 - acc: 0.8229 - val_loss: 0.5357 - val_acc: 0.7448\n",
      "Epoch 33/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4132 - acc: 0.8229 - val_loss: 0.5358 - val_acc: 0.7448\n",
      "Epoch 34/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5358 - val_acc: 0.7448\n",
      "Epoch 35/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5358 - val_acc: 0.7448\n",
      "Epoch 36/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5359 - val_acc: 0.7448\n",
      "Epoch 37/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5359 - val_acc: 0.7448\n",
      "Epoch 38/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5359 - val_acc: 0.7448\n",
      "Epoch 39/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5359 - val_acc: 0.7448\n",
      "Epoch 40/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4132 - acc: 0.8247 - val_loss: 0.5360 - val_acc: 0.7448\n",
      "Epoch 41/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4131 - acc: 0.8247 - val_loss: 0.5360 - val_acc: 0.7448\n",
      "Epoch 42/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4131 - acc: 0.8247 - val_loss: 0.5360 - val_acc: 0.7448\n",
      "Epoch 43/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4131 - acc: 0.8247 - val_loss: 0.5360 - val_acc: 0.7448\n",
      "Epoch 44/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4131 - acc: 0.8247 - val_loss: 0.5361 - val_acc: 0.7448\n",
      "Epoch 45/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4131 - acc: 0.8229 - val_loss: 0.5361 - val_acc: 0.7396\n",
      "Epoch 46/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4131 - acc: 0.8247 - val_loss: 0.5361 - val_acc: 0.7396\n",
      "Epoch 47/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4130 - acc: 0.8247 - val_loss: 0.5361 - val_acc: 0.7396\n",
      "Epoch 48/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4130 - acc: 0.8264 - val_loss: 0.5362 - val_acc: 0.7396\n",
      "Epoch 49/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4130 - acc: 0.8264 - val_loss: 0.5362 - val_acc: 0.7396\n",
      "Epoch 50/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4130 - acc: 0.8264 - val_loss: 0.5362 - val_acc: 0.7396\n",
      "Epoch 51/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4130 - acc: 0.8264 - val_loss: 0.5362 - val_acc: 0.7396\n",
      "Epoch 52/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4129 - acc: 0.8264 - val_loss: 0.5363 - val_acc: 0.7396\n",
      "Epoch 53/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4129 - acc: 0.8264 - val_loss: 0.5363 - val_acc: 0.7396\n",
      "Epoch 54/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4129 - acc: 0.8264 - val_loss: 0.5363 - val_acc: 0.7396\n",
      "Epoch 55/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4129 - acc: 0.8264 - val_loss: 0.5363 - val_acc: 0.7396\n",
      "Epoch 56/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4129 - acc: 0.8264 - val_loss: 0.5364 - val_acc: 0.7396\n",
      "Epoch 57/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4128 - acc: 0.8264 - val_loss: 0.5364 - val_acc: 0.7396\n",
      "Epoch 58/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4129 - acc: 0.8264 - val_loss: 0.5364 - val_acc: 0.7396\n",
      "Epoch 59/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4128 - acc: 0.8264 - val_loss: 0.5364 - val_acc: 0.7396\n",
      "Epoch 60/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4128 - acc: 0.8264 - val_loss: 0.5365 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4128 - acc: 0.8264 - val_loss: 0.5365 - val_acc: 0.7396\n",
      "Epoch 62/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4128 - acc: 0.8264 - val_loss: 0.5365 - val_acc: 0.7396\n",
      "Epoch 63/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5365 - val_acc: 0.7396\n",
      "Epoch 64/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5366 - val_acc: 0.7396\n",
      "Epoch 65/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5366 - val_acc: 0.7396\n",
      "Epoch 66/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5366 - val_acc: 0.7396\n",
      "Epoch 67/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5366 - val_acc: 0.7396\n",
      "Epoch 68/3000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5366 - val_acc: 0.7396\n",
      "Epoch 69/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5366 - val_acc: 0.7396\n",
      "Epoch 70/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4127 - acc: 0.8264 - val_loss: 0.5367 - val_acc: 0.7396\n",
      "Epoch 71/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5367 - val_acc: 0.7396\n",
      "Epoch 72/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5367 - val_acc: 0.7396\n",
      "Epoch 73/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5367 - val_acc: 0.7396\n",
      "Epoch 74/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5368 - val_acc: 0.7396\n",
      "Epoch 75/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5368 - val_acc: 0.7396\n",
      "Epoch 76/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5368 - val_acc: 0.7396\n",
      "Epoch 77/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5368 - val_acc: 0.7396\n",
      "Epoch 78/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4126 - acc: 0.8264 - val_loss: 0.5368 - val_acc: 0.7396\n",
      "Epoch 79/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5369 - val_acc: 0.7396\n",
      "Epoch 80/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5369 - val_acc: 0.7396\n",
      "Epoch 81/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5369 - val_acc: 0.7396\n",
      "Epoch 82/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5369 - val_acc: 0.7396\n",
      "Epoch 83/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4125 - acc: 0.8264 - val_loss: 0.5370 - val_acc: 0.7396\n",
      "Epoch 84/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4124 - acc: 0.8264 - val_loss: 0.5370 - val_acc: 0.7396\n",
      "Epoch 85/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4124 - acc: 0.8264 - val_loss: 0.5370 - val_acc: 0.7396\n",
      "Epoch 86/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4124 - acc: 0.8264 - val_loss: 0.5370 - val_acc: 0.7396\n",
      "Epoch 87/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4124 - acc: 0.8264 - val_loss: 0.5371 - val_acc: 0.7396\n",
      "Epoch 88/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4124 - acc: 0.8264 - val_loss: 0.5371 - val_acc: 0.7396\n",
      "Epoch 89/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5371 - val_acc: 0.7396\n",
      "Epoch 90/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5371 - val_acc: 0.7396\n",
      "Epoch 91/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4124 - acc: 0.8264 - val_loss: 0.5371 - val_acc: 0.7396\n",
      "Epoch 92/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5372 - val_acc: 0.7396\n",
      "Epoch 93/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5372 - val_acc: 0.7396\n",
      "Epoch 94/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5372 - val_acc: 0.7396\n",
      "Epoch 95/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5372 - val_acc: 0.7396\n",
      "Epoch 96/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5373 - val_acc: 0.7396\n",
      "Epoch 97/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5373 - val_acc: 0.7396\n",
      "Epoch 98/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4123 - acc: 0.8264 - val_loss: 0.5373 - val_acc: 0.7396\n",
      "Epoch 99/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5373 - val_acc: 0.7396\n",
      "Epoch 100/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5374 - val_acc: 0.7396\n",
      "Epoch 101/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5374 - val_acc: 0.7396\n",
      "Epoch 102/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5374 - val_acc: 0.7396\n",
      "Epoch 103/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5374 - val_acc: 0.7396\n",
      "Epoch 104/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5374 - val_acc: 0.7396\n",
      "Epoch 105/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5375 - val_acc: 0.7396\n",
      "Epoch 106/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4122 - acc: 0.8264 - val_loss: 0.5375 - val_acc: 0.7396\n",
      "Epoch 107/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5375 - val_acc: 0.7344\n",
      "Epoch 108/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5375 - val_acc: 0.7344\n",
      "Epoch 109/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5376 - val_acc: 0.7344\n",
      "Epoch 110/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5376 - val_acc: 0.7344\n",
      "Epoch 111/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.5376 - val_acc: 0.7344\n",
      "Epoch 112/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4120 - acc: 0.8264 - val_loss: 0.5376 - val_acc: 0.7344\n",
      "Epoch 113/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4120 - acc: 0.8264 - val_loss: 0.5376 - val_acc: 0.7344\n",
      "Epoch 114/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4120 - acc: 0.8247 - val_loss: 0.5377 - val_acc: 0.7344\n",
      "Epoch 115/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4120 - acc: 0.8264 - val_loss: 0.5377 - val_acc: 0.7344\n",
      "Epoch 116/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4120 - acc: 0.8264 - val_loss: 0.5377 - val_acc: 0.7344\n",
      "Epoch 117/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4120 - acc: 0.8247 - val_loss: 0.5378 - val_acc: 0.7396\n",
      "Epoch 118/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4119 - acc: 0.8264 - val_loss: 0.5378 - val_acc: 0.7396\n",
      "Epoch 119/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4119 - acc: 0.8264 - val_loss: 0.5378 - val_acc: 0.7396\n",
      "Epoch 120/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4120 - acc: 0.8264 - val_loss: 0.5378 - val_acc: 0.7396\n",
      "Epoch 121/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 34us/step - loss: 0.4119 - acc: 0.8247 - val_loss: 0.5379 - val_acc: 0.7396\n",
      "Epoch 122/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4119 - acc: 0.8264 - val_loss: 0.5379 - val_acc: 0.7396\n",
      "Epoch 123/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4119 - acc: 0.8264 - val_loss: 0.5379 - val_acc: 0.7396\n",
      "Epoch 124/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4119 - acc: 0.8264 - val_loss: 0.5380 - val_acc: 0.7396\n",
      "Epoch 125/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4118 - acc: 0.8264 - val_loss: 0.5380 - val_acc: 0.7396\n",
      "Epoch 126/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4118 - acc: 0.8264 - val_loss: 0.5380 - val_acc: 0.7396\n",
      "Epoch 127/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4118 - acc: 0.8247 - val_loss: 0.5381 - val_acc: 0.7396\n",
      "Epoch 128/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4118 - acc: 0.8247 - val_loss: 0.5381 - val_acc: 0.7396\n",
      "Epoch 129/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5382 - val_acc: 0.7396\n",
      "Epoch 130/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4118 - acc: 0.8247 - val_loss: 0.5382 - val_acc: 0.7396\n",
      "Epoch 131/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5382 - val_acc: 0.7396\n",
      "Epoch 132/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5383 - val_acc: 0.7396\n",
      "Epoch 133/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5383 - val_acc: 0.7396\n",
      "Epoch 134/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5383 - val_acc: 0.7448\n",
      "Epoch 135/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5384 - val_acc: 0.7448\n",
      "Epoch 136/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4116 - acc: 0.8247 - val_loss: 0.5384 - val_acc: 0.7448\n",
      "Epoch 137/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4117 - acc: 0.8247 - val_loss: 0.5384 - val_acc: 0.7448\n",
      "Epoch 138/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4116 - acc: 0.8247 - val_loss: 0.5385 - val_acc: 0.7448\n",
      "Epoch 139/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4116 - acc: 0.8247 - val_loss: 0.5385 - val_acc: 0.7448\n",
      "Epoch 140/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4116 - acc: 0.8247 - val_loss: 0.5385 - val_acc: 0.7448\n",
      "Epoch 141/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4115 - acc: 0.8247 - val_loss: 0.5386 - val_acc: 0.7448\n",
      "Epoch 142/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4116 - acc: 0.8247 - val_loss: 0.5386 - val_acc: 0.7448\n",
      "Epoch 143/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4115 - acc: 0.8264 - val_loss: 0.5387 - val_acc: 0.7448\n",
      "Epoch 144/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4115 - acc: 0.8264 - val_loss: 0.5387 - val_acc: 0.7448\n",
      "Epoch 145/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4115 - acc: 0.8247 - val_loss: 0.5387 - val_acc: 0.7448\n",
      "Epoch 146/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4115 - acc: 0.8264 - val_loss: 0.5388 - val_acc: 0.7448\n",
      "Epoch 147/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5388 - val_acc: 0.7448\n",
      "Epoch 148/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4115 - acc: 0.8264 - val_loss: 0.5388 - val_acc: 0.7448\n",
      "Epoch 149/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5388 - val_acc: 0.7448\n",
      "Epoch 150/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5389 - val_acc: 0.7448\n",
      "Epoch 151/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5389 - val_acc: 0.7448\n",
      "Epoch 152/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5389 - val_acc: 0.7448\n",
      "Epoch 153/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5390 - val_acc: 0.7448\n",
      "Epoch 154/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5390 - val_acc: 0.7448\n",
      "Epoch 155/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.5390 - val_acc: 0.7448\n",
      "Epoch 156/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4113 - acc: 0.8264 - val_loss: 0.5390 - val_acc: 0.7448\n",
      "Epoch 157/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4113 - acc: 0.8264 - val_loss: 0.5391 - val_acc: 0.7448\n",
      "Epoch 158/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4112 - acc: 0.8264 - val_loss: 0.5391 - val_acc: 0.7448\n",
      "Epoch 159/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4112 - acc: 0.8247 - val_loss: 0.5391 - val_acc: 0.7448\n",
      "Epoch 160/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4112 - acc: 0.8247 - val_loss: 0.5392 - val_acc: 0.7448\n",
      "Epoch 161/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4112 - acc: 0.8247 - val_loss: 0.5392 - val_acc: 0.7448\n",
      "Epoch 162/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4112 - acc: 0.8264 - val_loss: 0.5392 - val_acc: 0.7448\n",
      "Epoch 163/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4112 - acc: 0.8247 - val_loss: 0.5393 - val_acc: 0.7448\n",
      "Epoch 164/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5393 - val_acc: 0.7448\n",
      "Epoch 165/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4112 - acc: 0.8247 - val_loss: 0.5393 - val_acc: 0.7448\n",
      "Epoch 166/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4112 - acc: 0.8247 - val_loss: 0.5394 - val_acc: 0.7448\n",
      "Epoch 167/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5394 - val_acc: 0.7448\n",
      "Epoch 168/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5394 - val_acc: 0.7448\n",
      "Epoch 169/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5394 - val_acc: 0.7448\n",
      "Epoch 170/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5395 - val_acc: 0.7448\n",
      "Epoch 171/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5395 - val_acc: 0.7448\n",
      "Epoch 172/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4110 - acc: 0.8247 - val_loss: 0.5395 - val_acc: 0.7448\n",
      "Epoch 173/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4110 - acc: 0.8247 - val_loss: 0.5395 - val_acc: 0.7448\n",
      "Epoch 174/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4111 - acc: 0.8247 - val_loss: 0.5396 - val_acc: 0.7448\n",
      "Epoch 175/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4110 - acc: 0.8247 - val_loss: 0.5396 - val_acc: 0.7448\n",
      "Epoch 176/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4109 - acc: 0.8247 - val_loss: 0.5396 - val_acc: 0.7448\n",
      "Epoch 177/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4110 - acc: 0.8247 - val_loss: 0.5397 - val_acc: 0.7448\n",
      "Epoch 178/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4109 - acc: 0.8247 - val_loss: 0.5397 - val_acc: 0.7448\n",
      "Epoch 179/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4109 - acc: 0.8247 - val_loss: 0.5397 - val_acc: 0.7448\n",
      "Epoch 180/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4109 - acc: 0.8247 - val_loss: 0.5398 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4109 - acc: 0.8247 - val_loss: 0.5398 - val_acc: 0.7448\n",
      "Epoch 182/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4108 - acc: 0.8247 - val_loss: 0.5398 - val_acc: 0.7448\n",
      "Epoch 183/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4108 - acc: 0.8247 - val_loss: 0.5399 - val_acc: 0.7448\n",
      "Epoch 184/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4108 - acc: 0.8247 - val_loss: 0.5399 - val_acc: 0.7448\n",
      "Epoch 185/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4108 - acc: 0.8247 - val_loss: 0.5399 - val_acc: 0.7448\n",
      "Epoch 186/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4108 - acc: 0.8247 - val_loss: 0.5399 - val_acc: 0.7448\n",
      "Epoch 187/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4108 - acc: 0.8247 - val_loss: 0.5400 - val_acc: 0.7448\n",
      "Epoch 188/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5400 - val_acc: 0.7448\n",
      "Epoch 189/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5400 - val_acc: 0.7448\n",
      "Epoch 190/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5401 - val_acc: 0.7448\n",
      "Epoch 191/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5401 - val_acc: 0.7448\n",
      "Epoch 192/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5401 - val_acc: 0.7448\n",
      "Epoch 193/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5402 - val_acc: 0.7448\n",
      "Epoch 194/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4107 - acc: 0.8247 - val_loss: 0.5402 - val_acc: 0.7448\n",
      "Epoch 195/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4106 - acc: 0.8247 - val_loss: 0.5403 - val_acc: 0.7448\n",
      "Epoch 196/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4106 - acc: 0.8247 - val_loss: 0.5403 - val_acc: 0.7448\n",
      "Epoch 197/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4106 - acc: 0.8247 - val_loss: 0.5404 - val_acc: 0.7448\n",
      "Epoch 198/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4106 - acc: 0.8247 - val_loss: 0.5404 - val_acc: 0.7448\n",
      "Epoch 199/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4106 - acc: 0.8229 - val_loss: 0.5405 - val_acc: 0.7448\n",
      "Epoch 200/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4105 - acc: 0.8247 - val_loss: 0.5405 - val_acc: 0.7448\n",
      "Epoch 201/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4105 - acc: 0.8247 - val_loss: 0.5406 - val_acc: 0.7448\n",
      "Epoch 202/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4105 - acc: 0.8247 - val_loss: 0.5406 - val_acc: 0.7448\n",
      "Epoch 203/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4105 - acc: 0.8247 - val_loss: 0.5407 - val_acc: 0.7448\n",
      "Epoch 204/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4105 - acc: 0.8247 - val_loss: 0.5407 - val_acc: 0.7448\n",
      "Epoch 205/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4104 - acc: 0.8229 - val_loss: 0.5407 - val_acc: 0.7448\n",
      "Epoch 206/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4104 - acc: 0.8229 - val_loss: 0.5408 - val_acc: 0.7448\n",
      "Epoch 207/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4104 - acc: 0.8229 - val_loss: 0.5408 - val_acc: 0.7448\n",
      "Epoch 208/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4104 - acc: 0.8247 - val_loss: 0.5409 - val_acc: 0.7448\n",
      "Epoch 209/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4104 - acc: 0.8247 - val_loss: 0.5409 - val_acc: 0.7448\n",
      "Epoch 210/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4103 - acc: 0.8247 - val_loss: 0.5410 - val_acc: 0.7448\n",
      "Epoch 211/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4103 - acc: 0.8229 - val_loss: 0.5410 - val_acc: 0.7448\n",
      "Epoch 212/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4103 - acc: 0.8212 - val_loss: 0.5411 - val_acc: 0.7448\n",
      "Epoch 213/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4102 - acc: 0.8194 - val_loss: 0.5411 - val_acc: 0.7448\n",
      "Epoch 214/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4102 - acc: 0.8194 - val_loss: 0.5412 - val_acc: 0.7448\n",
      "Epoch 215/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4102 - acc: 0.8194 - val_loss: 0.5412 - val_acc: 0.7448\n",
      "Epoch 216/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4102 - acc: 0.8212 - val_loss: 0.5412 - val_acc: 0.7448\n",
      "Epoch 217/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4102 - acc: 0.8194 - val_loss: 0.5413 - val_acc: 0.7448\n",
      "Epoch 218/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4102 - acc: 0.8212 - val_loss: 0.5413 - val_acc: 0.7448\n",
      "Epoch 219/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4102 - acc: 0.8194 - val_loss: 0.5414 - val_acc: 0.7448\n",
      "Epoch 220/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4101 - acc: 0.8212 - val_loss: 0.5414 - val_acc: 0.7448\n",
      "Epoch 221/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4101 - acc: 0.8194 - val_loss: 0.5414 - val_acc: 0.7448\n",
      "Epoch 222/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4101 - acc: 0.8194 - val_loss: 0.5415 - val_acc: 0.7448\n",
      "Epoch 223/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4101 - acc: 0.8212 - val_loss: 0.5415 - val_acc: 0.7448\n",
      "Epoch 224/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4101 - acc: 0.8212 - val_loss: 0.5416 - val_acc: 0.7448\n",
      "Epoch 225/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4100 - acc: 0.8212 - val_loss: 0.5416 - val_acc: 0.7448\n",
      "Epoch 226/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4100 - acc: 0.8212 - val_loss: 0.5416 - val_acc: 0.7448\n",
      "Epoch 227/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4100 - acc: 0.8194 - val_loss: 0.5417 - val_acc: 0.7448\n",
      "Epoch 228/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4099 - acc: 0.8212 - val_loss: 0.5417 - val_acc: 0.7448\n",
      "Epoch 229/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4100 - acc: 0.8212 - val_loss: 0.5418 - val_acc: 0.7448\n",
      "Epoch 230/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4099 - acc: 0.8194 - val_loss: 0.5418 - val_acc: 0.7448\n",
      "Epoch 231/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4099 - acc: 0.8212 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 232/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4098 - acc: 0.8212 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 233/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4098 - acc: 0.8229 - val_loss: 0.5419 - val_acc: 0.7448\n",
      "Epoch 234/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4098 - acc: 0.8212 - val_loss: 0.5420 - val_acc: 0.7448\n",
      "Epoch 235/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4098 - acc: 0.8229 - val_loss: 0.5420 - val_acc: 0.7448\n",
      "Epoch 236/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4097 - acc: 0.8212 - val_loss: 0.5421 - val_acc: 0.7448\n",
      "Epoch 237/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4097 - acc: 0.8229 - val_loss: 0.5421 - val_acc: 0.7448\n",
      "Epoch 238/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4097 - acc: 0.8212 - val_loss: 0.5422 - val_acc: 0.7448\n",
      "Epoch 239/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4097 - acc: 0.8212 - val_loss: 0.5422 - val_acc: 0.7448\n",
      "Epoch 240/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4097 - acc: 0.8229 - val_loss: 0.5422 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4096 - acc: 0.8212 - val_loss: 0.5423 - val_acc: 0.7448\n",
      "Epoch 242/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4097 - acc: 0.8229 - val_loss: 0.5423 - val_acc: 0.7448\n",
      "Epoch 243/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4096 - acc: 0.8229 - val_loss: 0.5424 - val_acc: 0.7448\n",
      "Epoch 244/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4097 - acc: 0.8212 - val_loss: 0.5424 - val_acc: 0.7448\n",
      "Epoch 245/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4096 - acc: 0.8229 - val_loss: 0.5424 - val_acc: 0.7448\n",
      "Epoch 246/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4095 - acc: 0.8212 - val_loss: 0.5425 - val_acc: 0.7448\n",
      "Epoch 247/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4096 - acc: 0.8212 - val_loss: 0.5425 - val_acc: 0.7448\n",
      "Epoch 248/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4096 - acc: 0.8229 - val_loss: 0.5426 - val_acc: 0.7448\n",
      "Epoch 249/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4095 - acc: 0.8229 - val_loss: 0.5426 - val_acc: 0.7448\n",
      "Epoch 250/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4095 - acc: 0.8229 - val_loss: 0.5427 - val_acc: 0.7396\n",
      "Epoch 251/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4095 - acc: 0.8212 - val_loss: 0.5427 - val_acc: 0.7396\n",
      "Epoch 252/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4095 - acc: 0.8212 - val_loss: 0.5427 - val_acc: 0.7396\n",
      "Epoch 253/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4094 - acc: 0.8212 - val_loss: 0.5428 - val_acc: 0.7396\n",
      "Epoch 254/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4094 - acc: 0.8212 - val_loss: 0.5428 - val_acc: 0.7396\n",
      "Epoch 255/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4094 - acc: 0.8229 - val_loss: 0.5428 - val_acc: 0.7396\n",
      "Epoch 256/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4094 - acc: 0.8212 - val_loss: 0.5429 - val_acc: 0.7396\n",
      "Epoch 257/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4093 - acc: 0.8212 - val_loss: 0.5429 - val_acc: 0.7448\n",
      "Epoch 258/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4093 - acc: 0.8212 - val_loss: 0.5429 - val_acc: 0.7396\n",
      "Epoch 259/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4093 - acc: 0.8229 - val_loss: 0.5430 - val_acc: 0.7396\n",
      "Epoch 260/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4093 - acc: 0.8229 - val_loss: 0.5430 - val_acc: 0.7396\n",
      "Epoch 261/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4092 - acc: 0.8229 - val_loss: 0.5430 - val_acc: 0.7396\n",
      "Epoch 262/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4093 - acc: 0.8229 - val_loss: 0.5431 - val_acc: 0.7396\n",
      "Epoch 263/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4092 - acc: 0.8229 - val_loss: 0.5431 - val_acc: 0.7396\n",
      "Epoch 264/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4092 - acc: 0.8229 - val_loss: 0.5431 - val_acc: 0.7396\n",
      "Epoch 265/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4092 - acc: 0.8212 - val_loss: 0.5432 - val_acc: 0.7396\n",
      "Epoch 266/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4092 - acc: 0.8229 - val_loss: 0.5432 - val_acc: 0.7396\n",
      "Epoch 267/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4091 - acc: 0.8212 - val_loss: 0.5432 - val_acc: 0.7396\n",
      "Epoch 268/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4091 - acc: 0.8229 - val_loss: 0.5433 - val_acc: 0.7396\n",
      "Epoch 269/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4091 - acc: 0.8212 - val_loss: 0.5433 - val_acc: 0.7396\n",
      "Epoch 270/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4091 - acc: 0.8229 - val_loss: 0.5433 - val_acc: 0.7396\n",
      "Epoch 271/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4091 - acc: 0.8229 - val_loss: 0.5434 - val_acc: 0.7396\n",
      "Epoch 272/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4091 - acc: 0.8212 - val_loss: 0.5434 - val_acc: 0.7396\n",
      "Epoch 273/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4091 - acc: 0.8229 - val_loss: 0.5434 - val_acc: 0.7396\n",
      "Epoch 274/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4090 - acc: 0.8212 - val_loss: 0.5434 - val_acc: 0.7396\n",
      "Epoch 275/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4090 - acc: 0.8229 - val_loss: 0.5435 - val_acc: 0.7396\n",
      "Epoch 276/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4090 - acc: 0.8229 - val_loss: 0.5435 - val_acc: 0.7396\n",
      "Epoch 277/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4089 - acc: 0.8229 - val_loss: 0.5435 - val_acc: 0.7396\n",
      "Epoch 278/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4090 - acc: 0.8229 - val_loss: 0.5436 - val_acc: 0.7396\n",
      "Epoch 279/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4089 - acc: 0.8229 - val_loss: 0.5436 - val_acc: 0.7396\n",
      "Epoch 280/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4089 - acc: 0.8229 - val_loss: 0.5436 - val_acc: 0.7396\n",
      "Epoch 281/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4089 - acc: 0.8229 - val_loss: 0.5436 - val_acc: 0.7396\n",
      "Epoch 282/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4089 - acc: 0.8229 - val_loss: 0.5436 - val_acc: 0.7396\n",
      "Epoch 283/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4089 - acc: 0.8229 - val_loss: 0.5437 - val_acc: 0.7396\n",
      "Epoch 284/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4088 - acc: 0.8229 - val_loss: 0.5437 - val_acc: 0.7396\n",
      "Epoch 285/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4088 - acc: 0.8229 - val_loss: 0.5437 - val_acc: 0.7396\n",
      "Epoch 286/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4088 - acc: 0.8229 - val_loss: 0.5437 - val_acc: 0.7396\n",
      "Epoch 287/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4088 - acc: 0.8229 - val_loss: 0.5438 - val_acc: 0.7396\n",
      "Epoch 288/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4088 - acc: 0.8229 - val_loss: 0.5438 - val_acc: 0.7396\n",
      "Epoch 289/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8229 - val_loss: 0.5438 - val_acc: 0.7396\n",
      "Epoch 290/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4087 - acc: 0.8229 - val_loss: 0.5438 - val_acc: 0.7396\n",
      "Epoch 291/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4087 - acc: 0.8229 - val_loss: 0.5439 - val_acc: 0.7396\n",
      "Epoch 292/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4087 - acc: 0.8229 - val_loss: 0.5439 - val_acc: 0.7396\n",
      "Epoch 293/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4087 - acc: 0.8229 - val_loss: 0.5439 - val_acc: 0.7396\n",
      "Epoch 294/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4087 - acc: 0.8229 - val_loss: 0.5439 - val_acc: 0.7396\n",
      "Epoch 295/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4086 - acc: 0.8229 - val_loss: 0.5440 - val_acc: 0.7396\n",
      "Epoch 296/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4086 - acc: 0.8229 - val_loss: 0.5439 - val_acc: 0.7396\n",
      "Epoch 297/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4086 - acc: 0.8229 - val_loss: 0.5440 - val_acc: 0.7396\n",
      "Epoch 298/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4086 - acc: 0.8229 - val_loss: 0.5440 - val_acc: 0.7396\n",
      "Epoch 299/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4086 - acc: 0.8229 - val_loss: 0.5440 - val_acc: 0.7396\n",
      "Epoch 300/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5441 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5441 - val_acc: 0.7396\n",
      "Epoch 302/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5441 - val_acc: 0.7396\n",
      "Epoch 303/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5441 - val_acc: 0.7396\n",
      "Epoch 304/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5441 - val_acc: 0.7396\n",
      "Epoch 305/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5442 - val_acc: 0.7396\n",
      "Epoch 306/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4085 - acc: 0.8229 - val_loss: 0.5442 - val_acc: 0.7396\n",
      "Epoch 307/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4084 - acc: 0.8229 - val_loss: 0.5442 - val_acc: 0.7396\n",
      "Epoch 308/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4084 - acc: 0.8229 - val_loss: 0.5442 - val_acc: 0.7396\n",
      "Epoch 309/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4084 - acc: 0.8229 - val_loss: 0.5442 - val_acc: 0.7396\n",
      "Epoch 310/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4084 - acc: 0.8229 - val_loss: 0.5443 - val_acc: 0.7396\n",
      "Epoch 311/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4084 - acc: 0.8229 - val_loss: 0.5443 - val_acc: 0.7396\n",
      "Epoch 312/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4083 - acc: 0.8229 - val_loss: 0.5443 - val_acc: 0.7396\n",
      "Epoch 313/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4083 - acc: 0.8229 - val_loss: 0.5444 - val_acc: 0.7396\n",
      "Epoch 314/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4083 - acc: 0.8229 - val_loss: 0.5444 - val_acc: 0.7396\n",
      "Epoch 315/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4083 - acc: 0.8247 - val_loss: 0.5444 - val_acc: 0.7396\n",
      "Epoch 316/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4083 - acc: 0.8229 - val_loss: 0.5444 - val_acc: 0.7396\n",
      "Epoch 317/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4083 - acc: 0.8229 - val_loss: 0.5444 - val_acc: 0.7396\n",
      "Epoch 318/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5445 - val_acc: 0.7396\n",
      "Epoch 319/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4083 - acc: 0.8229 - val_loss: 0.5445 - val_acc: 0.7396\n",
      "Epoch 320/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5445 - val_acc: 0.7396\n",
      "Epoch 321/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5445 - val_acc: 0.7396\n",
      "Epoch 322/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5446 - val_acc: 0.7396\n",
      "Epoch 323/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5446 - val_acc: 0.7396\n",
      "Epoch 324/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5446 - val_acc: 0.7396\n",
      "Epoch 325/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5446 - val_acc: 0.7448\n",
      "Epoch 326/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4082 - acc: 0.8229 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 327/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 328/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 329/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 330/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5447 - val_acc: 0.7448\n",
      "Epoch 331/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5448 - val_acc: 0.7448\n",
      "Epoch 332/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5448 - val_acc: 0.7448\n",
      "Epoch 333/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4080 - acc: 0.8247 - val_loss: 0.5448 - val_acc: 0.7448\n",
      "Epoch 334/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 335/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4081 - acc: 0.8229 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 336/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4080 - acc: 0.8229 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 337/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4080 - acc: 0.8229 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 338/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4080 - acc: 0.8229 - val_loss: 0.5449 - val_acc: 0.7448\n",
      "Epoch 339/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4080 - acc: 0.8229 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 340/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4080 - acc: 0.8247 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 341/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4080 - acc: 0.8229 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 342/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4079 - acc: 0.8229 - val_loss: 0.5450 - val_acc: 0.7448\n",
      "Epoch 343/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4079 - acc: 0.8247 - val_loss: 0.5451 - val_acc: 0.7448\n",
      "Epoch 344/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4079 - acc: 0.8229 - val_loss: 0.5451 - val_acc: 0.7448\n",
      "Epoch 345/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4079 - acc: 0.8247 - val_loss: 0.5451 - val_acc: 0.7448\n",
      "Epoch 346/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4079 - acc: 0.8229 - val_loss: 0.5451 - val_acc: 0.7448\n",
      "Epoch 347/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4079 - acc: 0.8247 - val_loss: 0.5451 - val_acc: 0.7448\n",
      "Epoch 348/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4079 - acc: 0.8229 - val_loss: 0.5452 - val_acc: 0.7448\n",
      "Epoch 349/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4078 - acc: 0.8247 - val_loss: 0.5452 - val_acc: 0.7448\n",
      "Epoch 350/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4078 - acc: 0.8229 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 351/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4078 - acc: 0.8247 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 352/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4079 - acc: 0.8247 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 353/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4078 - acc: 0.8229 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 354/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4078 - acc: 0.8247 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 355/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4078 - acc: 0.8247 - val_loss: 0.5452 - val_acc: 0.7500\n",
      "Epoch 356/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4078 - acc: 0.8247 - val_loss: 0.5453 - val_acc: 0.7500\n",
      "Epoch 357/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4077 - acc: 0.8247 - val_loss: 0.5453 - val_acc: 0.7500\n",
      "Epoch 358/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4077 - acc: 0.8247 - val_loss: 0.5453 - val_acc: 0.7500\n",
      "Epoch 359/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4077 - acc: 0.8247 - val_loss: 0.5453 - val_acc: 0.7500\n",
      "Epoch 360/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4077 - acc: 0.8264 - val_loss: 0.5453 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4077 - acc: 0.8264 - val_loss: 0.5454 - val_acc: 0.7500\n",
      "Epoch 362/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4077 - acc: 0.8247 - val_loss: 0.5454 - val_acc: 0.7500\n",
      "Epoch 363/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4076 - acc: 0.8264 - val_loss: 0.5454 - val_acc: 0.7500\n",
      "Epoch 364/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4076 - acc: 0.8264 - val_loss: 0.5454 - val_acc: 0.7500\n",
      "Epoch 365/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4076 - acc: 0.8247 - val_loss: 0.5455 - val_acc: 0.7500\n",
      "Epoch 366/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4076 - acc: 0.8264 - val_loss: 0.5455 - val_acc: 0.7500\n",
      "Epoch 367/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4076 - acc: 0.8247 - val_loss: 0.5455 - val_acc: 0.7500\n",
      "Epoch 368/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4077 - acc: 0.8264 - val_loss: 0.5455 - val_acc: 0.7500\n",
      "Epoch 369/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4076 - acc: 0.8247 - val_loss: 0.5456 - val_acc: 0.7500\n",
      "Epoch 370/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5456 - val_acc: 0.7500\n",
      "Epoch 371/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5456 - val_acc: 0.7500\n",
      "Epoch 372/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5456 - val_acc: 0.7500\n",
      "Epoch 373/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5456 - val_acc: 0.7500\n",
      "Epoch 374/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5457 - val_acc: 0.7500\n",
      "Epoch 375/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5457 - val_acc: 0.7500\n",
      "Epoch 376/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5457 - val_acc: 0.7500\n",
      "Epoch 377/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4075 - acc: 0.8264 - val_loss: 0.5458 - val_acc: 0.7500\n",
      "Epoch 378/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5458 - val_acc: 0.7500\n",
      "Epoch 379/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5458 - val_acc: 0.7500\n",
      "Epoch 380/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5458 - val_acc: 0.7500\n",
      "Epoch 381/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5458 - val_acc: 0.7500\n",
      "Epoch 382/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5459 - val_acc: 0.7500\n",
      "Epoch 383/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4074 - acc: 0.8264 - val_loss: 0.5459 - val_acc: 0.7500\n",
      "Epoch 384/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4073 - acc: 0.8264 - val_loss: 0.5459 - val_acc: 0.7500\n",
      "Epoch 385/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4073 - acc: 0.8264 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 386/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4073 - acc: 0.8264 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 387/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4073 - acc: 0.8264 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 388/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 389/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5460 - val_acc: 0.7500\n",
      "Epoch 390/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 391/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 392/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 393/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 394/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 395/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4072 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 396/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 397/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 398/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 399/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 400/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5461 - val_acc: 0.7500\n",
      "Epoch 401/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4070 - acc: 0.8247 - val_loss: 0.5462 - val_acc: 0.7500\n",
      "Epoch 402/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4070 - acc: 0.8264 - val_loss: 0.5462 - val_acc: 0.7500\n",
      "Epoch 403/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4071 - acc: 0.8264 - val_loss: 0.5462 - val_acc: 0.7500\n",
      "Epoch 404/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4070 - acc: 0.8264 - val_loss: 0.5462 - val_acc: 0.7500\n",
      "Epoch 405/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4070 - acc: 0.8264 - val_loss: 0.5462 - val_acc: 0.7500\n",
      "Epoch 406/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4070 - acc: 0.8264 - val_loss: 0.5462 - val_acc: 0.7500\n",
      "Epoch 407/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4069 - acc: 0.8264 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 408/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4070 - acc: 0.8264 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 409/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4069 - acc: 0.8264 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 410/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4069 - acc: 0.8264 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 411/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4069 - acc: 0.8247 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 412/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4069 - acc: 0.8247 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 413/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4069 - acc: 0.8247 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 414/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4069 - acc: 0.8247 - val_loss: 0.5463 - val_acc: 0.7500\n",
      "Epoch 415/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4068 - acc: 0.8264 - val_loss: 0.5464 - val_acc: 0.7500\n",
      "Epoch 416/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4068 - acc: 0.8247 - val_loss: 0.5464 - val_acc: 0.7500\n",
      "Epoch 417/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4068 - acc: 0.8247 - val_loss: 0.5464 - val_acc: 0.7500\n",
      "Epoch 418/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4068 - acc: 0.8247 - val_loss: 0.5464 - val_acc: 0.7500\n",
      "Epoch 419/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4068 - acc: 0.8247 - val_loss: 0.5465 - val_acc: 0.7500\n",
      "Epoch 420/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4068 - acc: 0.8264 - val_loss: 0.5465 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4067 - acc: 0.8247 - val_loss: 0.5465 - val_acc: 0.7500\n",
      "Epoch 422/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4067 - acc: 0.8247 - val_loss: 0.5465 - val_acc: 0.7500\n",
      "Epoch 423/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4067 - acc: 0.8247 - val_loss: 0.5465 - val_acc: 0.7500\n",
      "Epoch 424/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4067 - acc: 0.8247 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 425/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4067 - acc: 0.8247 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 426/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4066 - acc: 0.8247 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 427/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4067 - acc: 0.8229 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 428/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4067 - acc: 0.8247 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 429/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4066 - acc: 0.8247 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 430/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4066 - acc: 0.8229 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 431/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4066 - acc: 0.8229 - val_loss: 0.5466 - val_acc: 0.7500\n",
      "Epoch 432/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4066 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 433/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 434/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 435/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 436/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 437/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 438/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 439/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4065 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 440/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4064 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 441/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4064 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 442/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 443/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4064 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 444/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 445/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 446/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4064 - acc: 0.8229 - val_loss: 0.5467 - val_acc: 0.7500\n",
      "Epoch 447/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 448/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 449/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 450/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4062 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 451/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4063 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 452/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4062 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 453/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4062 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 454/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4062 - acc: 0.8229 - val_loss: 0.5468 - val_acc: 0.7500\n",
      "Epoch 455/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4062 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 456/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4061 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 457/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4061 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 458/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 459/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4061 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 460/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4061 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 461/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 462/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 463/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5469 - val_acc: 0.7500\n",
      "Epoch 464/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5370 - acc: 0.750 - 0s 37us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 465/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 466/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 467/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4060 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 468/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 469/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 470/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4059 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 471/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4059 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 472/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4058 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 473/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4058 - acc: 0.8212 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 474/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4058 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 475/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4057 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 476/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4057 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 477/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4057 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 478/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4057 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 479/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4056 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 480/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4056 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 481/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4055 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 482/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4056 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 483/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4056 - acc: 0.8229 - val_loss: 0.5470 - val_acc: 0.7448\n",
      "Epoch 484/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4055 - acc: 0.8229 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 485/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4055 - acc: 0.8229 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 486/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4055 - acc: 0.8229 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 487/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4054 - acc: 0.8212 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 488/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4055 - acc: 0.8212 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 489/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4054 - acc: 0.8194 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 490/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4054 - acc: 0.8194 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 491/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4054 - acc: 0.8212 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 492/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4054 - acc: 0.8194 - val_loss: 0.5471 - val_acc: 0.7448\n",
      "Epoch 493/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4053 - acc: 0.8212 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 494/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4053 - acc: 0.8194 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 495/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4053 - acc: 0.8194 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 496/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4052 - acc: 0.8194 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 497/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4052 - acc: 0.8194 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 498/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4052 - acc: 0.8194 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 499/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4052 - acc: 0.8194 - val_loss: 0.5472 - val_acc: 0.7448\n",
      "Epoch 500/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4052 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 501/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 502/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 503/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 504/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 505/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 506/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5473 - val_acc: 0.7448\n",
      "Epoch 507/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4051 - acc: 0.8194 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 508/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4050 - acc: 0.8194 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 509/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4050 - acc: 0.8194 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 510/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - acc: 0.8194 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 511/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - acc: 0.8177 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 512/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4050 - acc: 0.8194 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 513/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4050 - acc: 0.8177 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 514/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4050 - acc: 0.8177 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 515/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4049 - acc: 0.8194 - val_loss: 0.5474 - val_acc: 0.7448\n",
      "Epoch 516/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4049 - acc: 0.8194 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 517/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4049 - acc: 0.8194 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 518/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4048 - acc: 0.8194 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 519/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4049 - acc: 0.8177 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 520/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4048 - acc: 0.8194 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 521/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4048 - acc: 0.8177 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 522/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4048 - acc: 0.8194 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 523/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4048 - acc: 0.8177 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 524/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4048 - acc: 0.8194 - val_loss: 0.5475 - val_acc: 0.7448\n",
      "Epoch 525/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4048 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 526/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 527/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 528/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 529/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 530/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 531/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 532/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 533/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 534/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4046 - acc: 0.8177 - val_loss: 0.5476 - val_acc: 0.7448\n",
      "Epoch 535/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 536/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4047 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 537/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4046 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 538/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4046 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 539/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4046 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4046 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 541/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4046 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 542/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 543/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 544/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5477 - val_acc: 0.7448\n",
      "Epoch 545/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 546/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 547/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 548/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 549/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4045 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 550/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 551/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 552/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 553/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 554/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 555/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4044 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 556/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 557/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 558/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 559/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 560/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5478 - val_acc: 0.7448\n",
      "Epoch 561/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4042 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 562/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 563/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 564/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 565/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4042 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 566/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4042 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 567/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4043 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 568/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4042 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 569/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 570/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 571/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 572/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 573/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 574/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5479 - val_acc: 0.7448\n",
      "Epoch 575/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 576/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7448\n",
      "Epoch 577/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4041 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 578/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 579/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 580/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 581/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 582/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 583/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 584/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4040 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 585/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5480 - val_acc: 0.7500\n",
      "Epoch 586/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 587/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 588/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 589/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 590/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 591/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4038 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 592/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4039 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 593/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4038 - acc: 0.8177 - val_loss: 0.5481 - val_acc: 0.7500\n",
      "Epoch 594/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4038 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 595/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4038 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 596/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 597/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4038 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 598/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 599/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4038 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 601/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5482 - val_acc: 0.7500\n",
      "Epoch 602/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 603/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 604/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 605/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 606/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 607/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4037 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 608/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4036 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 609/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4036 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 610/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4036 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 611/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4036 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 612/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 613/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4036 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 614/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4036 - acc: 0.8177 - val_loss: 0.5483 - val_acc: 0.7500\n",
      "Epoch 615/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 616/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 617/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 618/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 619/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 620/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.4034 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 621/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4034 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 622/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4035 - acc: 0.8177 - val_loss: 0.5484 - val_acc: 0.7500\n",
      "Epoch 623/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4034 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 624/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4034 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 625/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 626/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 627/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4034 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 628/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 629/3000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 630/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 631/3000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5485 - val_acc: 0.7500\n",
      "Epoch 632/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 633/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 634/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 635/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 636/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 637/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4033 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 638/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4033 - acc: 0.8160 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 639/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 640/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 641/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5486 - val_acc: 0.7500\n",
      "Epoch 642/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5487 - val_acc: 0.7500\n",
      "Epoch 643/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4032 - acc: 0.8177 - val_loss: 0.5487 - val_acc: 0.7500\n",
      "Epoch 644/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5487 - val_acc: 0.7500\n",
      "Epoch 645/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5487 - val_acc: 0.7500\n",
      "Epoch 646/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5487 - val_acc: 0.7500\n",
      "Epoch 647/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5488 - val_acc: 0.7500\n",
      "Epoch 648/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5487 - val_acc: 0.7500\n",
      "Epoch 649/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5488 - val_acc: 0.7500\n",
      "Epoch 650/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4030 - acc: 0.8177 - val_loss: 0.5488 - val_acc: 0.7552\n",
      "Epoch 651/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4031 - acc: 0.8177 - val_loss: 0.5488 - val_acc: 0.7552\n",
      "Epoch 652/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4030 - acc: 0.8177 - val_loss: 0.5488 - val_acc: 0.7552\n",
      "Epoch 653/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4030 - acc: 0.8160 - val_loss: 0.5488 - val_acc: 0.7552\n",
      "Epoch 654/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4030 - acc: 0.8177 - val_loss: 0.5489 - val_acc: 0.7552\n",
      "Epoch 655/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4030 - acc: 0.8177 - val_loss: 0.5489 - val_acc: 0.7552\n",
      "Epoch 656/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4030 - acc: 0.8177 - val_loss: 0.5489 - val_acc: 0.7552\n",
      "Epoch 657/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4030 - acc: 0.8177 - val_loss: 0.5489 - val_acc: 0.7552\n",
      "Epoch 658/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4029 - acc: 0.8177 - val_loss: 0.5489 - val_acc: 0.7552\n",
      "Epoch 659/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4029 - acc: 0.8160 - val_loss: 0.5489 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4029 - acc: 0.8194 - val_loss: 0.5489 - val_acc: 0.7552\n",
      "Epoch 661/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4029 - acc: 0.8194 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 662/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4029 - acc: 0.8177 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 663/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4029 - acc: 0.8194 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 664/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4029 - acc: 0.8194 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 665/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4029 - acc: 0.8194 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 666/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4028 - acc: 0.8194 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 667/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4028 - acc: 0.8177 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 668/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4028 - acc: 0.8194 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 669/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4028 - acc: 0.8160 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 670/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4028 - acc: 0.8177 - val_loss: 0.5490 - val_acc: 0.7552\n",
      "Epoch 671/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4028 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 672/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4028 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 673/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4027 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 674/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4028 - acc: 0.8177 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 675/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4027 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 676/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4028 - acc: 0.8177 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 677/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4027 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 678/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4027 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 679/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4027 - acc: 0.8194 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 680/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5491 - val_acc: 0.7552\n",
      "Epoch 681/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4026 - acc: 0.8194 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 682/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4026 - acc: 0.8194 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 683/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4026 - acc: 0.8194 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 684/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 685/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 686/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 687/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 688/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 689/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4026 - acc: 0.8177 - val_loss: 0.5492 - val_acc: 0.7604\n",
      "Epoch 690/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4026 - acc: 0.8142 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 691/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4025 - acc: 0.8160 - val_loss: 0.5492 - val_acc: 0.7552\n",
      "Epoch 692/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4025 - acc: 0.8160 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 693/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4025 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 694/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4025 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 695/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4025 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 696/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4024 - acc: 0.8160 - val_loss: 0.5493 - val_acc: 0.7604\n",
      "Epoch 697/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4025 - acc: 0.8160 - val_loss: 0.5493 - val_acc: 0.7552\n",
      "Epoch 698/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4024 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7604\n",
      "Epoch 699/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4024 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7604\n",
      "Epoch 700/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4024 - acc: 0.8177 - val_loss: 0.5493 - val_acc: 0.7604\n",
      "Epoch 701/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4024 - acc: 0.8194 - val_loss: 0.5493 - val_acc: 0.7604\n",
      "Epoch 702/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4024 - acc: 0.8177 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 703/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4024 - acc: 0.8194 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 704/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4024 - acc: 0.8177 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 705/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4023 - acc: 0.8177 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 706/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4023 - acc: 0.8160 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 707/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4023 - acc: 0.8177 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 708/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4023 - acc: 0.8160 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 709/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4023 - acc: 0.8194 - val_loss: 0.5494 - val_acc: 0.7604\n",
      "Epoch 710/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4022 - acc: 0.8160 - val_loss: 0.5494 - val_acc: 0.7656\n",
      "Epoch 711/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4022 - acc: 0.8177 - val_loss: 0.5494 - val_acc: 0.7656\n",
      "Epoch 712/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4022 - acc: 0.8160 - val_loss: 0.5494 - val_acc: 0.7656\n",
      "Epoch 713/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - acc: 0.8177 - val_loss: 0.5494 - val_acc: 0.7656\n",
      "Epoch 714/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4022 - acc: 0.8160 - val_loss: 0.5494 - val_acc: 0.7656\n",
      "Epoch 715/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4022 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 716/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 717/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 718/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 719/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 721/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4021 - acc: 0.8160 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 722/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5495 - val_acc: 0.7656\n",
      "Epoch 723/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4021 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 724/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4021 - acc: 0.8194 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 725/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4020 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 726/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4020 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 727/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4020 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 728/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4020 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 729/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4020 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 730/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4020 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 731/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4019 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 732/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.4019 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 733/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4019 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 734/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4019 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 735/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4019 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 736/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.4018 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 737/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4018 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 738/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 739/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - acc: 0.8160 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 740/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4018 - acc: 0.8160 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 741/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4018 - acc: 0.8177 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 742/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4018 - acc: 0.8160 - val_loss: 0.5496 - val_acc: 0.7656\n",
      "Epoch 743/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4017 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 744/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4017 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 745/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4017 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 746/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4017 - acc: 0.8160 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 747/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4017 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 748/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4016 - acc: 0.8160 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 749/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4017 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 750/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4016 - acc: 0.8160 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 751/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4016 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 752/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4016 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 753/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4016 - acc: 0.8177 - val_loss: 0.5497 - val_acc: 0.7656\n",
      "Epoch 754/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4015 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 755/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4016 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 756/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 757/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4016 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 758/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4015 - acc: 0.8177 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 759/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4015 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 760/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4014 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 761/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4015 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7656\n",
      "Epoch 762/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4015 - acc: 0.8160 - val_loss: 0.5498 - val_acc: 0.7708\n",
      "Epoch 763/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4014 - acc: 0.8142 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 764/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4015 - acc: 0.8160 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 765/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.4014 - acc: 0.8160 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 766/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4014 - acc: 0.8160 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 767/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.4014 - acc: 0.8160 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 768/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4014 - acc: 0.8160 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 769/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4013 - acc: 0.8142 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 770/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4013 - acc: 0.8160 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 771/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4014 - acc: 0.8142 - val_loss: 0.5499 - val_acc: 0.7708\n",
      "Epoch 772/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4013 - acc: 0.8125 - val_loss: 0.5500 - val_acc: 0.7708\n",
      "Epoch 773/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4013 - acc: 0.8160 - val_loss: 0.5500 - val_acc: 0.7708\n",
      "Epoch 774/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4012 - acc: 0.8160 - val_loss: 0.5500 - val_acc: 0.7708\n",
      "Epoch 775/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4012 - acc: 0.8125 - val_loss: 0.5500 - val_acc: 0.7708\n",
      "Epoch 776/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4013 - acc: 0.8125 - val_loss: 0.5501 - val_acc: 0.7708\n",
      "Epoch 777/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4012 - acc: 0.8160 - val_loss: 0.5501 - val_acc: 0.7708\n",
      "Epoch 778/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4012 - acc: 0.8160 - val_loss: 0.5501 - val_acc: 0.7708\n",
      "Epoch 779/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4012 - acc: 0.8125 - val_loss: 0.5501 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.4012 - acc: 0.8125 - val_loss: 0.5501 - val_acc: 0.7708\n",
      "Epoch 781/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4011 - acc: 0.8142 - val_loss: 0.5501 - val_acc: 0.7708\n",
      "Epoch 782/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4012 - acc: 0.8142 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 783/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4012 - acc: 0.8142 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 784/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4011 - acc: 0.8125 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 785/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4011 - acc: 0.8142 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 786/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4011 - acc: 0.8142 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 787/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4010 - acc: 0.8142 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 788/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4011 - acc: 0.8142 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 789/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4010 - acc: 0.8160 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 790/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4010 - acc: 0.8160 - val_loss: 0.5502 - val_acc: 0.7708\n",
      "Epoch 791/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.4010 - acc: 0.8142 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 792/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4010 - acc: 0.8125 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 793/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4009 - acc: 0.8125 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 794/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4010 - acc: 0.8160 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 795/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4009 - acc: 0.8142 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 796/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4009 - acc: 0.8142 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 797/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4010 - acc: 0.8142 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 798/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4009 - acc: 0.8142 - val_loss: 0.5503 - val_acc: 0.7708\n",
      "Epoch 799/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4009 - acc: 0.8125 - val_loss: 0.5504 - val_acc: 0.7708\n",
      "Epoch 800/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4009 - acc: 0.8142 - val_loss: 0.5504 - val_acc: 0.7708\n",
      "Epoch 801/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4008 - acc: 0.8142 - val_loss: 0.5504 - val_acc: 0.7708\n",
      "Epoch 802/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4008 - acc: 0.8142 - val_loss: 0.5504 - val_acc: 0.7708\n",
      "Epoch 803/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4008 - acc: 0.8142 - val_loss: 0.5504 - val_acc: 0.7708\n",
      "Epoch 804/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4008 - acc: 0.8142 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 805/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4008 - acc: 0.8160 - val_loss: 0.5504 - val_acc: 0.7708\n",
      "Epoch 806/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 807/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4007 - acc: 0.8125 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 808/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 809/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 810/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 811/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4007 - acc: 0.8125 - val_loss: 0.5505 - val_acc: 0.7708\n",
      "Epoch 812/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5506 - val_acc: 0.7708\n",
      "Epoch 813/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5506 - val_acc: 0.7708\n",
      "Epoch 814/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4007 - acc: 0.8142 - val_loss: 0.5506 - val_acc: 0.7708\n",
      "Epoch 815/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4006 - acc: 0.8142 - val_loss: 0.5506 - val_acc: 0.7708\n",
      "Epoch 816/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4006 - acc: 0.8142 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 817/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - acc: 0.8142 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 818/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4006 - acc: 0.8142 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 819/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.4006 - acc: 0.8142 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 820/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4006 - acc: 0.8142 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 821/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4006 - acc: 0.8142 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 822/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4005 - acc: 0.8125 - val_loss: 0.5507 - val_acc: 0.7708\n",
      "Epoch 823/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4005 - acc: 0.8142 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 824/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4005 - acc: 0.8142 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 825/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4005 - acc: 0.8125 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 826/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4004 - acc: 0.8125 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 827/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - acc: 0.8125 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 828/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4005 - acc: 0.8142 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 829/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5508 - val_acc: 0.7708\n",
      "Epoch 830/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 831/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 832/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 833/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 834/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4004 - acc: 0.8125 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 835/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 836/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4004 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 837/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5509 - val_acc: 0.7708\n",
      "Epoch 838/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n",
      "Epoch 839/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n",
      "Epoch 841/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n",
      "Epoch 842/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - acc: 0.8125 - val_loss: 0.5511 - val_acc: 0.7708\n",
      "Epoch 843/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n",
      "Epoch 844/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n",
      "Epoch 845/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5510 - val_acc: 0.7708\n",
      "Epoch 846/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - acc: 0.8125 - val_loss: 0.5511 - val_acc: 0.7708\n",
      "Epoch 847/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4003 - acc: 0.8142 - val_loss: 0.5511 - val_acc: 0.7708\n",
      "Epoch 848/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5511 - val_acc: 0.7708\n",
      "Epoch 849/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5511 - val_acc: 0.7708\n",
      "Epoch 850/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5511 - val_acc: 0.7708\n",
      "Epoch 851/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 852/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 853/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 854/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 855/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 856/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.4002 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 857/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.4001 - acc: 0.8125 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 858/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4001 - acc: 0.8125 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 859/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5512 - val_acc: 0.7708\n",
      "Epoch 860/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 861/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 862/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4001 - acc: 0.8125 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 863/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4001 - acc: 0.8125 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 864/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - acc: 0.8142 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 865/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 866/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4000 - acc: 0.8142 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 867/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4000 - acc: 0.8142 - val_loss: 0.5513 - val_acc: 0.7708\n",
      "Epoch 868/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4001 - acc: 0.8142 - val_loss: 0.5514 - val_acc: 0.7708\n",
      "Epoch 869/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4000 - acc: 0.8142 - val_loss: 0.5514 - val_acc: 0.7708\n",
      "Epoch 870/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.4000 - acc: 0.8125 - val_loss: 0.5514 - val_acc: 0.7708\n",
      "Epoch 871/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.4000 - acc: 0.8125 - val_loss: 0.5514 - val_acc: 0.7708\n",
      "Epoch 872/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5514 - val_acc: 0.7708\n",
      "Epoch 873/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4000 - acc: 0.8142 - val_loss: 0.5514 - val_acc: 0.7708\n",
      "Epoch 874/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.4000 - acc: 0.8142 - val_loss: 0.5515 - val_acc: 0.7708\n",
      "Epoch 875/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4000 - acc: 0.8125 - val_loss: 0.5515 - val_acc: 0.7708\n",
      "Epoch 876/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5515 - val_acc: 0.7708\n",
      "Epoch 877/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5515 - val_acc: 0.7708\n",
      "Epoch 878/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5515 - val_acc: 0.7708\n",
      "Epoch 879/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 880/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3999 - acc: 0.8125 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 881/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3999 - acc: 0.8125 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 882/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4000 - acc: 0.8108 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 883/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3999 - acc: 0.8160 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 884/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 885/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 886/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3999 - acc: 0.8108 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 887/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3998 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 888/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 889/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 890/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 891/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3998 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 892/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 893/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3998 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 894/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3999 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 895/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3997 - acc: 0.8142 - val_loss: 0.5516 - val_acc: 0.7708\n",
      "Epoch 896/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3998 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 897/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 898/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3998 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 899/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3998 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3997 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 901/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3997 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 902/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3997 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 903/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3997 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 904/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3997 - acc: 0.8125 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 905/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3997 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 906/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3997 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 907/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 908/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3996 - acc: 0.8160 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 909/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - acc: 0.8160 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 910/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - acc: 0.8142 - val_loss: 0.5517 - val_acc: 0.7708\n",
      "Epoch 911/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 912/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3996 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 913/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3996 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 914/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3996 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 915/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3996 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 916/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3996 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 917/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3995 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 918/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3996 - acc: 0.8160 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 919/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3996 - acc: 0.8160 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 920/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3996 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 921/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3995 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 922/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3995 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 923/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3995 - acc: 0.8160 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 924/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3995 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 925/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3995 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 926/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3995 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 927/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3995 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 928/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3994 - acc: 0.8160 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 929/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3994 - acc: 0.8160 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 930/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3995 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 931/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3994 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 932/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3994 - acc: 0.8125 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 933/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3994 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 934/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3994 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 935/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3994 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 936/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3994 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 937/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 938/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3994 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 939/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 940/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3994 - acc: 0.8160 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 941/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3993 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 942/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 943/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 944/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 945/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3994 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 946/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 947/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 948/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5518 - val_acc: 0.7708\n",
      "Epoch 949/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3993 - acc: 0.8160 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 950/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3992 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 951/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3993 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 952/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3992 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 953/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3993 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 954/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3992 - acc: 0.8160 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 955/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3992 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 956/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3992 - acc: 0.8160 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 957/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3992 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 958/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3992 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 959/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3992 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3991 - acc: 0.8160 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 961/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3992 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 962/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3991 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 963/3000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.3991 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 964/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3992 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 965/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.3991 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 966/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3991 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 967/3000\n",
      "576/576 [==============================] - 0s 96us/step - loss: 0.3991 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 968/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3991 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 969/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3991 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 970/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3990 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 971/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3990 - acc: 0.8160 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 972/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3990 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 973/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3990 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 974/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3990 - acc: 0.8125 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 975/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3990 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 976/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3990 - acc: 0.8142 - val_loss: 0.5519 - val_acc: 0.7708\n",
      "Epoch 977/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3990 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 978/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3990 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 979/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3990 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 980/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3990 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 981/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3990 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 982/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 983/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 984/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 985/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3989 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 986/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 987/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 988/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3989 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 989/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3989 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 990/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 991/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3988 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 992/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3988 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 993/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3988 - acc: 0.8142 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 994/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3988 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.7708\n",
      "Epoch 995/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3988 - acc: 0.8142 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 996/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3988 - acc: 0.8125 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 997/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3989 - acc: 0.8142 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 998/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3988 - acc: 0.8125 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 999/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3989 - acc: 0.8125 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1000/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3989 - acc: 0.8160 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1001/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3988 - acc: 0.8125 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1002/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3988 - acc: 0.8125 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1003/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - acc: 0.8160 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1004/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3988 - acc: 0.8142 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1005/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1006/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3987 - acc: 0.8160 - val_loss: 0.5521 - val_acc: 0.7708\n",
      "Epoch 1007/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3987 - acc: 0.8125 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1008/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1009/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1010/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1011/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1012/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3987 - acc: 0.8125 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1013/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1014/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1015/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5522 - val_acc: 0.7708\n",
      "Epoch 1016/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1017/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3987 - acc: 0.8125 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1018/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3987 - acc: 0.8142 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1019/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3987 - acc: 0.8125 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1020/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5523 - val_acc: 0.7708\n",
      "Epoch 1021/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3986 - acc: 0.8125 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1022/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3987 - acc: 0.8125 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1023/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1024/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1025/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1026/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1027/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1028/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1029/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1030/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3986 - acc: 0.8125 - val_loss: 0.5524 - val_acc: 0.7708\n",
      "Epoch 1031/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3986 - acc: 0.8125 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1032/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3986 - acc: 0.8125 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1033/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1034/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1035/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1036/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1037/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3985 - acc: 0.8160 - val_loss: 0.5526 - val_acc: 0.7708\n",
      "Epoch 1038/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3986 - acc: 0.8125 - val_loss: 0.5526 - val_acc: 0.7708\n",
      "Epoch 1039/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3986 - acc: 0.8142 - val_loss: 0.5526 - val_acc: 0.7708\n",
      "Epoch 1040/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5525 - val_acc: 0.7708\n",
      "Epoch 1041/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3985 - acc: 0.8125 - val_loss: 0.5526 - val_acc: 0.7708\n",
      "Epoch 1042/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5526 - val_acc: 0.7708\n",
      "Epoch 1043/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5526 - val_acc: 0.7760\n",
      "Epoch 1044/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3984 - acc: 0.8125 - val_loss: 0.5526 - val_acc: 0.7760\n",
      "Epoch 1045/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5526 - val_acc: 0.7760\n",
      "Epoch 1046/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1047/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1048/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1049/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1050/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1051/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1052/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1053/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3985 - acc: 0.8125 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1054/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3985 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1055/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5527 - val_acc: 0.7760\n",
      "Epoch 1056/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1057/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1058/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1059/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1060/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3984 - acc: 0.8160 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1061/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1062/3000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1063/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1064/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5528 - val_acc: 0.7760\n",
      "Epoch 1065/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1066/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3984 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1067/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1068/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3983 - acc: 0.8125 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1069/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1070/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1071/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1072/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3983 - acc: 0.8160 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1073/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1074/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1075/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1076/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5529 - val_acc: 0.7760\n",
      "Epoch 1077/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - acc: 0.8125 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1078/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 39us/step - loss: 0.3983 - acc: 0.8160 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1079/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3983 - acc: 0.8125 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1080/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1081/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1082/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1083/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1084/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1085/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1086/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3983 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1087/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1088/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1089/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1090/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1091/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1092/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1093/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5530 - val_acc: 0.7760\n",
      "Epoch 1094/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1095/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1096/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1097/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1098/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1099/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1100/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3982 - acc: 0.8160 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1101/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3982 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1102/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1103/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1104/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1105/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5531 - val_acc: 0.7760\n",
      "Epoch 1106/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1107/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1108/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1109/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1110/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1111/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1112/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1113/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1114/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1115/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1116/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1117/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5532 - val_acc: 0.7760\n",
      "Epoch 1118/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3981 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1119/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1120/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1121/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3981 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1122/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1123/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1124/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1125/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1126/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1127/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1128/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1129/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1130/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1131/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1132/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1133/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1134/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5533 - val_acc: 0.7760\n",
      "Epoch 1135/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3980 - acc: 0.8142 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1136/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1137/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1138/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1139/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1140/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3980 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1141/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1142/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1143/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1144/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1145/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1146/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1147/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5534 - val_acc: 0.7760\n",
      "Epoch 1148/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1149/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1150/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1151/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1152/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1153/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1154/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3978 - acc: 0.8142 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1155/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3979 - acc: 0.8142 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1156/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1157/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3978 - acc: 0.8142 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1158/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1159/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1160/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3979 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1161/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1162/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1163/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3978 - acc: 0.8142 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1164/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1165/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1166/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1167/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5535 - val_acc: 0.7760\n",
      "Epoch 1168/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3977 - acc: 0.8142 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1169/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1170/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1171/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1172/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.3977 - acc: 0.8142 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1173/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1174/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1175/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1176/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1177/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3977 - acc: 0.8142 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1178/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1179/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5536 - val_acc: 0.7760\n",
      "Epoch 1180/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1181/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1182/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3978 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1183/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1184/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1185/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1186/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3977 - acc: 0.8142 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1187/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1188/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1189/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3977 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1190/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3976 - acc: 0.8142 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1191/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1192/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1193/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1194/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3976 - acc: 0.8125 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1195/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1196/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 63us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1197/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5537 - val_acc: 0.7760\n",
      "Epoch 1198/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1199/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1200/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1201/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1202/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1203/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1204/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1205/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1206/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1207/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1208/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1209/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3976 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1210/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1211/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1212/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1213/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1214/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1215/3000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1216/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1217/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1218/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1219/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1220/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1221/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3975 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1222/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1223/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5538 - val_acc: 0.7760\n",
      "Epoch 1224/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3974 - acc: 0.8142 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1225/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1226/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3974 - acc: 0.8142 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1227/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1228/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3973 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1229/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3974 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1230/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3974 - acc: 0.8142 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1231/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3973 - acc: 0.8142 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1232/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3973 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1233/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3973 - acc: 0.8142 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1234/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3973 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1235/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3973 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1236/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3973 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1237/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3973 - acc: 0.8125 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1238/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3973 - acc: 0.8160 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1239/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3973 - acc: 0.8142 - val_loss: 0.5539 - val_acc: 0.7760\n",
      "Epoch 1240/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1241/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1242/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1243/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3972 - acc: 0.8160 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1244/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3973 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1245/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1246/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3973 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1247/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3973 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1248/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.3973 - acc: 0.8125 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1249/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1250/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1251/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1252/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1253/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1254/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1255/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1256/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1257/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5540 - val_acc: 0.7760\n",
      "Epoch 1258/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1259/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1260/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1261/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1262/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1263/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1264/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3972 - acc: 0.8142 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1265/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3971 - acc: 0.8142 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1266/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1267/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3971 - acc: 0.8142 - val_loss: 0.5541 - val_acc: 0.7760\n",
      "Epoch 1268/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1269/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1270/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1271/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3972 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1272/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3971 - acc: 0.8142 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1273/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3971 - acc: 0.8142 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1274/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1275/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1276/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3971 - acc: 0.8142 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1277/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1278/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1279/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3971 - acc: 0.8142 - val_loss: 0.5542 - val_acc: 0.7760\n",
      "Epoch 1280/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1281/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3971 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1282/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1283/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1284/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1285/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3970 - acc: 0.8142 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1286/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1287/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1288/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3970 - acc: 0.8142 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1289/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1290/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3970 - acc: 0.8142 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1291/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1292/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1293/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1294/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1295/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1296/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3969 - acc: 0.8142 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1297/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5543 - val_acc: 0.7760\n",
      "Epoch 1298/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1299/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1300/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1301/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3969 - acc: 0.8142 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1302/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1303/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3969 - acc: 0.8142 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1304/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3969 - acc: 0.8142 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1305/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1306/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1307/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1308/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1309/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1310/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1311/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3968 - acc: 0.8142 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1312/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1313/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1314/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 37us/step - loss: 0.3969 - acc: 0.8142 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1315/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3968 - acc: 0.8142 - val_loss: 0.5544 - val_acc: 0.7760\n",
      "Epoch 1316/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3969 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1317/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1318/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1319/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1320/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1321/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1322/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1323/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1324/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1325/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1326/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1327/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1328/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3967 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1329/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3967 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1330/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1331/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3967 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1332/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3967 - acc: 0.8125 - val_loss: 0.5545 - val_acc: 0.7760\n",
      "Epoch 1333/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3968 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1334/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3967 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1335/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3966 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1336/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3967 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1337/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1338/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3967 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1339/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1340/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3967 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1341/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3967 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1342/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1343/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3967 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1344/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1345/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1346/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1347/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3966 - acc: 0.8125 - val_loss: 0.5546 - val_acc: 0.7760\n",
      "Epoch 1348/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1349/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1350/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1351/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1352/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1353/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1354/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1355/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1356/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1357/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1358/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1359/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5547 - val_acc: 0.7760\n",
      "Epoch 1360/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1361/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1362/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1363/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3966 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1364/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1365/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1366/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1367/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1368/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1369/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1370/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1371/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1372/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1373/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7760\n",
      "Epoch 1374/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5548 - val_acc: 0.7760\n",
      "Epoch 1375/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7760\n",
      "Epoch 1376/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7760\n",
      "Epoch 1377/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1378/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1379/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3965 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1380/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1381/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1382/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1383/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1384/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1385/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1386/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1387/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1388/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1389/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5549 - val_acc: 0.7708\n",
      "Epoch 1390/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1391/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3964 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1392/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1393/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1394/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1395/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1396/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1397/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1398/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1399/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5550 - val_acc: 0.7708\n",
      "Epoch 1400/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5551 - val_acc: 0.7708\n",
      "Epoch 1401/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5551 - val_acc: 0.7708\n",
      "Epoch 1402/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5551 - val_acc: 0.7708\n",
      "Epoch 1403/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5551 - val_acc: 0.7708\n",
      "Epoch 1404/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5551 - val_acc: 0.7708\n",
      "Epoch 1405/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3963 - acc: 0.8142 - val_loss: 0.5552 - val_acc: 0.7708\n",
      "Epoch 1406/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5552 - val_acc: 0.7708\n",
      "Epoch 1407/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5552 - val_acc: 0.7708\n",
      "Epoch 1408/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5553 - val_acc: 0.7708\n",
      "Epoch 1409/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5553 - val_acc: 0.7708\n",
      "Epoch 1410/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5554 - val_acc: 0.7708\n",
      "Epoch 1411/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5554 - val_acc: 0.7708\n",
      "Epoch 1412/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5554 - val_acc: 0.7708\n",
      "Epoch 1413/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3962 - acc: 0.8142 - val_loss: 0.5555 - val_acc: 0.7708\n",
      "Epoch 1414/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5555 - val_acc: 0.7708\n",
      "Epoch 1415/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5556 - val_acc: 0.7708\n",
      "Epoch 1416/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5556 - val_acc: 0.7708\n",
      "Epoch 1417/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5557 - val_acc: 0.7708\n",
      "Epoch 1418/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5557 - val_acc: 0.7708\n",
      "Epoch 1419/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5557 - val_acc: 0.7708\n",
      "Epoch 1420/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5558 - val_acc: 0.7708\n",
      "Epoch 1421/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5558 - val_acc: 0.7708\n",
      "Epoch 1422/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5558 - val_acc: 0.7708\n",
      "Epoch 1423/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5558 - val_acc: 0.7708\n",
      "Epoch 1424/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5559 - val_acc: 0.7708\n",
      "Epoch 1425/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5559 - val_acc: 0.7708\n",
      "Epoch 1426/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3961 - acc: 0.8142 - val_loss: 0.5560 - val_acc: 0.7708\n",
      "Epoch 1427/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5560 - val_acc: 0.7708\n",
      "Epoch 1428/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5560 - val_acc: 0.7708\n",
      "Epoch 1429/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5560 - val_acc: 0.7708\n",
      "Epoch 1430/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5561 - val_acc: 0.7708\n",
      "Epoch 1431/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5561 - val_acc: 0.7708\n",
      "Epoch 1432/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 33us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5561 - val_acc: 0.7708\n",
      "Epoch 1433/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5561 - val_acc: 0.7708\n",
      "Epoch 1434/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3960 - acc: 0.8142 - val_loss: 0.5562 - val_acc: 0.7708\n",
      "Epoch 1435/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5562 - val_acc: 0.7708\n",
      "Epoch 1436/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5562 - val_acc: 0.7708\n",
      "Epoch 1437/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5562 - val_acc: 0.7708\n",
      "Epoch 1438/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5563 - val_acc: 0.7708\n",
      "Epoch 1439/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5563 - val_acc: 0.7708\n",
      "Epoch 1440/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5563 - val_acc: 0.7708\n",
      "Epoch 1441/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5564 - val_acc: 0.7708\n",
      "Epoch 1442/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5564 - val_acc: 0.7708\n",
      "Epoch 1443/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3959 - acc: 0.8142 - val_loss: 0.5564 - val_acc: 0.7708\n",
      "Epoch 1444/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5565 - val_acc: 0.7708\n",
      "Epoch 1445/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5565 - val_acc: 0.7708\n",
      "Epoch 1446/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5565 - val_acc: 0.7708\n",
      "Epoch 1447/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5565 - val_acc: 0.7708\n",
      "Epoch 1448/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5565 - val_acc: 0.7708\n",
      "Epoch 1449/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5566 - val_acc: 0.7708\n",
      "Epoch 1450/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3958 - acc: 0.8142 - val_loss: 0.5566 - val_acc: 0.7708\n",
      "Epoch 1451/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5567 - val_acc: 0.7708\n",
      "Epoch 1452/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5567 - val_acc: 0.7708\n",
      "Epoch 1453/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5567 - val_acc: 0.7708\n",
      "Epoch 1454/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5567 - val_acc: 0.7708\n",
      "Epoch 1455/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5567 - val_acc: 0.7708\n",
      "Epoch 1456/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5567 - val_acc: 0.7708\n",
      "Epoch 1457/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5568 - val_acc: 0.7708\n",
      "Epoch 1458/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3957 - acc: 0.8142 - val_loss: 0.5568 - val_acc: 0.7708\n",
      "Epoch 1459/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5568 - val_acc: 0.7708\n",
      "Epoch 1460/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5569 - val_acc: 0.7708\n",
      "Epoch 1461/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.7708\n",
      "Epoch 1462/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.7708\n",
      "Epoch 1463/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.7708\n",
      "Epoch 1464/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3956 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.7708\n",
      "Epoch 1465/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.7708\n",
      "Epoch 1466/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.7708\n",
      "Epoch 1467/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5571 - val_acc: 0.7708\n",
      "Epoch 1468/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5571 - val_acc: 0.7708\n",
      "Epoch 1469/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5571 - val_acc: 0.7708\n",
      "Epoch 1470/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5572 - val_acc: 0.7708\n",
      "Epoch 1471/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3955 - acc: 0.8142 - val_loss: 0.5572 - val_acc: 0.7708\n",
      "Epoch 1472/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3954 - acc: 0.8142 - val_loss: 0.5572 - val_acc: 0.7708\n",
      "Epoch 1473/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3954 - acc: 0.8142 - val_loss: 0.5572 - val_acc: 0.7708\n",
      "Epoch 1474/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3954 - acc: 0.8142 - val_loss: 0.5573 - val_acc: 0.7708\n",
      "Epoch 1475/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5573 - val_acc: 0.7708\n",
      "Epoch 1476/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5573 - val_acc: 0.7708\n",
      "Epoch 1477/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3954 - acc: 0.8142 - val_loss: 0.5574 - val_acc: 0.7708\n",
      "Epoch 1478/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5574 - val_acc: 0.7708\n",
      "Epoch 1479/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5574 - val_acc: 0.7708\n",
      "Epoch 1480/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5574 - val_acc: 0.7708\n",
      "Epoch 1481/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5575 - val_acc: 0.7708\n",
      "Epoch 1482/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3953 - acc: 0.8142 - val_loss: 0.5575 - val_acc: 0.7708\n",
      "Epoch 1483/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3952 - acc: 0.8142 - val_loss: 0.5575 - val_acc: 0.7708\n",
      "Epoch 1484/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3952 - acc: 0.8142 - val_loss: 0.5576 - val_acc: 0.7708\n",
      "Epoch 1485/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3952 - acc: 0.8142 - val_loss: 0.5577 - val_acc: 0.7708\n",
      "Epoch 1486/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3951 - acc: 0.8142 - val_loss: 0.5577 - val_acc: 0.7708\n",
      "Epoch 1487/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3952 - acc: 0.8142 - val_loss: 0.5577 - val_acc: 0.7708\n",
      "Epoch 1488/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3951 - acc: 0.8142 - val_loss: 0.5578 - val_acc: 0.7708\n",
      "Epoch 1489/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3951 - acc: 0.8142 - val_loss: 0.5578 - val_acc: 0.7708\n",
      "Epoch 1490/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3951 - acc: 0.8142 - val_loss: 0.5578 - val_acc: 0.7708\n",
      "Epoch 1491/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3950 - acc: 0.8142 - val_loss: 0.5579 - val_acc: 0.7708\n",
      "Epoch 1492/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3951 - acc: 0.8142 - val_loss: 0.5579 - val_acc: 0.7708\n",
      "Epoch 1493/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3950 - acc: 0.8142 - val_loss: 0.5580 - val_acc: 0.7708\n",
      "Epoch 1494/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3950 - acc: 0.8142 - val_loss: 0.5580 - val_acc: 0.7708\n",
      "Epoch 1495/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3951 - acc: 0.8142 - val_loss: 0.5580 - val_acc: 0.7708\n",
      "Epoch 1496/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3950 - acc: 0.8160 - val_loss: 0.5581 - val_acc: 0.7708\n",
      "Epoch 1497/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3949 - acc: 0.8160 - val_loss: 0.5581 - val_acc: 0.7708\n",
      "Epoch 1498/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3950 - acc: 0.8160 - val_loss: 0.5581 - val_acc: 0.7708\n",
      "Epoch 1499/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3950 - acc: 0.8160 - val_loss: 0.5581 - val_acc: 0.7708\n",
      "Epoch 1500/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3949 - acc: 0.8160 - val_loss: 0.5581 - val_acc: 0.7708\n",
      "Epoch 1501/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3949 - acc: 0.8160 - val_loss: 0.5581 - val_acc: 0.7708\n",
      "Epoch 1502/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3949 - acc: 0.8160 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1503/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3948 - acc: 0.8142 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1504/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3948 - acc: 0.8177 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1505/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3948 - acc: 0.8160 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1506/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3948 - acc: 0.8177 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1507/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3948 - acc: 0.8177 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1508/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3948 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1509/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3947 - acc: 0.8177 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1510/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3947 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1511/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3947 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1512/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3947 - acc: 0.8177 - val_loss: 0.5582 - val_acc: 0.7708\n",
      "Epoch 1513/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3947 - acc: 0.8160 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1514/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3946 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1515/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3945 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1516/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3946 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1517/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3946 - acc: 0.8160 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1518/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3945 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1519/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3946 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1520/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3945 - acc: 0.8177 - val_loss: 0.5583 - val_acc: 0.7708\n",
      "Epoch 1521/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3945 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1522/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3945 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1523/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3945 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1524/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3944 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1525/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3944 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1526/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3944 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1527/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1528/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1529/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1530/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3944 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1531/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1532/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5584 - val_acc: 0.7708\n",
      "Epoch 1533/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1534/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1535/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1536/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1537/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1538/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3943 - acc: 0.8177 - val_loss: 0.5585 - val_acc: 0.7708\n",
      "Epoch 1539/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5586 - val_acc: 0.7708\n",
      "Epoch 1540/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5586 - val_acc: 0.7708\n",
      "Epoch 1541/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5586 - val_acc: 0.7708\n",
      "Epoch 1542/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5586 - val_acc: 0.7708\n",
      "Epoch 1543/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5586 - val_acc: 0.7708\n",
      "Epoch 1544/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5586 - val_acc: 0.7708\n",
      "Epoch 1545/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5587 - val_acc: 0.7708\n",
      "Epoch 1546/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3942 - acc: 0.8177 - val_loss: 0.5587 - val_acc: 0.7708\n",
      "Epoch 1547/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5587 - val_acc: 0.7708\n",
      "Epoch 1548/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5587 - val_acc: 0.7708\n",
      "Epoch 1549/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5587 - val_acc: 0.7708\n",
      "Epoch 1550/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.3941 - acc: 0.8177 - val_loss: 0.5587 - val_acc: 0.7708\n",
      "Epoch 1551/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5588 - val_acc: 0.7708\n",
      "Epoch 1552/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5588 - val_acc: 0.7708\n",
      "Epoch 1553/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5588 - val_acc: 0.7708\n",
      "Epoch 1554/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5589 - val_acc: 0.7708\n",
      "Epoch 1555/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5588 - val_acc: 0.7708\n",
      "Epoch 1556/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5589 - val_acc: 0.7708\n",
      "Epoch 1557/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5589 - val_acc: 0.7708\n",
      "Epoch 1558/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5589 - val_acc: 0.7708\n",
      "Epoch 1559/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5590 - val_acc: 0.7708\n",
      "Epoch 1560/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5590 - val_acc: 0.7708\n",
      "Epoch 1561/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5590 - val_acc: 0.7708\n",
      "Epoch 1562/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5591 - val_acc: 0.7708\n",
      "Epoch 1563/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3940 - acc: 0.8177 - val_loss: 0.5591 - val_acc: 0.7708\n",
      "Epoch 1564/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5591 - val_acc: 0.7708\n",
      "Epoch 1565/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5591 - val_acc: 0.7708\n",
      "Epoch 1566/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5592 - val_acc: 0.7708\n",
      "Epoch 1567/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5592 - val_acc: 0.7708\n",
      "Epoch 1568/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5592 - val_acc: 0.7708\n",
      "Epoch 1569/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5592 - val_acc: 0.7708\n",
      "Epoch 1570/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3939 - acc: 0.8177 - val_loss: 0.5592 - val_acc: 0.7708\n",
      "Epoch 1571/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5592 - val_acc: 0.7708\n",
      "Epoch 1572/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5593 - val_acc: 0.7708\n",
      "Epoch 1573/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5593 - val_acc: 0.7708\n",
      "Epoch 1574/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5593 - val_acc: 0.7708\n",
      "Epoch 1575/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5594 - val_acc: 0.7708\n",
      "Epoch 1576/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5594 - val_acc: 0.7708\n",
      "Epoch 1577/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5594 - val_acc: 0.7708\n",
      "Epoch 1578/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5594 - val_acc: 0.7708\n",
      "Epoch 1579/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5594 - val_acc: 0.7708\n",
      "Epoch 1580/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5595 - val_acc: 0.7708\n",
      "Epoch 1581/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5595 - val_acc: 0.7708\n",
      "Epoch 1582/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5595 - val_acc: 0.7708\n",
      "Epoch 1583/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5595 - val_acc: 0.7708\n",
      "Epoch 1584/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5596 - val_acc: 0.7708\n",
      "Epoch 1585/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5596 - val_acc: 0.7708\n",
      "Epoch 1586/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5596 - val_acc: 0.7708\n",
      "Epoch 1587/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3938 - acc: 0.8177 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1588/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1589/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1590/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1591/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3937 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1592/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1593/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1594/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1595/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1596/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3935 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1597/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3936 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1598/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3935 - acc: 0.8177 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1599/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3935 - acc: 0.8177 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1600/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3935 - acc: 0.8177 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1601/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3935 - acc: 0.8177 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1602/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3935 - acc: 0.8177 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1603/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3935 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1604/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3934 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1605/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3934 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1606/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3934 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1607/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3934 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1608/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3933 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1609/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3933 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1610/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3933 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1611/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3933 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1612/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3932 - acc: 0.8177 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1613/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3933 - acc: 0.8177 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1614/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3931 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1615/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3931 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1616/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3932 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1617/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3932 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1618/3000\n",
      "576/576 [==============================] - 0s 155us/step - loss: 0.3931 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1619/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3931 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1620/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3932 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1621/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.3931 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1622/3000\n",
      "576/576 [==============================] - 0s 101us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1623/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1624/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1625/3000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1626/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1627/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1628/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3930 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1629/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3929 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1630/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3929 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1631/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3929 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1632/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3929 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1633/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3929 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1634/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3929 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1635/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3928 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1636/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3928 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1637/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3928 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1638/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3928 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1639/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1640/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1641/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1642/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3928 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1643/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1644/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5596 - val_acc: 0.7708\n",
      "Epoch 1645/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1646/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3927 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1647/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3927 - acc: 0.8212 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1648/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3926 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1649/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3926 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1650/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3926 - acc: 0.8194 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 1651/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3926 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1652/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3926 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1653/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1654/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1655/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1656/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3925 - acc: 0.8212 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1657/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3926 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1658/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1659/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1660/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1661/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3925 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1662/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1663/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1664/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1665/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1666/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1667/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1668/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 45us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 1669/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1670/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3924 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1671/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1672/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1673/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1674/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1675/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1676/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1677/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1678/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1679/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 1680/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 1681/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 1682/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 1683/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 1684/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 1685/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 1686/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1687/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1688/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1689/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1690/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1691/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1692/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1693/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 1694/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1695/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1696/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1697/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3922 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1698/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1699/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1700/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1701/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1702/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1703/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1704/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3921 - acc: 0.8194 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 1705/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1706/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1707/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1708/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1709/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1710/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1711/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1712/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1713/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 1714/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3920 - acc: 0.8194 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1715/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1716/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1717/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3919 - acc: 0.8194 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1718/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1719/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1720/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 1721/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1722/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1723/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3920 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1724/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1725/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1726/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1727/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1728/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1729/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1730/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1731/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1732/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1733/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1734/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 1735/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1736/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1737/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1738/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1739/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1740/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1741/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3919 - acc: 0.8194 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1742/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1743/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1744/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1745/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1746/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3919 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1747/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1748/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1749/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1750/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1751/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1752/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1753/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1754/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1755/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1756/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3918 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1757/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1758/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1759/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1760/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3917 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1761/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1762/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5606 - val_acc: 0.7708\n",
      "Epoch 1763/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1764/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1765/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3917 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1766/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3917 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1767/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3916 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1768/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3916 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1769/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1770/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1771/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1772/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3916 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1773/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1774/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3916 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1775/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1776/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1777/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3915 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1778/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1779/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1780/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3916 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1781/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1782/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1783/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1784/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1785/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1786/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 35us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7708\n",
      "Epoch 1787/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1788/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3915 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1789/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1790/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1791/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1792/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1793/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1794/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1795/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1796/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1797/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1798/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1799/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7708\n",
      "Epoch 1800/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1801/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7708\n",
      "Epoch 1802/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3915 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7708\n",
      "Epoch 1803/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7708\n",
      "Epoch 1804/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1805/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1806/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1807/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7708\n",
      "Epoch 1808/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1809/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7708\n",
      "Epoch 1810/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1811/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1812/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1813/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1814/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3914 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1815/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1816/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1817/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1818/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1819/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1820/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1821/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1822/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1823/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1824/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1825/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1826/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1827/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1828/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1829/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1830/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1831/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1832/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1833/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1834/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1835/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1836/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1837/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1838/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1839/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1840/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1841/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1842/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1843/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1844/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1845/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1846/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1847/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1848/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1849/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1850/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1851/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1852/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1853/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1854/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1855/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1856/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7604\n",
      "Epoch 1857/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1858/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1859/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1860/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3912 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1861/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1862/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1863/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1864/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1865/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1866/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1867/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1868/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1869/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3911 - acc: 0.8212 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1870/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3910 - acc: 0.8212 - val_loss: 0.5610 - val_acc: 0.7604\n",
      "Epoch 1871/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1872/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1873/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1874/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1875/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1876/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3911 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1877/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7604\n",
      "Epoch 1878/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1879/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1880/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7604\n",
      "Epoch 1881/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7604\n",
      "Epoch 1882/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1883/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1884/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1885/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1886/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1887/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1888/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3910 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1889/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1890/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1891/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1892/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5613 - val_acc: 0.7656\n",
      "Epoch 1893/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1894/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1895/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5613 - val_acc: 0.7656\n",
      "Epoch 1896/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5613 - val_acc: 0.7656\n",
      "Epoch 1897/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3909 - acc: 0.8212 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1898/3000\n",
      "576/576 [==============================] - 0s 117us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1899/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1900/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3909 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1901/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1902/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1903/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1904/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 53us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1905/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1906/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1907/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1908/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3907 - acc: 0.8212 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1909/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1910/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1911/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1912/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1913/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1914/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1915/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1916/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3908 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1917/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1918/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1919/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3907 - acc: 0.8212 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1920/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1921/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1922/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1923/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1924/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1925/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1926/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3907 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1927/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3907 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1928/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1929/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1930/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5240 - acc: 0.812 - 0s 48us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1931/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1932/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1933/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1934/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1935/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1936/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1937/3000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.3906 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1938/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1939/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3905 - acc: 0.8212 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1940/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1941/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3905 - acc: 0.8212 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1942/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1943/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1944/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3906 - acc: 0.8212 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1945/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3905 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1946/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1947/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3905 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1948/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1949/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 1950/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1951/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3905 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1952/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3904 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1953/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1954/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1955/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1956/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1957/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1958/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1959/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1960/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1961/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3905 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1962/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1963/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3904 - acc: 0.8229 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1964/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1965/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1966/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3903 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1967/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1968/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1969/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1970/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1971/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1972/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3904 - acc: 0.8212 - val_loss: 0.5611 - val_acc: 0.7656\n",
      "Epoch 1973/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1974/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1975/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3903 - acc: 0.8212 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1976/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1977/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3903 - acc: 0.8212 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1978/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1979/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1980/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1981/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1982/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3904 - acc: 0.8194 - val_loss: 0.5610 - val_acc: 0.7656\n",
      "Epoch 1983/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1984/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1985/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3903 - acc: 0.8247 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1986/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3903 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1987/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1988/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1989/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3903 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1990/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1991/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1992/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1993/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1994/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1995/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1996/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.7656\n",
      "Epoch 1997/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1998/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 1999/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3902 - acc: 0.8229 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2000/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3902 - acc: 0.8229 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2001/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3901 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2002/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2003/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2004/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2005/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3901 - acc: 0.8229 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2006/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2007/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3902 - acc: 0.8212 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2008/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3901 - acc: 0.8229 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2009/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2010/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3901 - acc: 0.8194 - val_loss: 0.5608 - val_acc: 0.7656\n",
      "Epoch 2011/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3901 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2012/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3902 - acc: 0.8194 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2013/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3901 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2014/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3901 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2015/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3901 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2016/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3901 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2017/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3901 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2018/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2019/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3900 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2020/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2021/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2022/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 31us/step - loss: 0.3901 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2023/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3900 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2024/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2025/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3901 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2026/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3900 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2027/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3900 - acc: 0.8212 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2028/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2029/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2030/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2031/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2032/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2033/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3899 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2034/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2035/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2036/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2037/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2038/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2039/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2040/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3900 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2041/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2042/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3899 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2043/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2044/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2045/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2046/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3899 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2047/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2048/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3899 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2049/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2050/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2051/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2052/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2053/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2054/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3899 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2055/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2056/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2057/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3898 - acc: 0.8229 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2058/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3898 - acc: 0.8229 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2059/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2060/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2061/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2062/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2063/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2064/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2065/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2066/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2067/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2068/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2069/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2070/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3898 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2071/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3897 - acc: 0.8229 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2072/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2073/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2074/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2075/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3898 - acc: 0.8229 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2076/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3897 - acc: 0.8264 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2077/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2078/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2079/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3896 - acc: 0.8229 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2080/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3897 - acc: 0.8229 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2081/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2082/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2083/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2084/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3896 - acc: 0.8229 - val_loss: 0.5602 - val_acc: 0.7656\n",
      "Epoch 2085/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7656\n",
      "Epoch 2086/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7656\n",
      "Epoch 2087/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7656\n",
      "Epoch 2088/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7656\n",
      "Epoch 2089/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2090/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2091/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2092/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2093/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2094/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2095/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3897 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2096/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2097/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2098/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2099/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2100/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2101/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2102/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2103/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2104/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2105/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2106/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2107/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2108/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2109/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3895 - acc: 0.8264 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2110/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2111/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2112/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2113/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2114/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2115/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2116/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2117/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2118/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2119/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2120/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7656\n",
      "Epoch 2121/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2122/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2123/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3894 - acc: 0.8264 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2124/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2125/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2126/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2127/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2128/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2129/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2130/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2131/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2132/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2133/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2134/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2135/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2136/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3893 - acc: 0.8229 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2137/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3894 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2138/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2139/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3893 - acc: 0.8264 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2140/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 47us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2141/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2142/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2143/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3893 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2144/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2145/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3893 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2146/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2147/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3892 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2148/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3893 - acc: 0.8229 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2149/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2150/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2151/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2152/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2153/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2154/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2155/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2156/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2157/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2158/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3893 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2159/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3893 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2160/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2161/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2162/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3892 - acc: 0.8264 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2163/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2164/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2165/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2166/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2167/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2168/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2169/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3891 - acc: 0.8264 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2170/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2171/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2172/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3892 - acc: 0.8264 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2173/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2174/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2175/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2176/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2177/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2178/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2179/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2180/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2181/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2182/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2183/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3891 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2184/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2185/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2186/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2187/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2188/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2189/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2190/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2191/3000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.3891 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2192/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3889 - acc: 0.8264 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2193/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2194/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2195/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2196/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2197/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2198/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2199/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2200/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2201/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2202/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2203/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2204/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2205/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2206/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3890 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2207/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3889 - acc: 0.8264 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2208/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2209/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2210/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3890 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2211/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2212/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2213/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2214/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2215/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2216/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2217/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2218/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3889 - acc: 0.8264 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2219/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2220/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2221/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2222/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2223/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2224/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2225/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3888 - acc: 0.8264 - val_loss: 0.5607 - val_acc: 0.7656\n",
      "Epoch 2226/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2227/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2228/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2229/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2230/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2231/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2232/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2233/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2234/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2235/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2236/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2237/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2238/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3889 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2239/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3887 - acc: 0.8264 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2240/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2241/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2242/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2243/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2244/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2245/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3888 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2246/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2247/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2248/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3888 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2249/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3888 - acc: 0.8264 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2250/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2251/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2252/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3887 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2253/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2254/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3886 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2255/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2256/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2257/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3887 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2258/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 37us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2259/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3886 - acc: 0.8229 - val_loss: 0.5606 - val_acc: 0.7656\n",
      "Epoch 2260/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2261/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3887 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2262/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2263/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2264/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3887 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2265/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2266/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3886 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2267/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2268/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2269/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2270/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7656\n",
      "Epoch 2271/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3886 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2272/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2273/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2274/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2275/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3886 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2276/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3886 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2277/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2278/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2279/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2280/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7656\n",
      "Epoch 2281/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2282/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2283/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2284/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2285/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2286/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3885 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2287/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2288/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2289/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2290/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2291/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3885 - acc: 0.8229 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2292/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3886 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2293/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2294/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2295/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2296/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2297/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2298/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2299/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2300/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5605 - val_acc: 0.7708\n",
      "Epoch 2301/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2302/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2303/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2304/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2305/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2306/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2307/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3885 - acc: 0.8229 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2308/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2309/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2310/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2311/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2312/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2313/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2314/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2315/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3885 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2316/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2317/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2318/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2319/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2320/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2321/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2322/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2323/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3884 - acc: 0.8229 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2324/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2325/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3884 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2326/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2327/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2328/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2329/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2330/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2331/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2332/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2333/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2334/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2335/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2336/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2337/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2338/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5604 - val_acc: 0.7708\n",
      "Epoch 2339/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2340/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2341/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2342/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2343/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2344/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2345/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2346/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2347/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2348/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2349/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2350/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2351/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2352/3000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2353/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2354/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2355/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5603 - val_acc: 0.7708\n",
      "Epoch 2356/3000\n",
      "576/576 [==============================] - 0s 25us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2357/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2358/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2359/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2360/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2361/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2362/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2363/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3883 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2364/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2365/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2366/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2367/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2368/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2369/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2370/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2371/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2372/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2373/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2374/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2375/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2376/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 38us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2377/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2378/3000\n",
      "576/576 [==============================] - 0s 27us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2379/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7708\n",
      "Epoch 2380/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2381/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2382/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2383/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2384/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2385/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3882 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2386/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2387/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2388/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2389/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2390/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5602 - val_acc: 0.7656\n",
      "Epoch 2391/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2392/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2393/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2394/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2395/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7656\n",
      "Epoch 2396/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2397/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2398/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7656\n",
      "Epoch 2399/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2400/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7656\n",
      "Epoch 2401/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7656\n",
      "Epoch 2402/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7656\n",
      "Epoch 2403/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7656\n",
      "Epoch 2404/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "Epoch 2405/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3881 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2406/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2407/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2408/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5601 - val_acc: 0.7708\n",
      "Epoch 2409/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2410/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2411/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2412/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2413/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2414/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2415/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2416/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3881 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2417/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2418/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2419/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2420/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2421/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2422/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2423/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2424/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2425/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2426/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2427/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2428/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2429/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2430/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3880 - acc: 0.8247 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2431/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2432/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2433/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2434/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2435/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2436/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2437/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2438/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2439/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2440/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2441/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2442/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4987 - acc: 0.718 - 0s 47us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2443/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2444/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3879 - acc: 0.8247 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2445/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2446/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2447/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2448/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2449/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2450/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2451/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2452/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2453/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2454/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2455/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2456/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2457/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2458/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2459/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2460/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2461/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2462/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2463/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2464/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2465/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2466/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2467/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2468/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2469/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2470/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2471/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2472/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.3879 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2473/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2474/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2475/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2476/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2477/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2478/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2479/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2480/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2481/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2482/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2483/3000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2484/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2485/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2486/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2487/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2488/3000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2489/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2490/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2491/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2492/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3994 - acc: 0.843 - 0s 32us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2493/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2494/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2495/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2496/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2497/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2498/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2499/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2500/3000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.3878 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2501/3000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2502/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2503/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2504/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2505/3000\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2506/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2507/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2508/3000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2509/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2510/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2511/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2512/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2513/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2514/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2515/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2516/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2517/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2518/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2519/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2520/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2521/3000\n",
      "576/576 [==============================] - 0s 98us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2522/3000\n",
      "576/576 [==============================] - 0s 110us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2523/3000\n",
      "576/576 [==============================] - 0s 139us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2524/3000\n",
      "576/576 [==============================] - 0s 116us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2525/3000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2526/3000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2527/3000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2528/3000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2529/3000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2530/3000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2531/3000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2532/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2533/3000\n",
      "576/576 [==============================] - 0s 89us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2534/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2535/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2536/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2537/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2538/3000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2539/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3877 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2540/3000\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2541/3000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2542/3000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2543/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2544/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2545/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2546/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2547/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2548/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2549/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2550/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2551/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2552/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2553/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3876 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2554/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2555/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2556/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2557/3000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2558/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2559/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2560/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2561/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2562/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2563/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2564/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2565/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2566/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2567/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2568/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2569/3000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2570/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2571/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2572/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2573/3000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2574/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2575/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2576/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2577/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2578/3000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2579/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2580/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2581/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2582/3000\n",
      "576/576 [==============================] - 0s 62us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2583/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2584/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2585/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2586/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2587/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3875 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2588/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2589/3000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2590/3000\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2591/3000\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2592/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2593/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2594/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2595/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2596/3000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2597/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2598/3000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2599/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2600/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2601/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2602/3000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2603/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2604/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2605/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2606/3000\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2607/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2608/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2609/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2610/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2611/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2612/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 61us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2613/3000\n",
      "576/576 [==============================] - 0s 90us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2614/3000\n",
      "576/576 [==============================] - 0s 72us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2615/3000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2616/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2617/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2618/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2619/3000\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.3874 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2620/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2621/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2622/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2623/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2624/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2625/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2626/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2627/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2628/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2629/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2630/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2631/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2632/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2633/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2634/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2635/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2636/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2637/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2638/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2639/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2640/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2641/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2642/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2643/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2644/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2645/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3873 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2646/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2647/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2648/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2649/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2650/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2651/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2652/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2653/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2654/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2655/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2656/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2657/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2658/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2659/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2660/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2661/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2662/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2663/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3871 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2664/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2665/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3872 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2666/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2667/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2668/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2669/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2670/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2671/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2672/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2673/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2674/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2675/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2676/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2677/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2678/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2679/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2680/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2681/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2682/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2683/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2684/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2685/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2686/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2687/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2688/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2689/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2690/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2691/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2692/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2693/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2694/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3871 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2695/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2696/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2697/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2698/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2699/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2700/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2701/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2702/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2703/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2704/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2705/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2706/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2707/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2708/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2709/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2710/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2711/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2712/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2713/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2714/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3870 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2715/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2716/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2717/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2718/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2719/3000\n",
      "576/576 [==============================] - 0s 115us/step - loss: 0.3869 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2720/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2721/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.3869 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2722/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3869 - acc: 0.8281 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2723/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2724/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2725/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2726/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2727/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2728/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2729/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2730/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 50us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2731/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2732/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2733/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2734/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2735/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2736/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2737/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2738/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2739/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2740/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2741/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2742/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2743/3000\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.3869 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2744/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2745/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2746/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2747/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2748/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2749/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2750/3000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2751/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2752/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2753/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2754/3000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2755/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2756/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2757/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2758/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2759/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2760/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2761/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2762/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2763/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3867 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2764/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2765/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2766/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2767/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2768/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2769/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2770/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3867 - acc: 0.8281 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2771/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2772/3000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2773/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3868 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2774/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2775/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2776/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2777/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3868 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2778/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2779/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3867 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2780/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2781/3000\n",
      "576/576 [==============================] - 0s 67us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5595 - val_acc: 0.7656\n",
      "Epoch 2782/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2783/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2784/3000\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2785/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3867 - acc: 0.8281 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2786/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2787/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2788/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3384 - acc: 0.843 - 0s 69us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2789/3000\n",
      "576/576 [==============================] - 0s 71us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2790/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2791/3000\n",
      "576/576 [==============================] - 0s 44us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2792/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2793/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5596 - val_acc: 0.7656\n",
      "Epoch 2794/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2795/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2796/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2797/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2798/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2799/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2800/3000\n",
      "576/576 [==============================] - 0s 73us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2801/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2802/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2803/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2804/3000\n",
      "576/576 [==============================] - 0s 70us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2805/3000\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5352 - acc: 0.750 - 0s 49us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2806/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2807/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2808/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2809/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2810/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2811/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2812/3000\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2813/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2814/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2815/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2816/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2817/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2818/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2819/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2820/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2821/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2822/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2823/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2824/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2825/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2826/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2827/3000\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2828/3000\n",
      "576/576 [==============================] - 0s 86us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2829/3000\n",
      "576/576 [==============================] - 0s 97us/step - loss: 0.3866 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2830/3000\n",
      "576/576 [==============================] - 0s 65us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2831/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3866 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2832/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2833/3000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2834/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2835/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2836/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2837/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2838/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2839/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2840/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2841/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2842/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2843/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2844/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2845/3000\n",
      "576/576 [==============================] - 0s 51us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2846/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2847/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2848/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 34us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2849/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2850/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2851/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2852/3000\n",
      "576/576 [==============================] - 0s 48us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2853/3000\n",
      "576/576 [==============================] - 0s 53us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2854/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2855/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2856/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2857/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2858/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3865 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2859/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2860/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2861/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2862/3000\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2863/3000\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2864/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7656\n",
      "Epoch 2865/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2866/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2867/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2868/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2869/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2870/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3865 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2871/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2872/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2873/3000\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2874/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2875/3000\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2876/3000\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2877/3000\n",
      "576/576 [==============================] - 0s 92us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2878/3000\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2879/3000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2880/3000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2881/3000\n",
      "576/576 [==============================] - 0s 60us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7656\n",
      "Epoch 2882/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7656\n",
      "Epoch 2883/3000\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.3864 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2884/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2885/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2886/3000\n",
      "576/576 [==============================] - 0s 58us/step - loss: 0.3864 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2887/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2888/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2889/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2890/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2891/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2892/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2893/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2894/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2895/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2896/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2897/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2898/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2899/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2900/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2901/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2902/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2903/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2904/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2905/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2906/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2907/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2908/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2909/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2910/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2911/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2912/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2913/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2914/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2915/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2916/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2917/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2918/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2919/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5597 - val_acc: 0.7708\n",
      "Epoch 2920/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2921/3000\n",
      "576/576 [==============================] - 0s 26us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2922/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2923/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2924/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2925/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2926/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3863 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2927/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2928/3000\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.3861 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2929/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2930/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2931/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2932/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2933/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2934/3000\n",
      "576/576 [==============================] - 0s 55us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2935/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2936/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2937/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2938/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2939/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2940/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2941/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2942/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2943/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2944/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2945/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2946/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2947/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3862 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2948/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2949/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2950/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2951/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2952/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2953/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2954/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2955/3000\n",
      "576/576 [==============================] - 0s 41us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2956/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3862 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2957/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2958/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2959/3000\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2960/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2961/3000\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2962/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2963/3000\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2964/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3861 - acc: 0.8264 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2965/3000\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2966/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 43us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2967/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2968/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2969/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2970/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3861 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2971/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2972/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2973/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2974/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2975/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2976/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2977/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2978/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2979/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2980/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2981/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2982/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3860 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2983/3000\n",
      "576/576 [==============================] - 0s 30us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2984/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2985/3000\n",
      "576/576 [==============================] - 0s 28us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2986/3000\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2987/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2988/3000\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2989/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2990/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2991/3000\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.3860 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2992/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2993/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3860 - acc: 0.8264 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2994/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5600 - val_acc: 0.7708\n",
      "Epoch 2995/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3859 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2996/3000\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.3861 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2997/3000\n",
      "576/576 [==============================] - 0s 29us/step - loss: 0.3859 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 2998/3000\n",
      "576/576 [==============================] - 0s 32us/step - loss: 0.3861 - acc: 0.8264 - val_loss: 0.5599 - val_acc: 0.7708\n",
      "Epoch 2999/3000\n",
      "576/576 [==============================] - 0s 34us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5598 - val_acc: 0.7708\n",
      "Epoch 3000/3000\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.3860 - acc: 0.8281 - val_loss: 0.5599 - val_acc: 0.7708\n"
     ]
    }
   ],
   "source": [
    "#There is not a big improvement when training with 2x as many epochs\n",
    "run_hist_2b = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa248b854a8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt0VOW9//H3N+EuICTgwYqnQYunIkLAFJ1qNV6KoqfaWtuCcsC2Nq09rbX+rGJ7VlV6I9hfpa7jUqnVVX9Q0Z+X6vHgCdVC1RaRcBEFRCjCzxQvMShFATHJ9/fH3hMmk0kySeaWmc9rrVnMfvZlvtkh3/3M8zz72ebuiIhIYSjKdgAiIpI5SvoiIgVESV9EpIAo6YuIFBAlfRGRAqKkLyJSQJT0RUQKiJK+iEgBUdIXESkgfbIdQLwRI0Z4WVlZtsMQEelV1qxZ8467j+xsu5xL+mVlZdTW1mY7DBGRXsXMdiaznZp3REQKiJK+iEgBUdIXESkgOdemLyKZ8dFHH1FXV8eBAweyHYp0wYABAxg9ejR9+/bt1v5K+iIFqq6ujiFDhlBWVoaZZTscSYK709DQQF1dHWPGjOnWMdS8I1KgDhw4QGlpqRJ+L2JmlJaW9ujbWV4l/ZUr4Re/CP4Vkc4p4fc+Pf2d5U3zzlNPwbRp0NwM/fvD009DJJLtqEREckve1PT//GdobAyS/sEPnRUrsh2RiHSkoaGB8vJyysvLGTVqFEcddVTL8sGDB5M6xle/+lW2bNmS9GfefffdXH311d0NOS/kTU3/3JIX+CmfApzi5oNUlm4FTsx2WCLSjtLSUtavXw/ATTfdxODBg7n22mtbbePuuDtFRYnrp/fee2/a48w3SdX0zew8M9tiZtvMbE6C9bea2frw9aqZvRezbraZbQ1fs1MZfKzil16MfiIGsG5duj5KpHBloONs27ZtjB8/nm9961tMnjyZN954g6qqKioqKjjhhBOYO3duy7annXYa69evp7GxkWHDhjFnzhwmTpxIJBLh7bffTvozFy1axIknnsj48eP54Q9/CEBjYyP/9m//1lJ+2223AXDrrbcybtw4Jk6cyMyZM1P7w2dApzV9MysGbgc+C9QBq83scXffFN3G3b8fs/13gUnh+xLgRqACcGBNuO+7Kf0pgBV9PxuNgEaKWcEZqElfJElXXw1hrbtde/bAhg1BG2pREUyYAIcf3v725eWwYEG3wtm0aRP33nsvd955JwDz5s2jpKSExsZGzjzzTC655BLGjRsXF94ezjjjDObNm8c111zDPffcw5w5beqobdTV1fEf//Ef1NbWcvjhh3POOefwxBNPMHLkSN555x1eeuklAN57L6jLzp8/n507d9KvX7+Wst4kmZr+FGCbu29394PAEuCiDrafAdwfvj8X+KO77w4T/R+B83oScHsqLy8juK40U1xsVM76eDo+RqRw7dkTJHwI/t2zJ20fdeyxx/KpT32qZfn+++9n8uTJTJ48mc2bN7Np06Y2+wwcOJBp06YBcNJJJ7Fjx46kPmvVqlWcddZZjBgxgr59+3LppZfyzDPP8IlPfIItW7bwve99j5qaGg4PL3AnnHACM2fOZPHixd2+QSqbkmnTPwp4PWa5Djg50YZm9nFgDPCnDvY9quthJuGllyhiHM0UYU2N8NJmiKhNXyQpydTIV66Es8+GgwehXz9YvDhtQ+QOO+ywlvdbt27l17/+NS+88ALDhg1j5syZCcep9+vXr+V9cXExjY2NSX2WuycsLy0tZcOGDTz55JPcdtttPPzwwyxcuJCamhr+/Oc/89hjj/HTn/6Ul19+meLi4i7+hNmTTE0/0aDQxGcJpgMPuXtTV/Y1syozqzWz2vr6+iRCamvFww00Y7Q07zzc0K3jiEg7IpFgLPRPfpLRMdH/+Mc/GDJkCEOHDuWNN96gpqYmpcc/5ZRTWL58OQ0NDTQ2NrJkyRLOOOMM6uvrcXe+9KUvcfPNN7N27Vqampqoq6vjrLPO4pZbbqG+vp59+/alNJ50S6amXwccHbM8GtjVzrbTgX+P27cybt8V8Tu5+0JgIUBFRUV7F5QOVX6xlOJlzTRhFNNE5RdLu3MYEelIJJLxG2AmT57MuHHjGD9+PMcccwynnnpqj47329/+loceeqhluba2lrlz51JZWYm787nPfY4LLriAtWvX8vWvfx13x8yorq6msbGRSy+9lL1799Lc3Mz111/PkCFDevojZpS199WmZQOzPsCrwNnA34HVwKXuvjFuu38BaoAxHh407MhdA0wON1sLnOTuu9v7vIqKCu/OQ1RWLnyJz3zzeJoopj8fsvyurUSq1Lwj0p7Nmzdz/PHHZzsM6YZEvzszW+PuFZ3t22nzjrs3At8hSOibgQfdfaOZzTWzC2M2nQEs8ZirSJjcf0JwoVgNzO0o4feEmndERDqX1M1Z7r4UWBpX9uO45Zva2fce4J5uxpe0yi+WUrSsiSaKKaZZzTsiIgnkzTQMEPvDaBIpEZFE8ibpr3i4gabwx2mkSM07IiIJ5E3Sr/xiKf34CAjq+aXlR3e8g4hIAcqbpB858X2qi24AoJkirv51mebVFxGJkzdJnxUreL95EOA4RXz4IZpeWSSHVVZWtrnRasGCBXz729/ucL/BgwcDsGvXLi655JJ2j93Z0O8FCxa0urHq/PPPT8lcOjfddBO//OUve3ycdMmfpF9ZyYg+0V+Y00wRpRrAI5KzZsyYwZIlS1qVLVmyhBkzZiS1/8c+9rFWN1l1VXzSX7p0KcOGDev28XqL/En6kQgNn50eLhhGEw3rdmY1JJF8k8qZlS+55BKeeOIJPvzwQwB27NjBrl27OO2003j//fc5++yzmTx5MieeeCKPPfZYm/137NjB+PHjAdi/fz/Tp09nwoQJfOUrX2H//v0t21155ZUt0zLfeOONANx2223s2rWLM888kzPPPBOAsrIy3nnnHQB+9atfMX78eMaPH8+CcF6iHTt2cPzxx/ONb3yDE044galTp7b6nM4kOuYHH3zABRdcwMSJExk/fjwPPPAAAHPmzGHcuHFMmDChzTMGeipvHqICUNr3H+E7xymm9M2NgGbbFOlMNmZWLi0tZcqUKfzP//wPF110EUuWLOErX/kKZsaAAQN49NFHGTp0KO+88w6nnHIKF154YbvPh73jjjsYNGgQGzZsYMOGDUyePLll3c9+9jNKSkpoamri7LPPZsOGDVx11VX86le/Yvny5YwYMaLVsdasWcO9997LqlWrcHdOPvlkzjjjDIYPH87WrVu5//77+c1vfsOXv/xlHn744aTm1G/vmNu3b+djH/sY//3f/x2e4z3s3r2bRx99lFdeeQUzS/n0zflT0wcaio4gmM/NKKKJBkZ0touIJCkdMyvHNvHENu24Oz/84Q+ZMGEC55xzDn//+99566232j3OM88805J8J0yYwIQJE1rWPfjgg0yePJlJkyaxcePGhNMyx3ruuef4whe+wGGHHcbgwYO5+OKLefbZZwEYM2YM5eXlQNemb27vmCeeeCJPPfUU119/Pc8++yyHH344Q4cOZcCAAVxxxRU88sgjDBo0KKnPSFZe1fQrR71CMZNpwuhDI5WjXiF4HICIdCRbMyt//vOf55prrmHt2rXs37+/pYa+ePFi6uvrWbNmDX379qWsrCzhdMqxEn0LeO211/jlL3/J6tWrGT58OJdffnmnx+loPrL+/fu3vC8uLk66eae9Yx533HGsWbOGpUuXcsMNNzB16lR+/OMf88ILL/D000+zZMkS/vM//5M//elPCffvjryq6TNpEhbW9C1cFpHUSMfMyoMHD6ayspKvfe1rrTpw9+zZwxFHHEHfvn1Zvnw5O3d23D93+umns3jxYgBefvllNmzYAATTMh922GEcfvjhvPXWWzz55JMt+wwZMoS9e/cmPNYf/vAH9u3bxwcffMCjjz7KZz7zmR79nO0dc9euXQwaNIiZM2dy7bXXsnbtWt5//3327NnD+eefz4IFC1qeI5wqeVXTX7FuaMtduR/RhxXrhuqRiSIplI6ZlWfMmMHFF1/caiTPZZddxuc+9zkqKiooLy/nk5/8ZIfHuPLKK/nqV7/KhAkTKC8vZ8qU4Bv+xIkTmTRpEieccEKbaZmrqqqYNm0aRx55JMuXL28pnzx5MpdffnnLMa644gomTZqUdFMOwE9/+tOWzloIHsmY6Jg1NTX84Ac/oKioiL59+3LHHXewd+9eLrroIg4cOIC7c+uttyb9ucnodGrlTOvu1MoAC7+wlG/+YRrBPbnOXZ9/kqpHz09pfCL5QlMr915pnVq5N2lgBEWEPU0463aXZTMcEZGck1dJv3LUK/QJ598B496/HKepGEREYuRV0o/MGsvX7HdEh21+1FysqRhEOpBrzbvSuZ7+zvIq6QNMsnXhO6fZ0VQMIu0YMGAADQ0NSvy9iLvT0NDAgAEDun2MvBq9w4oVrGueGC4Enbnr1nW0g0jhGj16NHV1ddTX12c7FOmCAQMGMHr06G7vn19Jv7ISijbQ0pcL8OabwKgsBSSSu/r27cuYMWOyHYZkWH4170QiTDo1esty8JV1EmuzF4+ISI7Jr6QPNJT+S8xduc0atikiEiPvkn7ssE2niN8+p2GbIiJReZf0I5MOcAYrwqVg2OZ992UzIhGR3JFfHbkADQ2MwYmO1RcRkUPyrqZPaSkVROfuCTtzNdmmiAiQZNI3s/PMbIuZbTOzOe1s82Uz22RmG83s9zHlTWa2Pnw9nqrA29XQwDqiT80Javoaqy8iEui0ecfMioHbgc8CdcBqM3vc3TfFbDMWuAE41d3fNbMjYg6x393LUxx3+yorwTZEK/kBjdUXEQGSq+lPAba5+3Z3PwgsAS6K2+YbwO3u/i6Au7+d2jC7IBJh0if3tSoauiO1DyEQEemtkkn6RwGvxyzXhWWxjgOOM7O/mNnzZnZezLoBZlYbln++h/EmpWHwx4m9Lfd/v3iOhm2KiJBc0k80BCZ+hqY+wFigEpgB3G1mw8J1/xxO7H8psMDMjm3zAWZV4YWhNhXzgFSeWURxS4hGk2vYpogIJJf064CjY5ZHA7sSbPOYu3/k7q8BWwguArj7rvDf7cAKoM1YGndf6O4V7l4xcuTILv8Q8SLDNnMB/0Xba5OISGFLJumvBsaa2Rgz6wdMB+JH4fwBOBPAzEYQNPdsN7PhZtY/pvxUYBPpVlrKBSwNFzRsU0QkqtPRO+7eaGbfAWqAYuAed99oZnOBWnd/PFw31cw2AU3AD9y9wcw+DdxlZs0EF5h5saN+0mbdurhhm5piWUQEkrwj192XQkvVOVr245j3DlwTvmK3+StwYs/D7Lo3+adWy5ue3wMcno1QRERyRv7dkQswaxajaD1q9LkXh2gEj4gUvPxM+pEIsy7ZRxFNYYHR7KYRPCJS8PIz6QOR0lc5jeeIHcHz5pvZi0dEJBfkbdLnrbcoYXe2oxARySn5m/RHtZ1rZ7euASJS4PI36U+axCjealX03HOoM1dEClr+Jv2GBmZxX+vO3GZXZ66IFLT8TfqVlUSKV6szV0QkRv4m/UgETj21TWeu2vVFpJDlb9IHKClpU/Tss2rXF5HCld9JH+I6cw131K4vIgUrv5P+qFHM4j6MJg6167va9UWkYOV30p81i0jRC3yG51oVq11fRApVfif9djpz1a4vIoUqv5M+QGmp2vVFREL5n/SBWdwHrdr1YVP6H+UiIpJz8j/pjxpFhOcpY2dMofPqq1mLSEQka/I/6c+aBUVFlPNiq+I334SFC7MUk4hIluR/0o9E4LTTuI5bgGaCJh4D4Le/zWZgIiKZl/9JH6CkhAjPM5ZtrYp37cpSPCIiWVIYST80nHdbLdfVqYlHRApLYST98IEqXyfannNoFI+aeESkkBRG0p81C4Aq7uYo/l+rVWriEZFCUhhJPxKB8nIAjuKNVqvUxCMihSSppG9m55nZFjPbZmZz2tnmy2a2ycw2mtnvY8pnm9nW8DU7VYF3WVkZkLiJ5+c/z3w4IiLZ0GnSN7Ni4HZgGjAOmGFm4+K2GQvcAJzq7icAV4flJcCNwMnAFOBGMxue0p8gWWG7fhV3U8I7rVbt3Km5eESkMCRT058CbHP37e5+EFgCXBS3zTeA2939XQB3fzssPxf4o7vvDtf9ETgvNaF30axZYMH4/NN5ts3q+fMzHZCISOYlk/SPAl6PWa4Ly2IdBxxnZn8xs+fN7Lwu7JsZkQhMnAgQ3qjlxDbxPPNMVqISEcmoZJK+JSjzuOU+wFigEpgB3G1mw5LcFzOrMrNaM6utr69PIqRu6tcPIJyLZ0erVbt3q0NXRPJfMkm/Djg6Znk0ED/QsQ54zN0/cvfXgC0EF4Fk9sXdF7p7hbtXjBw5sivxd83Xv97y9gZ+Ef30ljJ16IpIvksm6a8GxprZGDPrB0wHHo/b5g/AmQBmNoKguWc7UANMNbPhYQfu1LAsO6qq1KErIgWt06Tv7o3AdwiS9WbgQXffaGZzzezCcLMaoMHMNgHLgR+4e4O77wZ+QnDhWA3MDcuy57jjWt4m6tD99rczGYyISGaZe5sm9qyqqKjw2tra9H3AlVfCnXcCsJJT+DR/Ieh6ONT98Ne/Bv2+IiK9hZmtcfeKzrYrjDtyY4VTMkDQoTuR9W02UW1fRPJV4SX9SKTl7lyAO/h34gcUrV+vkTwikp8KL+lDyzw8ENT2T+cZ4hP/jTdmOCYRkQwozKR/3XWtFudxA/FJX49TFJF8VJhJPxJpGboJYW2/uO1YTdX2RSTfFGbSBzjllFaL85quJXiG7iGq7YtIvincpB/XxBPheU7v90KbzVTbF5F8UrhJP66JB2Dewe+j2r6I5LPCTfrQpoknwvOcfuS2NpvdcEOmAhIRSa/CTvpxTTwA8wb/rE2ZZuAUkXxR2Ek/7kYtgMjW+7hs6tttNr322gzFJCKSRoWd9KHVjVpRiw58iYEDW5ft3QszZ2YoJhGRNFHST9DEwzPP8N2L69oUL16sqZdFpHdT0o9E4PTT2xRXD/kZQ4e23XzOnAzEJCKSJkr6APPmtS17/nluuaVt8TPPqLYvIr2Xkj4k7NBl/XqqTlwZP5QfgNmzMxKViEjKKelHJejQZf58br65bfHWrRrCKSK9k5J+VDsdulVV8IlPtF31/e+nPyQRkVRT0o9K1MQT3pV1331tN9+3D04+OSORiYikjJJ+rETzLfz850QicNllbVe98IKaeUSkdym8B6N3prQ0qOHHCp+UfsQRUF/fetWgQfDBB5kLT0QkET0YvbsSjNln/nwAHnus7So184hIb6KkH6+dDl2gw2YeTdEgIr2Bkn68Djp0ARYtgpEj2+62eLHa90Uk9ynpJ9JOh25UomYe0DBOEcl9SSV9MzvPzLaY2TYzazP7jJldbmb1ZrY+fF0Rs64ppvzxVAafNlVVUFLSumznzpb5FyKRxK1A+/bBuHEZiE9EpJs6TfpmVgzcDkwDxgEzzCxRanvA3cvD190x5ftjyi9MTdgZ0EGHLkB1NUyd2naTzZvh3HPTGJeISA8kU9OfAmxz9+3ufhBYAlyU3rByQAcdulE1NYnb95ctg+uvT1NcIiI9kEzSPwp4PWa5LiyL90Uz22BmD5nZ0THlA8ys1syeN7PP9yTYjOqkQzeqvfb9+fM1G6eI5J5kkr4lKIu/o+u/gDJ3nwA8BfwuZt0/hzcMXAosMLNj23yAWVV4Yaitj7/7KZs66dCF9tv3Ac4/Pw0xiYj0QDJJvw6IrbmPBnbFbuDuDe7+Ybj4G+CkmHW7wn+3AyuASfEf4O4L3b3C3StGJmovyZZOOnSj2mvff++9tl8WRESyKZmkvxoYa2ZjzKwfMB1oNQrHzI6MWbwQ2ByWDzez/uH7EcCpwKZUBJ4xnXToRtXUwPHHt910506N6BGR3NFp0nf3RuA7QA1BMn/Q3Tea2Vwzi47GucrMNprZi8BVwOVh+fFAbVi+HJjn7r0r6SfRoRu1aRMMG9a2fPNmTdUgIrlBE64lY8wY2LGjddlddwXNP3FWroRPfzrxYaZODb4RiIikmiZcS6UkOnSjIpHgepDIsmUawy8i2aWkn4wkO3RjN29vRM+yZWrqEZHsUdJPVqIO3TltZqRoUV2deEZOCGblVOeuiGSDkn6y2uvQ7eAOrEWLEg/lhKBzd+BAzcwpUigWLgye0WTW/mvQoPTfza+kn6xEd+hCh7V9CDpu20v8Bw7AN7+p5h6R3uzcc6GoqONkbhb8rcc/lC/e/v3BiPB0Jn4l/a5I1KHbSW0fgsTfXlMPBM09/fur1i+SK2bOhD59Ok/kZkE/XaoHQT7ySGqPF0tJvyuqqmDUqLblCW7WirdoUfuduwAHDwY1AbX1i6ReV5K4WfBQpKam7MV78cXpO7aSflfdfHPbsqefTmrX6urgGesdzTSxeXPwVVGPXxRJLNnmlFxK4skaODCoHFZXp+8zlPS7KlFtf+/epAfgRyLw9tsdN/e4B/9J+/TRFM3Su1x/fZC4YhNuVxN0NppTMsEMBg8Okrp74te+felN+KCk3z2JavvLlnWpUX7RoqDWn2jahqimpqDlqG9fJX/pmWRGjqTiNX9+MEAhVm9M0F1RVBQM1mgvkUdfzc1B/TDdSb3TeLP78b1UVRV84hNty2+8sUuHiUTg3XeDK78lmsA61NgY/DEVFUF5uebpLwTdacLo6cgROcQs+BP/6187T+ZNTb1rehUl/e667762ZW++2a0hONXVQS1gypSOt3OHF18M5vbp00ft/rls5Uo47rjCa8LIVV1J4tFa+datQcUs3yjpd1ckkvgu3S7W9mOtWtV5R29UU1PQ7m8WfG3XcM/06uroj09/OkgaknrJNqcUShLvKiX9npg3r21ZN2v7UdGO3rvuCu7OS8bu3cHXd7Og/V/fADrWnVp4bxn9kQtKSoL/v+5BJebnP0++hp3Mq7c1p+Qcd8+p10knneS9yumnt/1/WVKSssPfdVdwuO7+iZSUBMcoBD09V/n+GjjQ/brrsv1bknQBaj2JHKuafk8lqu0neIB6d1VVQUND8Gd72WXBV9uuiP0WEB0+N3Zs7+kM7kqzSj51VnanCaOzVyaGA0ru00NUUmHmzOD7f6whQ+Af/0jLx61cCbNnq8041/XrB1/6UjA8VyTd9BCVTFq0KLgjJdbevWkbXB+JwKuvBrW3666DAQPS8jESo6ioa6M/3OHDD5XwJfco6afKd7/btuy229L+sdXVwcx87kFCGjs27R+ZF/r0CZrLkk3gTU0a/SH5QUk/VaqrYejQ1mUHDmR0KE3sNwD3YARF/AO/8l107pLOkvhHH6kWLoVJST+VbrmlbdnixVnrNY3tBI6+LrsMiouzEk63dPWmGnVWinRMHbmpVlradgjJ2LFBFVxEJE3UkZstv/hF27KtW3XLrIjkBCX9VGtvMrZrr818LCIicZJK+mZ2npltMbNtZtbmobBmdrmZ1ZvZ+vB1Rcy62Wa2NXzNTmXwOSvRZGx792p+BBHJuk6TvpkVA7cD04BxwAwzS/RQvwfcvTx83R3uWwLcCJwMTAFuNLPhKYs+V0UiiZ+SksVOXRERSK6mPwXY5u7b3f0gsAS4KMnjnwv80d13u/u7wB+B87oXai+zaFHbIZwAX/5y5mMREQklk/SPAl6PWa4Ly+J90cw2mNlDZnZ0F/fNT4mGcNbVqZlHRLImmaSf6JlO8eM8/wsoc/cJwFPA77qwL2ZWZWa1ZlZbX1+fREi9RHudumrmEZEsSSbp1wFHxyyPBnbFbuDuDe7+Ybj4G+CkZPcN91/o7hXuXjEymSeI9CaJOnVBzTwikhXJJP3VwFgzG2Nm/YDpwOOxG5jZkTGLFwKbw/c1wFQzGx524E4NywpHJBLMCxCvri54EKqISAZ1mvTdvRH4DkGy3gw86O4bzWyumV0YbnaVmW00sxeBq4DLw313Az8huHCsBuaGZYWlujpxM8+yZWrfF5GM0jQMmbJyZfDg1ESuu04TxohIj2gahlzTXjMPwPz5mqZBRDJCST+TqqsT37QFwbP+NKJHRNJMST/TFi0KHn6ayPnnZzYWESk4SvrZUFMDxx/ftvy996CsLOPhiEjhUNLPlk2b4OMfb1u+c6cSv4ikjZJ+Nu3YAcOGtS1X4heRNFHSz7alSxOXK/GLSBoo6WdbJBI8wTyRnTvhyCMTrxMR6QYl/VxQVdV+4n/zTRg0SMM5RSQllPRzRUeJf//+4G5eTdkgIj2kpJ9LOkr8EEzJPC7RQ8tERJKjpJ9rqqrgr3+FgQMTr9+8Gfr317QNItItSvq5KBKBfftg1KjE6w8eDKZtUK1fRLpIST+XvfEGTJnS/vrNm6FvX9X6RSRpSvq5btWqoJ2/b9/E6xsbVesXkaQp6fcGVVVBk06iaRuiNm+GoiKN8BGRDinp9yY7dgRz8lui580D7sEIHyV/EWmHkn5vU10Nzc0d1/qjyd9Mz+EVkVaU9Hurzmr9UcuWBduUlqrDV0SU9Hu1aK2/oxE+Ubt3Bx2+RUWq/YsUMCX9fLBqVXBD1+jRnW/rfqj2P2gQXH99+uMTkZyhpJ8vIhF4/fUg+Y8dm9w++/cHD2VX849IwVDSzzeRCLz6alCjb+8h7Imo+UekICjp57NFi4Lkf911MGBAcvvENv8UFwffGjSts0jeUNIvBNXVQVOOO0ydmvx+zc2wbVswrbOagETyQlJJ38zOM7MtZrbNzOZ0sN0lZuZmVhEul5nZfjNbH77uTFXg0k01NUHyv+suKCnp2r7RJiCzYFoI3QAm0ut0mvTNrBi4HZgGjANmmFmbiV7MbAhwFbAqbtXf3L08fH0rBTFLKlRVQUND15t/ohobD90ApouASK+RTE1/CrDN3be7+0FgCXBRgu1+AswHDqQwPsmE+Oafom60+sVfBNQcJJKTkvnrPgp4PWa5LixrYWaTgKPd/YkE+48xs3Vm9mcz+0z3Q5WMqKmBpqZDo3+Ki7t/LDUHieScZJJ+ovv8vWWlWRFwK/C/Emz3BvDP7j4JuAb4vZkNbfMBZlVmVmtmtfX19clFLum3aFFQg+9uE1Cs+G8CujEwC+8nAAAJeElEQVRMJCuSSfp1wNExy6OBXTHLQ4DxwAoz2wGcAjxuZhXu/qG7NwC4+xrgb8Bx8R/g7gvdvcLdK0aOHNm9n0TSK7YJqCs3gLUn9sYwXQhEMiaZpL8aGGtmY8ysHzAdeDy60t33uPsIdy9z9zLgeeBCd681s5FhRzBmdgwwFtie8p9CMiv2BrDoRaC8vHt9AbHiLwRFRbpPQCTFOv0rdfdG4DtADbAZeNDdN5rZXDO7sJPdTwc2mNmLwEPAt9x9d0+DlhwTicC6dYf6AlLRHATBcWLvE1DfgEiPmbt3vlUGVVRUeG1tbbbDkFRauRJmz4atW9NzfDM49li4777gAiRSgMxsjbtXdLad7siV9ItvDurOjWEdSfSNQH0EIgkp6Uvmxd4Ylq4LASTuLNYFQQqckr7khkQXgp7eJ9CR9i4I6jOQPKekL7kr9j6B2KGinT0isicS3Vms0USSR5T0pfeI9g00N2fuG0Gs9voONO2E9CJK+tL7xX8jSFcfQWdip51I9FLTkeQAJX3JT4n6CLJ5QYCOm450cZAMUdKXwtPeBSEV00ukQrIXB41Ckm5Q0heJir+fIP6Vqb6DruhoWKq+RUgCSvoiyUrUd5DKaScyoSvfIqLPST733GxHLSmkpC+SCrGzkCZ65UrTUVc1N8OyZclfJNTklPOU9EUyobOmo95+cYjV1SYnfaPIKCV9kVyS7MUhOgpp1KieT2mdC7rzjUIXim7Jg/8tIgWqqgreeKP1lNbJfItI5x3NmdSdC4VuoFPSFykY7d3R3NFr6tT8uUhA5zfQFcDFQUlfRNpXU9O1i0S2bnxLtWQvDr1wPiYlfRFJnY7uhM7HbxSdzceUg/0RSvoikn1d/UbRmy8U0H5/RAaGuyrpi0jv1NULRW+4gS463DWNiV9JX0QKQ2c30OXSxeGRR9J2aCV9EZFYyV4c0jkf08UXp/6YISV9EZHu6mg+pu70RwwcGHzTqK5OW8h90nZkERFJrKYmax+tmr6ISAFR0hcRKSBJJX0zO8/MtpjZNjOb08F2l5iZm1lFTNkN4X5bzEyzI4mIZFGnbfpmVgzcDnwWqANWm9nj7r4pbrshwFXAqpiyccB04ATgY8BTZnacuzel7kcQEZFkJVPTnwJsc/ft7n4QWAJclGC7nwDzgQMxZRcBS9z9Q3d/DdgWHk9ERLIgmaR/FPB6zHJdWNbCzCYBR7v7E13dN9y/ysxqzay2vr4+qcBFRKTrkhmymWhyC29ZaVYE3Apc3tV9WwrcFwILw+PVm9nOJOJqzwjgnR7sn265Hh/kfoy5Hh8oxlTI9fggt2L8eDIbJZP064CjY5ZHA7tilocA44EVFtxsMAp43MwuTGLfNtx9ZBIxtcvMat29ovMtsyPX44PcjzHX4wPFmAq5Hh/0jhjjJdO8sxoYa2ZjzKwfQcfs49GV7r7H3Ue4e5m7lwHPAxe6e2243XQz629mY4CxwAsp/ylERCQpndb03b3RzL4D1ADFwD3uvtHM5gK17v54B/tuNLMHgU1AI/DvGrkjIpI9SU3D4O5LgaVxZT9uZ9vKuOWfAT/rZnzdkevPOMv1+CD3Y8z1+EAxpkKuxwe9I8ZWzL1Nv6qIiOQpTcMgIlJA8ibpJztVRAbiONrMlpvZZjPbaGbfC8tLzOyPZrY1/Hd4WG5mdlsY9wYzm5yhOIvNbJ2ZPREujzGzVWF8D4Sd9oSd8A+E8a0ys7IMxTfMzB4ys1fCcxnJpXNoZt8Pf78vm9n9ZjYg2+fQzO4xs7fN7OWYsi6fMzObHW6/1cxmZyDGW8Lf8wYze9TMhsWsSziNS7r+3hPFF7PuWgummRkRLmflHPaYu/f6F0EH89+AY4B+wIvAuCzFciQwOXw/BHgVGEdwt/KcsHwOUB2+Px94kuCehlOAVRmK8xrg98AT4fKDwPTw/Z3AleH7bwN3hu+nAw9kKL7fAVeE7/sBw3LlHBLcYPgaMDDm3F2e7XMInA5MBl6OKevSOQNKgO3hv8PD98PTHONUoE/4vjomxnHh33J/YEz4N16czr/3RPGF5UcTDGbZCYzI5jns8c+Y7QBS9IuKADUxyzcAN2Q7rjCWxwjmLdoCHBmWHQlsCd/fBcyI2b5luzTGNBp4GjgLeCL8T/tOzB9ey/kM/6NHwvd9wu0szfENDZOqxZXnxDnk0J3mJeE5eQI4NxfOIVAWl1C7dM6AGcBdMeWttktHjHHrvgAsDt+3+juOnsd0/70nig94CJgI7OBQ0s/aOezJK1+ad5Ka7iHTwq/xkwgmofsnd38DIPz3iHCzbMS+ALgOaA6XS4H33L0xQQwt8YXr94Tbp9MxQD1wb9gEdbeZHUaOnEN3/zvwS+D/AW8QnJM15NY5jOrqOcv239LXCGrPdBBLRmO04EbTv7v7i3GrciK+rsqXpJ/UdA+ZZGaDgYeBq939Hx1tmqAsbbGb2b8Cb7v7miRjyMa57UPwFfsOd58EfEDQNNGeTJ/D4QSTCY4hmD32MGBaBzHk3P9P2o8pa7Ga2Y8I7udZHC1qJ5aMxWhmg4AfAYmGqGc9vu7Il6Tf5eke0snM+hIk/MXuHn2s/VtmdmS4/kjg7bA807GfClxoZjsIZkw9i6DmP8zMovdtxMbQEl+4/nBgdxrji35mnbtHp+l+iOAikCvn8BzgNXevd/ePgEeAT5Nb5zCqq+csK39LYWfnvwKXedgmkiMxHktwcX8x/JsZDaw1s1E5El+X5UvS73CqiEwyMwN+C2x291/FrHociPbizyZo64+WzwpHApwC7Il+HU8Hd7/B3Ud7MGXGdOBP7n4ZsBy4pJ34onFfEm6f1lqLu78JvG5m/xIWnU1wV3dOnEOCZp1TzGxQ+PuOxpcz5zBGV89ZDTDVzIaH32imhmVpY2bnAdcTTN+yLy72RNO4ZOzv3d1fcvcj/NA0M3UEAzXeJIfOYZdku1MhVS+CnvRXCXr1f5TFOE4j+Cq3AVgfvs4naMN9Gtga/lsSbm8ED6n5G/ASUJHBWCs5NHrnGII/qG3A/wX6h+UDwuVt4fpjMhRbOVAbnsc/EIyCyJlzCNwMvAK8DPwfghEmWT2HwP0EfQwfESSnr3fnnBG0q28LX1/NQIzbCNrAo38vd8Zs/6Mwxi3AtJjytPy9J4ovbv0ODnXkZuUc9vSlO3JFRApIvjTviIhIEpT0RUQKiJK+iEgBUdIXESkgSvoiIgVESV9EpIAo6YuIFBAlfRGRAvL/AfZxMmR48pdoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2.history[\"acc\"],'r', marker='.', label=\"Train Accuracy\")\n",
    "ax.plot(run_hist_2.history[\"val_acc\"],'b', marker='.', label=\"Validation Accuracy\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa206711400>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2b.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_2b.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_2b.history[\"acc\"],'r', marker='.', label=\"Train Accuracy\")\n",
    "ax.plot(run_hist_2b.history[\"val_acc\"],'b', marker='.', label=\"Validation Accuracy\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa23c76e160>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
